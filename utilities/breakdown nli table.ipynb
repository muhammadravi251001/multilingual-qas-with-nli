{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b725b5",
   "metadata": {},
   "source": [
    "# Inference with NLI validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0296fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from io import StringIO\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b777c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"https://huggingface.co/muhammadravi251001/fine-tuned-FilteringNLI-\"\n",
    "suffix = \"/raw/main/results/output/output_df.csv\"\n",
    "suffix_squadid = \"/resolve/main/results/output/output_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea7850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"idkmrc\"\n",
    "\n",
    "MODEL_SC_NAME_1 = f\"muhammadravi251001/fine-tuned-NLI-indonli-with-xlm-roberta-large\"\n",
    "MODEL_SC_NAME_2 = f\"muhammadravi251001/fine-tuned-NLI-indonli_mnli-with-xlm-roberta-large\"\n",
    "MODEL_SC_NAME_3 = f\"muhammadravi251001/fine-tuned-NLI-indonli_mnli_{data}-nli-with-xlm-roberta-large\"\n",
    "\n",
    "tokenizer_sc_1 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_1)\n",
    "model_sc_1 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_1)\n",
    "\n",
    "tokenizer_sc_2 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_2)\n",
    "model_sc_2 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_2)\n",
    "\n",
    "tokenizer_sc_3 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_3)\n",
    "model_sc_3 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e56d71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_dataframe(url): \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        csv_data = StringIO(response.text)\n",
    "        df = pd.read_csv(csv_data, index_col=0)\n",
    "    \n",
    "    else:\n",
    "        print(\"Failed to download CSV\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eaca91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_sc(text_dict, model_num):\n",
    "    \n",
    "    if model_num == 1:\n",
    "        tokenizer_sc = tokenizer_sc_1\n",
    "        model_sc = model_sc_1\n",
    "    \n",
    "    elif model_num == 2:\n",
    "        tokenizer_sc = tokenizer_sc_2\n",
    "        model_sc = model_sc_2\n",
    "   \n",
    "    elif model_num == 3:\n",
    "        tokenizer_sc = tokenizer_sc_3\n",
    "        model_sc = model_sc_3\n",
    "    \n",
    "    tokenizer_kwargs = {'truncation': True, 'max_length': 512}\n",
    "    \n",
    "    inputs = tokenizer_sc(text_dict['text'], text_dict['text_pair'], \n",
    "                          return_tensors=\"pt\",\n",
    "                          **tokenizer_kwargs)\n",
    "    \n",
    "    outputs = model_sc(**inputs)\n",
    "\n",
    "    label_id = torch.argmax(outputs.logits).item()\n",
    "    label = model_sc.config.id2label[label_id]\n",
    "    score = outputs.logits.softmax(dim=-1)[0][label_id].item()\n",
    "\n",
    "    return {'label': label, 'score': score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c465b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_label(df, model_num):\n",
    "    \n",
    "    entailment = 0\n",
    "    neutral = 0\n",
    "    contradiction = 0\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        \n",
    "        label = nlp_sc({'text': df['Context'][i], 'text_pair': df['Gold Hypothesis'][i]}, model_num)[\"label\"]\n",
    "        \n",
    "        if label == \"entailment\": entailment += 1\n",
    "        elif label == \"neutral\": neutral += 1\n",
    "        elif label == \"contradiction\": contradiction += 1\n",
    "            \n",
    "    return entailment, neutral, contradiction, len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf206fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nli_of_gold_answer(data, squadid=False):\n",
    "    \n",
    "    # Take output_df.csv from Hugging Face\n",
    "    df = take_dataframe(f\"{prefix}indonli_mnli-{data}-TQ2-TS4-MS3-VA0-TH0.0{suffix}\")\n",
    "    \n",
    "    if squadid:\n",
    "        df = take_dataframe(f\"{prefix}indonli_mnli-{data}-TQ2-TS4-MS3-VA0-TH0.0{suffix_squadid}\")\n",
    "    \n",
    "    label_1 = gold_label(df, 1)\n",
    "    label_2 = gold_label(df, 2)\n",
    "    label_3 = gold_label(df, 3)\n",
    "    \n",
    "    # Show table to Latex\n",
    "    dataset_list = []\n",
    "    dataset_list.extend([data] * 3)\n",
    "\n",
    "    df_nli_label_gold_answer = pd.DataFrame(\n",
    "        {\n",
    "\n",
    "        'Model': [\"INLI\", \"INLI_MNLI\", \"INLI_MNLI_AUG\"],\n",
    "        'Dataset': dataset_list,\n",
    "        'Entailment': [label_1[0], label_2[0], label_3[0]],\n",
    "        'Neutral': [label_1[1], label_2[1], label_3[1]],\n",
    "        'Contradiction': [label_1[2], label_2[2], label_3[2]],\n",
    "        'Total': [label_1[3], label_2[3], label_3[3]]\n",
    "            \n",
    "        }, \n",
    "\n",
    "        columns=['Model', 'Dataset', 'Entailment', 'Neutral', 'Contradiction', 'Total']\n",
    "        )\n",
    "\n",
    "    # Uncomment this to get latex code\n",
    "    #print(\"NLI of gold answer\")\n",
    "    #print(df_score_em_f1.to_latex(index=False))\n",
    "    \n",
    "    return df_nli_label_gold_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 844/844 [12:51<00:00,  1.09it/s]\n",
      " 32%|█████████████████████████▊                                                       | 269/844 [03:49<07:13,  1.33it/s]"
     ]
    }
   ],
   "source": [
    "data = \"idkmrc\"\n",
    "table = pd.DataFrame(show_nli_of_gold_answer(data))\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff1b6d-0326-456d-b587-02440370939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"tydiqaid\"\n",
    "\n",
    "MODEL_SC_NAME_1 = f\"muhammadravi251001/fine-tuned-NLI-indonli-with-xlm-roberta-large\"\n",
    "MODEL_SC_NAME_2 = f\"muhammadravi251001/fine-tuned-NLI-indonli_mnli-with-xlm-roberta-large\"\n",
    "MODEL_SC_NAME_3 = f\"muhammadravi251001/fine-tuned-NLI-indonli_mnli_{data}-nli-with-xlm-roberta-large\"\n",
    "\n",
    "tokenizer_sc_1 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_1)\n",
    "model_sc_1 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_1)\n",
    "\n",
    "tokenizer_sc_2 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_2)\n",
    "model_sc_2 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_2)\n",
    "\n",
    "tokenizer_sc_3 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_3)\n",
    "model_sc_3 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ff7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"tydiqaid\"\n",
    "table = pd.DataFrame(show_nli_of_gold_answer(data))\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53146f-c1fe-4215-b049-b10d89c96b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"squadid\"\n",
    "\n",
    "MODEL_SC_NAME_1 = f\"muhammadravi251001/fine-tuned-NLI-indonli-with-xlm-roberta-large\"\n",
    "MODEL_SC_NAME_2 = f\"muhammadravi251001/fine-tuned-NLI-indonli_mnli-with-xlm-roberta-large\"\n",
    "MODEL_SC_NAME_3 = f\"muhammadravi251001/fine-tuned-NLI-indonli_mnli_{data}-nli-with-xlm-roberta-large\"\n",
    "\n",
    "tokenizer_sc_1 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_1)\n",
    "model_sc_1 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_1)\n",
    "\n",
    "tokenizer_sc_2 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_2)\n",
    "model_sc_2 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_2)\n",
    "\n",
    "tokenizer_sc_3 = AutoTokenizer.from_pretrained(MODEL_SC_NAME_3)\n",
    "model_sc_3 = AutoModelForSequenceClassification.from_pretrained(MODEL_SC_NAME_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"squadid\"\n",
    "table = pd.DataFrame(show_nli_of_gold_answer(data, squadid=True))\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0306be",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
