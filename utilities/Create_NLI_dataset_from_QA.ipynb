{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9171daa4",
   "metadata": {},
   "source": [
    "# Define tool and model of the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a063a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 15 08:15:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    57W / 300W |  29352MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    75W / 300W |  17054MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    79W / 300W |  16774MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    98W / 300W |  16872MiB / 32510MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   50C    P0   104W / 300W |  16982MiB / 32510MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   122W / 300W |  31732MiB / 32510MiB |     92%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    59W / 300W |    828MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f10e14",
   "metadata": {},
   "source": [
    "Below, it is some settings to run in my local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e983e0",
   "metadata": {},
   "source": [
    "You can tweak your settings too in code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41849a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "NAME = \"idk-mrc\"\n",
    "NO_ANSWER_STATEMENT = \"Tidak ada jawaban\"\n",
    "\n",
    "TASK_NER_NAME = \"ner\"\n",
    "MODEL_NER_NAME = \"ageng-anugrah/indobert-large-p2-finetuned-ner\"\n",
    "\n",
    "TASK_CHUNKING_NAME = \"token-classification\"\n",
    "MODEL_CHUNKING_NAME = \"ageng-anugrah/indobert-large-p2-finetuned-chunking\"\n",
    "\n",
    "MODEL_SIMILARITY_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "URL_STOPWORD = \"https://raw.githubusercontent.com/6/stopwords-json/master/stopwords-all.json\"\n",
    "\n",
    "TASK_PARAPHRASER_NAME = \"text2text-generation\"\n",
    "MODEL_PARAPHRASER_NAME = \"\"\n",
    "\n",
    "# Uncomment sys.maxsize to create all of the data, \n",
    "# else if you want to debugging\n",
    "\n",
    "# SAMPLE = sys.maxsize\n",
    "SAMPLE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9fdd4",
   "metadata": {},
   "source": [
    "# Import anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26d313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import string\n",
    "import contextlib\n",
    "import gc\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from evaluate import load\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "from datetime import datetime\n",
    "from huggingface_hub import notebook_login\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import HfApi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    Dataset,\n",
    "    DatasetDict\n",
    ")\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback, \n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cd27c",
   "metadata": {},
   "source": [
    "# Retrieve QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f426d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRAM STARTED\n"
     ]
    }
   ],
   "source": [
    "print(\"PROGRAM STARTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafbf0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset idk_mrc (/root/.cache/huggingface/datasets/idk_mrc/idk_mrc_source/1.0.0/cf468d86fa7341e69998db1449851672ebfb4fa46036929d66b9de15c421334f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e66b68cd8e4130909b08401c83eb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3659/3659 [00:16<00:00, 218.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 358/358 [00:01<00:00, 266.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 378/378 [00:01<00:00, 257.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 9332\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 764\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "data_qas = conhelps.filtered(lambda x: 'idk_mrc' in x.dataset_name)[0].load_dataset()\n",
    "\n",
    "df_train = pd.DataFrame(data_qas['train'])\n",
    "df_validation = pd.DataFrame(data_qas['validation'])\n",
    "df_test = pd.DataFrame(data_qas['test'])\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_train['context']))):\n",
    "    for j in df_train[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                           \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                           \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                           ignore_index=True)\n",
    "        else:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": str(), \n",
    "                                                           \"answer_start\": 0, \n",
    "                                                           \"answer_end\": 0}}, \n",
    "                                                           ignore_index=True)\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_val = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_validation['context']))):\n",
    "    for j in df_validation[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)        \n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_test = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_test['context']))):\n",
    "    for j in df_test[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict(new_df_train)\n",
    "validation_dataset = Dataset.from_dict(new_df_val)\n",
    "test_dataset = Dataset.from_dict(new_df_test)\n",
    "\n",
    "data_qas = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset, \"test\": test_dataset})\n",
    "data_qas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae908a",
   "metadata": {},
   "source": [
    "# Convert to NLI, with hypothesis being just do concat question & answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c79ac",
   "metadata": {},
   "source": [
    "## Convert Dataset to DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b342b8ce-41f9-4714-84a5-1697cfee1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 42, the answer to life the universe and everything\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275dc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to training all of the data (prod),\n",
    "# this code will convert to DataFrame.\n",
    "# However, if you want to debug (not-prod),\n",
    "# this code will convert SAMPLE of your DataFrame\n",
    "\n",
    "if SAMPLE == sys.maxsize:\n",
    "    data_qas_train_df = pd.DataFrame(data_qas[\"train\"][:SAMPLE])\n",
    "    data_qas_val_df = pd.DataFrame(data_qas[\"validation\"][:SAMPLE])\n",
    "    data_qas_test_df = pd.DataFrame(data_qas[\"test\"][:SAMPLE])\n",
    "\n",
    "else:\n",
    "    data_qas_train_df = (pd.DataFrame(data_qas[\"train\"])).sample(n=SAMPLE, random_state=seed_value)\n",
    "    data_qas_val_df = (pd.DataFrame(data_qas[\"validation\"])).sample(n=SAMPLE, random_state=seed_value)\n",
    "    data_qas_test_df = (pd.DataFrame(data_qas[\"test\"])).sample(n=SAMPLE, random_state=seed_value)\n",
    "\n",
    "    data_qas_train_df = data_qas_train_df.reset_index(drop=True)\n",
    "    data_qas_val_df = data_qas_val_df.reset_index(drop=True)\n",
    "    data_qas_test_df = data_qas_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bbf0b",
   "metadata": {},
   "source": [
    "## Retrieve answer text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0424485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retrieve answer text\n",
    "# Because, we do not use answer_start\n",
    "# and answer_end\n",
    "\n",
    "def retrieve_answer_text(data):\n",
    "    for i in range(len(data)):\n",
    "        data['answer'][i] = data['answer'][i]['text']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b1a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = retrieve_answer_text(data_qas_train_df)\n",
    "data_qas_val_df = retrieve_answer_text(data_qas_val_df)\n",
    "data_qas_test_df = retrieve_answer_text(data_qas_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881d292",
   "metadata": {},
   "source": [
    "## Create NLI dataset from copy of QA dataset above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8808af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_qas_train_df.copy()\n",
    "data_nli_val_df = data_qas_val_df.copy()\n",
    "data_nli_test_df = data_qas_test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89c33f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bendera Jerman pertama kali diperkenalkan pada...</td>\n",
       "      <td>Apa warna bendera Jerman ?</td>\n",
       "      <td>hitam di atas, merah di tengah, dan kuning (\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daratan utama Skotlandia mencakup sepertiga da...</td>\n",
       "      <td>Berapa luas Skotlandia pada tahun 1835?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paus (dari Dutch: paus; Latin: papa dari Greek...</td>\n",
       "      <td>Siapakah nama pemimpin dalam gereja ?</td>\n",
       "      <td>Paus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Euro (€) adalah mata uang yang dipakai di 19 n...</td>\n",
       "      <td>Kapan mata uang Euro secara fisik baru dipakai?</td>\n",
       "      <td>1 Januari 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kabupaten Kaimana adalah salah satu kabupaten ...</td>\n",
       "      <td>Berapa luas Kabupaten Kaimana?</td>\n",
       "      <td>36.000 km2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Bintang The Fabulous Beekman Boys dan teman hi...</td>\n",
       "      <td>Siapakah pemenang The Amazing Race?</td>\n",
       "      <td>Josh Kilmer-Purcell dan Brent Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Kekristenan muncul dari wilayah Levant (sekara...</td>\n",
       "      <td>Kapan agama Kristen pertama muncul?</td>\n",
       "      <td>abad pertama Masehi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Lalu wayang golek dengan cerita dari epos Hind...</td>\n",
       "      <td>Dimana karya Mahabharata pertama ditampilkan?</td>\n",
       "      <td>wayang golek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Setelah Perhimpunan Pekabaran Injil Gereformee...</td>\n",
       "      <td>Kapan Antonie Aris van de Loosdrecht masuk ke ...</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Sejarah internet Indonesia dimulai pada awal t...</td>\n",
       "      <td>Kapan internet mulai masuk ke Indonesia?</td>\n",
       "      <td>tahun 1990-an</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Bendera Jerman pertama kali diperkenalkan pada...   \n",
       "1    Daratan utama Skotlandia mencakup sepertiga da...   \n",
       "2    Paus (dari Dutch: paus; Latin: papa dari Greek...   \n",
       "3    Euro (€) adalah mata uang yang dipakai di 19 n...   \n",
       "4    Kabupaten Kaimana adalah salah satu kabupaten ...   \n",
       "..                                                 ...   \n",
       "145  Bintang The Fabulous Beekman Boys dan teman hi...   \n",
       "146  Kekristenan muncul dari wilayah Levant (sekara...   \n",
       "147  Lalu wayang golek dengan cerita dari epos Hind...   \n",
       "148  Setelah Perhimpunan Pekabaran Injil Gereformee...   \n",
       "149  Sejarah internet Indonesia dimulai pada awal t...   \n",
       "\n",
       "                                              question  \\\n",
       "0                           Apa warna bendera Jerman ?   \n",
       "1              Berapa luas Skotlandia pada tahun 1835?   \n",
       "2                Siapakah nama pemimpin dalam gereja ?   \n",
       "3      Kapan mata uang Euro secara fisik baru dipakai?   \n",
       "4                       Berapa luas Kabupaten Kaimana?   \n",
       "..                                                 ...   \n",
       "145                Siapakah pemenang The Amazing Race?   \n",
       "146                Kapan agama Kristen pertama muncul?   \n",
       "147      Dimana karya Mahabharata pertama ditampilkan?   \n",
       "148  Kapan Antonie Aris van de Loosdrecht masuk ke ...   \n",
       "149           Kapan internet mulai masuk ke Indonesia?   \n",
       "\n",
       "                                                answer  \n",
       "0    hitam di atas, merah di tengah, dan kuning (\"e...  \n",
       "1                                                       \n",
       "2                                                 Paus  \n",
       "3                                       1 Januari 2002  \n",
       "4                                           36.000 km2  \n",
       "..                                                 ...  \n",
       "145                Josh Kilmer-Purcell dan Brent Ridge  \n",
       "146                                abad pertama Masehi  \n",
       "147                                       wayang golek  \n",
       "148                                               1913  \n",
       "149                                      tahun 1990-an  \n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qas_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b938d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'context': [\"Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fettes atau Oxford University karena bisnis ayahnya terkena dampak depresi pertengahan dekade 1920-an. Namun, kuliahnya tidak berhasil dan ia meninggalkan Oxford untuk ke Paris pada tahun 1931 tempat ia menjadi chef magang di Majestic Hotel. Setelah setahun, ia kembali ke Skotlandia dan mulai menjual kompor masak AGA dari rumah ke rumah. Keberhasilannya dalam menjual kompor ini membuatnya dikenal sebagai karyawan, yang kemudian memintanya menulis manual instruksi, The Theory and Practice of Selling the AGA Cooker, untuk staf penjualan lainnya. Tiga puluh tahun kemudian, editor majalah Fortune menyebutnya sebagai manual instruksi penjualan terbaik yang pernah ditulis.\"],\n",
    "    'question': [\"Apa alasan Ogilvy tidak bisa kuliah di Fettes atau Oxford University?\"],\n",
    "    'answer': [\"ogilvy tidak bisa kuliah di fettes atau oxford university karena bisnis ayahnya terkena dampak depresi pertengahan dekade 1920-an.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "9ef75ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fe...</td>\n",
       "      <td>Apa alasan Ogilvy tidak bisa kuliah di Fettes ...</td>\n",
       "      <td>ogilvy tidak bisa kuliah di fettes atau oxford...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fe...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Apa alasan Ogilvy tidak bisa kuliah di Fettes ...   \n",
       "\n",
       "                                              answer  \n",
       "0  ogilvy tidak bisa kuliah di fettes atau oxford...  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_debug = pd.DataFrame(data)\n",
    "data_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83072dc4",
   "metadata": {},
   "source": [
    "## Convert context pair to premise (only renaming column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "a1562622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming it, just for consistency\n",
    "\n",
    "#data_nli_train_df = data_nli_train_df.rename(columns={\"context\": \"premise\"})\n",
    "#data_nli_val_df = data_nli_val_df.rename(columns={\"context\": \"premise\"})\n",
    "#data_nli_test_df = data_nli_test_df.rename(columns={\"context\": \"premise\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a09ab26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_debug = data_debug.rename(columns={\"context\": \"premise\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33986ce",
   "metadata": {},
   "source": [
    "# Add contradiction label cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095664cc",
   "metadata": {},
   "source": [
    "## Import pipeline to create contradiction cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e8850d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_ner = pipeline(task = TASK_NER_NAME, \n",
    "                     model = MODEL_NER_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_NER_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "e84dda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_chunking = pipeline(task = TASK_CHUNKING_NAME, \n",
    "                     model = MODEL_CHUNKING_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_CHUNKING_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae4a76",
   "metadata": {},
   "source": [
    "## Add NER and chunking tag column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a68f3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code useful for cleaning the data (text)\n",
    "\n",
    "def remove_space_after_number_and_punctuation(text):\n",
    "    pattern = r'(\\d+)\\s*([.,])\\s*(?=\\S|$)'\n",
    "    cleaned_text = re.sub(pattern, r'\\1\\2', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ee495118-61e1-4603-9194-690c0ae737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code useful for tagging the entire premise\n",
    "# with NER and chunking tools\n",
    "\n",
    "def add_premise_tag(data, tag, index, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "    \n",
    "    # If the tools detected nothing, retrieve NO TOKEN DETECTED\n",
    "    if len(tools(data['premise'][index])) == 0:\n",
    "        premise_array.append(\"NO TOKEN DETECTED\")\n",
    "    \n",
    "    # Else if, the tools detected something, retrieve all of the entity and the word associated\n",
    "    else:\n",
    "        for j in tools(data['premise'][index]):\n",
    "            tag_premise = (j['entity_group'], remove_space_after_number_and_punctuation(j['word']))\n",
    "            premise_array.append(tag_premise)\n",
    "\n",
    "    return premise_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8de4a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for clean the text off punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = text.lstrip(string.punctuation)\n",
    "    cleaned_text = cleaned_text.rstrip(string.punctuation)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "2c888804-88ec-4858-ba18-131545ee6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code useful for tagging the entire answer\n",
    "# with NER and chunking tools\n",
    "\n",
    "def add_answer_tag(answer, tag, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "\n",
    "    tag_answer_list = list()\n",
    "    \n",
    "    if tag == \"ner\":\n",
    "        \n",
    "        # If tools in premise detecting some token\n",
    "        \n",
    "        if len(premise_array) != 0:\n",
    "            \n",
    "            for i in premise_array:\n",
    "                \n",
    "                # Extract the label and the word of premise\n",
    "                \n",
    "                label_from_premise_tag = i[0]\n",
    "                word_from_premise_tag = remove_space_after_number_and_punctuation(i[1])\n",
    "\n",
    "                # With assumption, that I do not dividing label when\n",
    "                # there is more than one label in one word answer.\n",
    "                # Instead, I give a NULL.\n",
    "\n",
    "                if word_from_premise_tag.lower() == answer.lower():\n",
    "                    tag_answer = (label_from_premise_tag, word_from_premise_tag)\n",
    "                    break\n",
    "\n",
    "                # Or, I could do this: to reducing NULL label \n",
    "                # with subset of string not really with the entire string.\n",
    "                \n",
    "                elif answer.lower() in word_from_premise_tag or word_from_premise_tag in answer.lower():\n",
    "                    tag_answer = (label_from_premise_tag, answer.lower())\n",
    "                    break\n",
    "                \n",
    "                # Then, if you still do not find the word, NULL given\n",
    "                \n",
    "                else:\n",
    "                    tag_answer = (\"NULL\", answer)\n",
    "            \n",
    "            tag_answer_list.append(tag_answer)\n",
    "\n",
    "        # If tools in premise NOT detecting some token, NULL given\n",
    "        \n",
    "        else:\n",
    "            tag_answer = (\"NULL\", answer)\n",
    "            tag_answer_list.append(tag_answer)\n",
    "    \n",
    "    elif tag == \"chunking\":\n",
    "        \n",
    "        # In chunking, it's slightly different because \n",
    "        # the basic assumption is that there are no NULL chunks,\n",
    "        # so it will capture all the chunk labels.\n",
    "        \n",
    "        retrieved_from_tools = tools(answer)\n",
    "\n",
    "        if len(retrieved_from_tools) != 0:\n",
    "            \n",
    "            for i in retrieved_from_tools:\n",
    "                tag_answer = (i['entity_group'], i['word'])\n",
    "                tag_answer_list.append(tag_answer)\n",
    "        \n",
    "        # So, it rarely going down there\n",
    "        # But, if really going down there\n",
    "        # from basic assumption, there is no NULL in chunking\n",
    "        # We can check subset of the sentence from premise,\n",
    "        # if found, we can take that particular label\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for i in premise_array:\n",
    "                \n",
    "                # Extract the label and the word of premise\n",
    "                \n",
    "                label_from_premise_tag = i[0]\n",
    "                word_from_premise_tag = remove_space_after_number_and_punctuation(i[1])\n",
    "                \n",
    "                # Take label from subset of sentence from premise\n",
    "                \n",
    "                if answer.lower() in word_from_premise_tag:\n",
    "                    tag_answer = (label_from_premise_tag, answer.lower())\n",
    "                    tag_answer_list.append(tag_answer)\n",
    "                    break\n",
    "            \n",
    "            # Use for and then direct else (for-else),\n",
    "            # if for-loop above not getting the break statement\n",
    "            \n",
    "            else:\n",
    "                tag_answer = (\"NULL\", answer)\n",
    "                tag_answer_list.append(tag_answer)\n",
    "        \n",
    "    return tag_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4967bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper code to run\n",
    "# process for add tag to entire premise\n",
    "# and answer\n",
    "\n",
    "def add_ner_and_chunking_all_tag(data):\n",
    "    \n",
    "    data['ner_tag_answer'] = \"\"\n",
    "    data['chunking_tag_answer'] = \"\"\n",
    "    \n",
    "    data['ner_tag_premise'] = \"\"\n",
    "    data['chunking_tag_premise'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "        \n",
    "        ner_premise_array = list()\n",
    "        chunking_premise_array = list()\n",
    "                                                \n",
    "        data['ner_tag_premise'][i] = add_premise_tag(data, \"ner\", i, ner_premise_array)\n",
    "        data['chunking_tag_premise'][i] = add_premise_tag(data, \"chunking\", i, chunking_premise_array)\n",
    "        \n",
    "        data['ner_tag_answer'][i] = add_answer_tag(answer, \"ner\", data['ner_tag_premise'][i])\n",
    "        data['chunking_tag_answer'][i] = add_answer_tag(answer, \"chunking\", data['chunking_tag_premise'][i])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "25cad8f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_nli_train_df = add_ner_and_chunking_all_tag(data_nli_train_df)\n",
    "#data_nli_val_df = add_ner_and_chunking_all_tag(data_nli_val_df)\n",
    "#data_nli_test_df = add_ner_and_chunking_all_tag(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "7dee2bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ner_tag_answer</th>\n",
       "      <th>chunking_tag_answer</th>\n",
       "      <th>ner_tag_premise</th>\n",
       "      <th>chunking_tag_premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fe...</td>\n",
       "      <td>Apa alasan Ogilvy tidak bisa kuliah di Fettes ...</td>\n",
       "      <td>ogilvy tidak bisa kuliah di fettes atau oxford...</td>\n",
       "      <td>[(PERSON, ogilvy tidak bisa kuliah di fettes a...</td>\n",
       "      <td>[(NP, ogilvy), (ADVP, tidak), (VP, bisa kuliah...</td>\n",
       "      <td>[(PERSON, ogilvy), (PLACE, fettes), (PLACE, ox...</td>\n",
       "      <td>[(PP, tanpa), (NP, beasiswa), (NP, ogilvy), (A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fe...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Apa alasan Ogilvy tidak bisa kuliah di Fettes ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  ogilvy tidak bisa kuliah di fettes atau oxford...   \n",
       "\n",
       "                                      ner_tag_answer  \\\n",
       "0  [(PERSON, ogilvy tidak bisa kuliah di fettes a...   \n",
       "\n",
       "                                 chunking_tag_answer  \\\n",
       "0  [(NP, ogilvy), (ADVP, tidak), (VP, bisa kuliah...   \n",
       "\n",
       "                                     ner_tag_premise  \\\n",
       "0  [(PERSON, ogilvy), (PLACE, fettes), (PLACE, ox...   \n",
       "\n",
       "                                chunking_tag_premise  \n",
       "0  [(PP, tanpa), (NP, beasiswa), (NP, ogilvy), (A...  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_debug = add_ner_and_chunking_all_tag(data_debug)\n",
    "data_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49a3e4",
   "metadata": {},
   "source": [
    "# Create wrong answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a0d00a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-multilingual-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# This function useful for sorting the closest distance\n",
    "# by using embedding\n",
    "\n",
    "model_similarity = SentenceTransformer(MODEL_SIMILARITY_NAME)\n",
    "\n",
    "def return_similarity_sorted_array(right_answer, sentence_array, model=model_similarity):\n",
    "    \n",
    "    right_answer = right_answer.lower()\n",
    "    \n",
    "    embedding_right_answer = model.encode([right_answer], convert_to_tensor=True)\n",
    "    embedding_sentence_array = model.encode(sentence_array, convert_to_tensor=True)\n",
    "    \n",
    "    # Using cosine scores to calculate\n",
    "    cosine_scores = util.pytorch_cos_sim(embedding_right_answer, embedding_sentence_array)\n",
    "    \n",
    "    sorted_indices = cosine_scores.argsort(descending=True)[0]\n",
    "    sorted_array = [sentence_array[i] for i in sorted_indices]\n",
    "    \n",
    "    return sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "0a9f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# removing value with hash.\n",
    "# Because, from label-tagging before\n",
    "# Some data have a hash symbol, because\n",
    "# that data was part of a word fragment\n",
    "\n",
    "def remove_values_with_hash(arr):\n",
    "    return [item for item in arr if \"#\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "bf6c62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve stopword from all language\n",
    "\n",
    "response = requests.get(URL_STOPWORD)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    stopword_data = response.json()\n",
    "else:\n",
    "    print(\"Failed to download stopword JSON.\")\n",
    "\n",
    "stopword_data = set([item for sublist in list(stopword_data.values()) for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c043ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just retrieve random word\n",
    "# of entire premise\n",
    "\n",
    "def select_random_word(text, answer, stopword_data=stopword_data):\n",
    "\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "    # Filtering to remove stopword and punctuation\n",
    "    filtered_words = [word for word in words if word not in stopword_data and word not in string.punctuation]\n",
    "    \n",
    "    # If filtered words less than answer\n",
    "    # only take one word as random word\n",
    "    \n",
    "    if len(filtered_words) < len(answer.split()):\n",
    "        random_word = random.choice(filtered_words)\n",
    "    \n",
    "    # But, if filtered words NOT less than answer\n",
    "    # take a same length word as a random word\n",
    "    # with the same order as filtered words\n",
    "    \n",
    "    else:\n",
    "        start_index = random.randint(0, len(filtered_words) - len(answer.split()))\n",
    "        random_word_array = filtered_words[start_index : start_index + len(answer.split())]\n",
    "        random_word = ' '.join(random_word_array)\n",
    "    \n",
    "    return random_word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d682a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for find the same order\n",
    "# of sequence, this function will used in\n",
    "# chunking domain, to classify whether an\n",
    "# answer is word or a sentence\n",
    "\n",
    "def find_order(premise, answer):\n",
    "    \n",
    "    results = []\n",
    "    answer_labels = [item[0] for item in answer]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while i < len(premise):\n",
    "        \n",
    "        if premise[i][0] == answer_labels[0]:\n",
    "            \n",
    "            matching_words = []\n",
    "            \n",
    "            j = 0\n",
    "            \n",
    "            while i + j < len(premise) and j < len(answer_labels) and premise[i + j][0] == answer_labels[j]:\n",
    "                matching_words.append(premise[i + j][1])\n",
    "                j += 1\n",
    "            \n",
    "            if j == len(answer_labels):\n",
    "                results.append(\" \".join(matching_words))\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "76d0afd1-e751-4cb8-ae22-1b7bb10a5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for grouping same tag-label \n",
    "# between answer and word (or sentence) in an entire premise\n",
    "\n",
    "def grouping_same_tag(tag_answers, tag_premises, same_tag_array, tag):\n",
    "    \n",
    "    # In NER, basicly you need to iterate\n",
    "    # to find a same tag-label\n",
    "    \n",
    "    if tag == \"ner\":\n",
    "        \n",
    "        for tag_premise in tag_premises:\n",
    "\n",
    "            label_tag_premise = tag_premise[0]\n",
    "            word_premise = tag_premise[1]\n",
    "\n",
    "            for tag_answer in tag_answers:\n",
    "\n",
    "                label_tag_answer = tag_answer[0]\n",
    "\n",
    "                if label_tag_answer == label_tag_premise:\n",
    "                    same_tag_array.append(word_premise)\n",
    "                    \n",
    "    # In Chunking, slightly different\n",
    "    # you need to find subset for find the same order\n",
    "    # of sequence with find_order() function\n",
    "    \n",
    "    elif tag == \"chunking\":\n",
    "        \n",
    "        matching_words = find_order(tag_premises, tag_answers)\n",
    "        \n",
    "        # If there is a correct order of subset answer to premise, add it word\n",
    "        \n",
    "        if len(matching_words) != 0:\n",
    "            for word in matching_words:\n",
    "                same_tag_array.append(word)\n",
    "\n",
    "    # Still, filter value with hash\n",
    "    \n",
    "    return remove_values_with_hash(same_tag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "598b3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# checking text if only\n",
    "# contain punctuation, no words at all \n",
    "\n",
    "def contains_only_punctuation(text):\n",
    "    return all(char in string.punctuation for char in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "c20d3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# filter overlapping right answer and wrong answer\n",
    "# that provided in plausible answer\n",
    "\n",
    "def filtering_plausible_answer(answer, plausible_answer_array):\n",
    "    \n",
    "    if type(plausible_answer_array) == str: \n",
    "        plausible_answer_array = list([plausible_answer_array])\n",
    "    \n",
    "    answer = answer.lower()\n",
    "    \n",
    "    plausible_answer_array = [item.lower().strip() for item in plausible_answer_array]\n",
    "    plausible_answer_array = [string for string in plausible_answer_array if not contains_only_punctuation(string)]\n",
    "    plausible_answer_array = [remove_punctuation(text) for text in plausible_answer_array]\n",
    "    \n",
    "    final_plausible_answer_array = list()\n",
    "    answer_words = set(remove_punctuation(text) for text in answer.split())\n",
    "    \n",
    "    # For check overlapping answer, using set of word,\n",
    "    # and so, check for intersection\n",
    "    \n",
    "    for plausible_answer in plausible_answer_array:\n",
    "        plausible_answer_words = set(plausible_answer.split())\n",
    "        if not plausible_answer_words.intersection(answer_words):\n",
    "            if not all(word in answer for word in plausible_answer.split()):\n",
    "                final_plausible_answer_array.append(plausible_answer)\n",
    "    \n",
    "    return final_plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ddb26145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# detecting number, date, time\n",
    "# to give plausible answer more\n",
    "# \"make sense\" answer\n",
    "\n",
    "def is_number(input_str):\n",
    "    pattern = r'\\d'\n",
    "    return bool(re.search(pattern, input_str))\n",
    "\n",
    "def is_date(input_str):\n",
    "    pattern = r'\\b\\d{1,2}[/\\s](\\d{1,2}|\\w+)[/\\s]\\d{4}\\b'\n",
    "    return bool(re.search(pattern, input_str))\n",
    "\n",
    "def is_time(input_str):\n",
    "    pattern = r'\\b\\d{1,2}[:.]\\d{2}(:\\d{2})?\\b'\n",
    "    return bool(re.search(pattern, input_str))\n",
    "\n",
    "def check_regex(right_answer, plausible_answer_array):\n",
    "    \n",
    "    if is_date(right_answer):\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if is_date(item)]\n",
    "    \n",
    "    elif is_time(right_answer):\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if is_time(item)]\n",
    "        \n",
    "    elif is_number(right_answer):\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if is_number(item)]\n",
    "        \n",
    "    else:\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if (not is_number(item) or \n",
    "                                                                              not is_date(item) or \n",
    "                                                                              not is_time(item)\n",
    "                                                                             )]\n",
    "    \n",
    "    return plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9dfb4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# overlap checking\n",
    "# after select random word\n",
    "\n",
    "def overlap_checking_with_random_word(premise, right_answer, max_iter=10, word_threshold=3, NO_ANSWER_STATEMENT=NO_ANSWER_STATEMENT):\n",
    "    \n",
    "    # Selecting wrong answer from random word in premise\n",
    "    wrong_answer = select_random_word(premise, right_answer)\n",
    "\n",
    "    # If that random word is overlapping to right answer,\n",
    "    # iterate again until it is not overlap again until reach the max counter\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if len(filtering_plausible_answer(right_answer, wrong_answer)) > 0:\n",
    "            break\n",
    "\n",
    "        # If it still detect overlapped right answer,\n",
    "        # just assign it with NO_ANSWER_STATEMENT.\n",
    "\n",
    "        if counter == max_iter or len(wrong_answer) < word_threshold:\n",
    "            wrong_answer = NO_ANSWER_STATEMENT\n",
    "            break\n",
    "\n",
    "        wrong_answer = select_random_word(premise, right_answer)\n",
    "    \n",
    "    return wrong_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "5369eced-0cee-4d0d-a436-89a97d2af242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# sorting similarity and\n",
    "# to give final wrong answer \n",
    "# and properties\n",
    "\n",
    "def return_wrong_and_plausible(data, right_answer, index, tag, plausible_answer_array, premise,\n",
    "                       NO_ANSWER_STATEMENT=NO_ANSWER_STATEMENT):\n",
    "\n",
    "    if tag == \"ner\": slice = 'same_ner_tag_answer'\n",
    "    elif tag == \"chunking\": slice = 'same_chunking_tag_answer'\n",
    "    \n",
    "    # Find all the sorted (by similarity) plausible wrong answer, \n",
    "    # and remove hask & punctuation only answer\n",
    "    \n",
    "    if slice != None:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, data[slice][index])\n",
    "    \n",
    "    # Below, do the filtering to plausible answer\n",
    "\n",
    "    plausible_answer_array = remove_values_with_hash(wrong_answer_array)\n",
    "    plausible_answer_array = filtering_plausible_answer(right_answer, plausible_answer_array)\n",
    "    plausible_answer_array = check_regex(right_answer, plausible_answer_array)\n",
    "\n",
    "    if len(plausible_answer_array) > 0:\n",
    "        \n",
    "        # Only return the most similar to right_answer\n",
    "        wrong_answer = plausible_answer_array[0].strip()\n",
    "        \n",
    "        if tag == \"ner\": \n",
    "            properties = \"IDENTICAL NER labels were found, and the highest similarity score same NER array was selected\"\n",
    "        \n",
    "        elif tag == \"chunking\":\n",
    "            properties = \"IDENTICAL Chunking labels were found, and the highest similarity score from same Chunking array was selected\"\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Return wrong answer from random word in premise with overlap checking\n",
    "        wrong_answer = overlap_checking_with_random_word(premise, right_answer)\n",
    "        \n",
    "        if tag == \"ner\": \n",
    "            properties = \"Detected (NER) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "        \n",
    "        elif tag == \"chunking\":\n",
    "            properties = \"Detected (Chunking) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "    \n",
    "    # Still need to check/assert the wrong answer\n",
    "    # and the plausible answer type\n",
    "    \n",
    "    assert isinstance(wrong_answer, str)\n",
    "    assert isinstance(plausible_answer_array, list)\n",
    "    \n",
    "    return wrong_answer, plausible_answer_array, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "20cab74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# matching regex in the first\n",
    "# section on create wrong answer\n",
    "# to detect: number, date, and time\n",
    "\n",
    "def matching_regex(right_answer, chunking_tag_premise):\n",
    "    \n",
    "    plausible_answer_array = []\n",
    "\n",
    "    for _, word in chunking_tag_premise:\n",
    "        \n",
    "        word = remove_punctuation(word)\n",
    "        right_answer = remove_punctuation(right_answer)\n",
    "        \n",
    "        if (word != right_answer) and (word not in right_answer):\n",
    "\n",
    "            if is_date(word) and is_date(right_answer):\n",
    "                plausible_answer_array.append(word)\n",
    "\n",
    "            if is_time(word) and is_time(right_answer):\n",
    "                plausible_answer_array.append(word)\n",
    "                \n",
    "            if is_number(word) and is_number(right_answer):\n",
    "                plausible_answer_array.append(word)\n",
    "\n",
    "    return plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "a2f689e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# cleaning the reference off the premise\n",
    "\n",
    "def cleaning_premise(premise):\n",
    "    cleaned_premise = re.sub(r'\\[.*?\\]', '', premise)\n",
    "    cleaned_premise = re.sub(r'jmpl\\|200px\\|', '', cleaned_premise)\n",
    "    return cleaned_premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "97759144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is the main idea to create wrong answer\n",
    "# Though, this function is helper function\n",
    "\n",
    "def create_wrong_answer(data, NO_ANSWER_STATEMENT=NO_ANSWER_STATEMENT):\n",
    "    \n",
    "    data['same_ner_tag_answer'] = \"\"\n",
    "    data['same_chunking_tag_answer'] = \"\"\n",
    "    data['wrong_answer'] = \"\"\n",
    "    data['no_answer'] = \"\"\n",
    "    data['plausible_answer_based_on_method'] = \"\"\n",
    "    data['properties'] = \"\"\n",
    "    \n",
    "    #print(\"FOR A DEBUG PUPROSE\")\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        #print(f\"Iteration: {i}\")\n",
    "        #print(f\"Premise: {data['premise'][i]}\")\n",
    "        #print(f\"Question: {data['question'][i]}\")\n",
    "        #print(f\"Right answer: {data['answer'][i]}\")\n",
    "        \n",
    "        right_answer = data['answer'][i]\n",
    "        premise = cleaning_premise(data['premise'][i])\n",
    "\n",
    "        same_ner_tag_answer_array = list()\n",
    "        same_chunking_tag_answer_array = list()\n",
    "\n",
    "        ner_tag_answer = data['ner_tag_answer'][i]\n",
    "        ner_tag_premise = data['ner_tag_premise'][i]\n",
    "\n",
    "        chunking_tag_answer = data['chunking_tag_answer'][i]\n",
    "        chunking_tag_premise = data['chunking_tag_premise'][i]\n",
    "        \n",
    "        # If that row of data is unanswerable, do this, then continue\n",
    "        \n",
    "        if right_answer == \"\":\n",
    "            data['properties'][i] = \"Unanswerable question\"\n",
    "            data['wrong_answer'][i] = \"NULL\"\n",
    "            data['no_answer'][i] = \"NULL\"\n",
    "            data['plausible_answer_based_on_method'][i] = \"Unanswerable question\"\n",
    "            continue\n",
    "            \n",
    "        # Grouped with the same NER & Chunking group, between answer and word of premise\n",
    "        \n",
    "        data['same_ner_tag_answer'][i] = grouping_same_tag(ner_tag_answer,\n",
    "                                                           ner_tag_premise,\n",
    "                                                           same_ner_tag_answer_array, \"ner\")\n",
    "        \n",
    "        data['same_chunking_tag_answer'][i] = grouping_same_tag(chunking_tag_answer, \n",
    "                                                                chunking_tag_premise, \n",
    "                                                                same_chunking_tag_answer_array, \"chunking\")\n",
    "        \n",
    "        # Start to create wrong answer\n",
    "        plausible_answer_array = list()\n",
    "        \n",
    "        # Firstly, matching regex\n",
    "        if is_number(right_answer) or is_date(right_answer) or is_time(right_answer):\n",
    "            \n",
    "            plausible_answer_array = matching_regex(right_answer, chunking_tag_premise)\n",
    "            plausible_answer_array = filtering_plausible_answer(right_answer, plausible_answer_array)\n",
    "            \n",
    "            if len(plausible_answer_array) > 0:\n",
    "                plausible_answer_array = return_similarity_sorted_array(right_answer, plausible_answer_array)\n",
    "                wrong_answer = plausible_answer_array[0].strip()\n",
    "                data['properties'][i] = \"Regex matched with right answer, and get alternative answer\"\n",
    "            \n",
    "            else:\n",
    "                wrong_answer = NO_ANSWER_STATEMENT\n",
    "                data['properties'][i] = \"Regex matched with right answer, but no alternative answer\"\n",
    "            \n",
    "            data['wrong_answer'][i] = wrong_answer\n",
    "            data['no_answer'][i] = NO_ANSWER_STATEMENT\n",
    "            data['plausible_answer_based_on_method'][i] = list(set(plausible_answer_array))\n",
    "            continue\n",
    "\n",
    "        # Perform NER classification\n",
    "        # If the NER of the right_answer can be detected, then calculate the distance using semantic \n",
    "        # similarity or word vectors between the right_answer and various possible wrong_answers with \n",
    "        # the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "\n",
    "        if data['same_ner_tag_answer'][i] != list():\n",
    "            wrong_answer, plausible_answer_array, properties = return_wrong_and_plausible(data, right_answer, \\\n",
    "                                                                      i, \"ner\", plausible_answer_array, premise)\n",
    "            \n",
    "        # If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain \n",
    "        # any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "        \n",
    "        # Perform POS/Chunking classification\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # If the POS/Chunking of the right_answer can be detected, then calculate the distance \n",
    "            # using semantic similarity or word vectors between the right_answer and various possible \n",
    "            # wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the \n",
    "            # final wrong_answer.\n",
    "            \n",
    "            if data['same_chunking_tag_answer'][i] != list():\n",
    "                wrong_answer, plausible_answer_array, properties = return_wrong_and_plausible(data, right_answer, \\\n",
    "                                                                          i, \"chunking\", plausible_answer_array, premise)\n",
    "            \n",
    "            # If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise \n",
    "            # does not contain any of NER of right_answer, then the final wrong_answer will be chosen \n",
    "            # selected random word from premise.\n",
    "            \n",
    "            else:\n",
    "                properties = \"No same tag detected, search random word from premise\"\n",
    "                wrong_answer = overlap_checking_with_random_word(premise, right_answer)\n",
    "                plausible_answer_array = list()\n",
    "        \n",
    "        data['properties'][i] = properties\n",
    "        data['wrong_answer'][i] = wrong_answer\n",
    "        data['no_answer'][i] = NO_ANSWER_STATEMENT\n",
    "        data['plausible_answer_based_on_method'][i] = list(set(plausible_answer_array))\n",
    "            \n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "efed3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_nli_train_df = create_wrong_answer(data_nli_train_df)\n",
    "#data_nli_val_df = create_wrong_answer(data_nli_val_df)\n",
    "#data_nli_test_df = create_wrong_answer(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e50ad7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95609d16130348f78969c9307b69aab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a845c35648934b35affc4e5d00cb771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ner_tag_answer</th>\n",
       "      <th>chunking_tag_answer</th>\n",
       "      <th>ner_tag_premise</th>\n",
       "      <th>chunking_tag_premise</th>\n",
       "      <th>same_ner_tag_answer</th>\n",
       "      <th>same_chunking_tag_answer</th>\n",
       "      <th>wrong_answer</th>\n",
       "      <th>no_answer</th>\n",
       "      <th>plausible_answer_based_on_method</th>\n",
       "      <th>properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fe...</td>\n",
       "      <td>Apa alasan Ogilvy tidak bisa kuliah di Fettes ...</td>\n",
       "      <td>ogilvy tidak bisa kuliah di fettes atau oxford...</td>\n",
       "      <td>[(PERSON, ogilvy tidak bisa kuliah di fettes a...</td>\n",
       "      <td>[(NP, ogilvy), (ADVP, tidak), (VP, bisa kuliah...</td>\n",
       "      <td>[(PERSON, ogilvy), (PLACE, fettes), (PLACE, ox...</td>\n",
       "      <td>[(PP, tanpa), (NP, beasiswa), (NP, ogilvy), (A...</td>\n",
       "      <td>[ogilvy]</td>\n",
       "      <td>[ogilvy tidak bisa kuliah di fettes atau oxfor...</td>\n",
       "      <td>tahun 1931</td>\n",
       "      <td>Tidak ada jawaban</td>\n",
       "      <td>[tahun 1931]</td>\n",
       "      <td>Regex matched with right answer, and get alter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Tanpa beasiswa, Ogilvy tidak bisa kuliah di Fe...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Apa alasan Ogilvy tidak bisa kuliah di Fettes ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  ogilvy tidak bisa kuliah di fettes atau oxford...   \n",
       "\n",
       "                                      ner_tag_answer  \\\n",
       "0  [(PERSON, ogilvy tidak bisa kuliah di fettes a...   \n",
       "\n",
       "                                 chunking_tag_answer  \\\n",
       "0  [(NP, ogilvy), (ADVP, tidak), (VP, bisa kuliah...   \n",
       "\n",
       "                                     ner_tag_premise  \\\n",
       "0  [(PERSON, ogilvy), (PLACE, fettes), (PLACE, ox...   \n",
       "\n",
       "                                chunking_tag_premise same_ner_tag_answer  \\\n",
       "0  [(PP, tanpa), (NP, beasiswa), (NP, ogilvy), (A...            [ogilvy]   \n",
       "\n",
       "                            same_chunking_tag_answer wrong_answer  \\\n",
       "0  [ogilvy tidak bisa kuliah di fettes atau oxfor...   tahun 1931   \n",
       "\n",
       "           no_answer plausible_answer_based_on_method  \\\n",
       "0  Tidak ada jawaban                     [tahun 1931]   \n",
       "\n",
       "                                          properties  \n",
       "0  Regex matched with right answer, and get alter...  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_debug = create_wrong_answer(data_debug)\n",
    "data_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "fbae5ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_number(\"ogilvy tidak bisa kuliah di fettes atau oxford university karena bisnis ayahnya terkena dampak depresi pertengahan dekade 1920-an.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "99c842fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right answer: ogilvy tidak bisa kuliah di fettes atau oxford university karena bisnis ayahnya terkena dampak depresi pertengahan dekade 1920-an.\n",
      "\n",
      "['tahun 1931']\n",
      "Wrong answer: tahun 1931\n"
     ]
    }
   ],
   "source": [
    "print(\"Right answer:\", data_debug['answer'][0])\n",
    "print()\n",
    "print(data_debug['plausible_answer_based_on_method'][0])\n",
    "print(\"Wrong answer:\", data_debug['wrong_answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "878ffec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: Masjid Tua Palopo merupakan masjid peninggalan Kerajaan Luwu yang berlokasi di kota Palopo, Sulawesi Selatan. Masjid ini didirikan oleh Raja Luwu yang bernama Datu Payung Luwu XVI Pati Pasaung Toampanangi Sultan Abdullah Matinroe pada tahun 1604 M. Masjid yang memiliki luas 15 m² ini diberi nama Tua, karena usianya yang sudah tua. Sedangkan nama Palopo diambil dari kata dalam bahasa Bugis dan Luwu yang memiliki dua arti, yaitu: pertama, penganan yang terbuat dari campuran nasi ketan dan air gula; kedua, memasukkan pasak dalam lubang tiang bangunan. Kedua makna ini memiliki relasi dengan proses pembangunan Masjid Tua Palopo ini.[1]\n",
      "Question: berapakah luas  Masjid Tua Palopo?\n",
      "\n",
      "[('PLACE', 'masjid tua palopo'), ('PLACE', 'luwu'), ('PLACE', 'kota palopo'), ('PLACE', 'sulawesi selatan'), ('PLACE', 'luwu'), ('PLACE', 'datu payung luwu'), ('PERSON', 'abdullah matinroe'), ('PLACE', 'palopo'), ('PLACE', 'bugis'), ('PLACE', 'luwu'), ('PLACE', 'masjid tua palopo')]\n",
      "[('NP', 'masjid tua palopo'), ('VP', 'merupakan'), ('NP', 'masjid peninggalan kerajaan luwu'), ('SBAR', 'yang'), ('VP', 'berlokasi'), ('PP', 'di'), ('NP', 'kota palopo, sulawesi selatan'), ('NP', 'masjid ini'), ('VP', 'didirikan'), ('PP', 'oleh'), ('NP', 'raja luwu'), ('SBAR', 'yang'), ('VP', 'bernama'), ('NP', 'datu payung luwu xvi pati pasaung toampanangi'), ('NP', 'sultan abdullah matinroe'), ('PP', 'pada'), ('NP', 'tahun 1604 m'), ('NP', 'masjid'), ('SBAR', 'yang'), ('VP', 'memiliki'), ('NP', 'luas 15 m² ini'), ('VP', 'diberi'), ('NP', 'nama'), ('ADJP', 'tua'), ('VP', ','), ('PP', 'karena'), ('NP', 'usianya'), ('SBAR', 'yang'), ('ADVP', 'sudah'), ('ADJP', 'tua'), ('NP', 'nama palopo'), ('VP', 'diambil'), ('PP', 'dari'), ('NP', 'kata'), ('PP', 'dalam'), ('NP', 'bahasa bugis dan luwu'), ('SBAR', 'yang'), ('VP', 'memiliki'), ('NP', 'dua arti,'), ('SBAR', 'yaitu'), ('VP', ':'), ('NP', 'pertama,'), ('NP', 'penganan'), ('SBAR', 'yang'), ('VP', 'terbuat'), ('PP', 'dari'), ('NP', 'campuran nasi ketan dan air gula ; kedua'), ('VP', ', memasukkan'), ('NP', 'pasak'), ('PP', 'dalam'), ('NP', 'lubang tiang bangunan'), ('NP', 'kedua makna ini'), ('VP', 'memiliki'), ('NP', 'relasi'), ('PP', 'dengan'), ('NP', 'proses pembangunan masjid tua palopo ini')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Premise:\", data_debug['premise'][0])\n",
    "print(\"Question:\", data_debug['question'][0])\n",
    "print()\n",
    "print(data_debug['ner_tag_premise'][0])\n",
    "print(data_debug['chunking_tag_premise'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe61c82",
   "metadata": {},
   "source": [
    "# Split to two dataset: right dataset & wrong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is just only\n",
    "# for aesthetics of column number\n",
    "\n",
    "def move_to_column_number(data, column_name=\"hypothesis\", column_num=3):\n",
    "\n",
    "    cols = list(data.columns)\n",
    "    cols.remove(column_name)\n",
    "    cols.insert(column_num, column_name)\n",
    "\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56880d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating answerable right (entailment label) dataset\n",
    "\n",
    "columns_to_exclude = ['wrong_answer', 'no_answer']\n",
    "\n",
    "data_nli_answerable_right_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_right_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_right_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_answerable_right_train_df = data_nli_answerable_right_train_df[data_nli_answerable_right_train_df['answer'] != '']\n",
    "data_nli_answerable_right_val_df = data_nli_answerable_right_val_df[data_nli_answerable_right_val_df['answer'] != '']\n",
    "data_nli_answerable_right_test_df = data_nli_answerable_right_test_df[data_nli_answerable_right_test_df['answer'] != '']\n",
    "\n",
    "data_nli_answerable_right_train_df = data_nli_answerable_right_train_df.reset_index(drop=True)\n",
    "data_nli_answerable_right_val_df = data_nli_answerable_right_val_df.reset_index(drop=True)\n",
    "data_nli_answerable_right_test_df = data_nli_answerable_right_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating answerable wrong (contradiction label) dataset\n",
    "\n",
    "columns_to_exclude = ['answer', 'no_answer']\n",
    "\n",
    "data_nli_answerable_wrong_train_df = data_nli_train_df[data_nli_train_df['answer'] != '']\n",
    "data_nli_answerable_wrong_val_df = data_nli_val_df[data_nli_val_df['answer'] != '']\n",
    "data_nli_answerable_wrong_test_df = data_nli_test_df[data_nli_test_df['answer'] != '']\n",
    "\n",
    "data_nli_answerable_wrong_train_df = data_nli_answerable_wrong_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_wrong_val_df = data_nli_answerable_wrong_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_wrong_test_df = data_nli_answerable_wrong_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_answerable_wrong_train_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_answerable_wrong_val_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_answerable_wrong_test_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "\n",
    "data_nli_answerable_wrong_train_df = data_nli_answerable_wrong_train_df.reset_index(drop=True)\n",
    "data_nli_answerable_wrong_val_df = data_nli_answerable_wrong_val_df.reset_index(drop=True)\n",
    "data_nli_answerable_wrong_test_df = data_nli_answerable_wrong_test_df.reset_index(drop=True)\n",
    "\n",
    "data_nli_answerable_wrong_train_df = move_to_column_number(data_nli_answerable_wrong_train_df, \"answer\", 2)\n",
    "data_nli_answerable_wrong_val_df = move_to_column_number(data_nli_answerable_wrong_val_df, \"answer\", 2)\n",
    "data_nli_answerable_wrong_test_df = move_to_column_number(data_nli_answerable_wrong_test_df, \"answer\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating unanswerable right (entailment label) and no-answer dataset\n",
    "\n",
    "columns_to_exclude = ['wrong_answer', 'no_answer']\n",
    "\n",
    "data_nli_unanswerable_right_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_right_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_right_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_unanswerable_right_train_df = data_nli_unanswerable_right_train_df[data_nli_unanswerable_right_train_df['answer'] == '']\n",
    "data_nli_unanswerable_right_val_df = data_nli_unanswerable_right_val_df[data_nli_unanswerable_right_val_df['answer'] == '']\n",
    "data_nli_unanswerable_right_test_df = data_nli_unanswerable_right_test_df[data_nli_unanswerable_right_test_df['answer'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5df327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating unanswerable wrong (contradiction label) and no-answer dataset\n",
    "\n",
    "columns_to_exclude = ['answer', 'wrong_answer']\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_train_df[data_nli_train_df['answer'] != '']\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_val_df[data_nli_val_df['answer'] != '']\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_test_df[data_nli_test_df['answer'] != '']\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_unanswerable_wrong_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_unanswerable_wrong_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_unanswerable_wrong_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df.rename(columns={'no_answer': 'answer'}, inplace=True)\n",
    "data_nli_unanswerable_wrong_val_df.rename(columns={'no_answer': 'answer'}, inplace=True)\n",
    "data_nli_unanswerable_wrong_test_df.rename(columns={'no_answer': 'answer'}, inplace=True)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = move_to_column_number(data_nli_unanswerable_wrong_train_df, \"answer\", 2)\n",
    "data_nli_unanswerable_wrong_val_df = move_to_column_number(data_nli_unanswerable_wrong_val_df, \"answer\", 2)\n",
    "data_nli_unanswerable_wrong_test_df = move_to_column_number(data_nli_unanswerable_wrong_test_df, \"answer\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than duplicating the no-answer statement, \n",
    "# it's better to remove the excessing row ones.\n",
    "\n",
    "def balancing_data(data1, data2):\n",
    "    \n",
    "    if len(data1) > len(data2):\n",
    "        data1 = data1.sample(n=len(data2))\n",
    "    \n",
    "    elif len(data1) < len(data2):\n",
    "        data2 = data2.sample(n=len(data1))\n",
    "        \n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312fdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_right_train_df, data_nli_unanswerable_wrong_train_df = balancing_data(data_nli_unanswerable_right_train_df,\n",
    "                                                                                            data_nli_unanswerable_wrong_train_df)\n",
    "\n",
    "data_nli_unanswerable_right_val_df, data_nli_unanswerable_wrong_val_df = balancing_data(data_nli_unanswerable_right_val_df,\n",
    "                                                                                        data_nli_unanswerable_wrong_val_df)\n",
    "\n",
    "data_nli_unanswerable_right_test_df, data_nli_unanswerable_wrong_test_df = balancing_data(data_nli_unanswerable_right_test_df,\n",
    "                                                                                        data_nli_unanswerable_wrong_test_df)\n",
    "\n",
    "# Still need to reset index of DataFrame\n",
    "\n",
    "data_nli_unanswerable_right_train_df = data_nli_unanswerable_right_train_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_right_val_df = data_nli_unanswerable_right_val_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_right_test_df = data_nli_unanswerable_right_test_df.reset_index(drop=True)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_unanswerable_wrong_train_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_unanswerable_wrong_val_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_unanswerable_wrong_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debug purpose\n",
    "\n",
    "print(\"ENTAILMENT ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_answerable_right_train_df))\n",
    "print(\"VAL:\", len(data_nli_answerable_right_val_df))\n",
    "print(\"TEST:\", len(data_nli_answerable_right_test_df))\n",
    "print()\n",
    "\n",
    "print(\"CONTRADICTION ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_answerable_wrong_train_df))\n",
    "print(\"VAL:\", len(data_nli_answerable_wrong_val_df))\n",
    "print(\"TEST:\", len(data_nli_answerable_wrong_test_df))\n",
    "print()\n",
    "\n",
    "print(\"ENTAILMENT UN-ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_unanswerable_right_train_df))\n",
    "print(\"VAL:\", len(data_nli_unanswerable_right_val_df))\n",
    "print(\"TEST:\", len(data_nli_unanswerable_right_test_df))\n",
    "print()\n",
    "\n",
    "print(\"CONTRADICTION UN-ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_unanswerable_wrong_train_df))\n",
    "print(\"VAL:\", len(data_nli_unanswerable_wrong_val_df))\n",
    "print(\"TEST:\", len(data_nli_unanswerable_wrong_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6f08",
   "metadata": {},
   "source": [
    "# Convert question-answer pair to hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we can try this approach\n",
    "\n",
    "#nlp_tools_paraphraser = pipeline(task = TASK_PARAPHRASER_NAME, \n",
    "#                     model = MODEL_PARAPHRASER_NAME, \n",
    "#                     tokenizer = AutoTokenizer.from_pretrained(MODEL_PARAPHRASER_NAME, \n",
    "#                                                               model_max_length=512, \n",
    "#                                                               truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function useful for\n",
    "# retrieve hypothesis from\n",
    "# question and answer\n",
    "\n",
    "def convert_question_and_answer_to_hypothesis(data, NO_ANSWER_STATEMENT=NO_ANSWER_STATEMENT):\n",
    "    \n",
    "    data['hypothesis'] = \"\"\n",
    "    hypothesis_array = list()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if data['answer'][i] != \"\" and type(data['answer'][i]) == str:\n",
    "            hypothesis_array.append(data['question'][i] + ' ' + data['answer'][i])\n",
    "        else:\n",
    "            hypothesis_array.append(data['question'][i] + ' ' + NO_ANSWER_STATEMENT)\n",
    "        \n",
    "        # Use this to decline no-answer-warning properties\n",
    "        #hypothesis_array.append(data['question'][i] + ' ' + data['answer'][i])\n",
    "        \n",
    "        # Use this to use paraphraser\n",
    "        #hypothesis_array.append(str(nlp_tools_paraphraser(data['question'][i] + ' ' + data['answer'][i])[0]['generated_text']))\n",
    "    \n",
    "    data['hypothesis'] = hypothesis_array\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf340e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_right_train_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_right_train_df)\n",
    "data_nli_answerable_right_val_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_right_val_df)\n",
    "data_nli_answerable_right_test_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_right_test_df)\n",
    "\n",
    "data_nli_answerable_right_train_df = move_to_column_number(data_nli_answerable_right_train_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_right_val_df = move_to_column_number(data_nli_answerable_right_val_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_right_test_df = move_to_column_number(data_nli_answerable_right_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20241aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_wrong_train_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_wrong_train_df)\n",
    "data_nli_answerable_wrong_val_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_wrong_val_df)\n",
    "data_nli_answerable_wrong_test_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_wrong_test_df)\n",
    "\n",
    "data_nli_answerable_wrong_train_df = move_to_column_number(data_nli_answerable_wrong_train_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_wrong_val_df = move_to_column_number(data_nli_answerable_wrong_val_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_wrong_test_df = move_to_column_number(data_nli_answerable_wrong_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_right_train_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_right_train_df)\n",
    "data_nli_unanswerable_right_val_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_right_val_df)\n",
    "data_nli_unanswerable_right_test_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_right_test_df)\n",
    "\n",
    "data_nli_unanswerable_right_train_df = move_to_column_number(data_nli_unanswerable_right_train_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_right_val_df = move_to_column_number(data_nli_unanswerable_right_val_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_right_test_df = move_to_column_number(data_nli_unanswerable_right_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d28ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_wrong_train_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_wrong_train_df)\n",
    "data_nli_unanswerable_wrong_val_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_wrong_val_df)\n",
    "data_nli_unanswerable_wrong_test_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_wrong_test_df)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = move_to_column_number(data_nli_unanswerable_wrong_train_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_wrong_val_df = move_to_column_number(data_nli_unanswerable_wrong_val_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_wrong_test_df = move_to_column_number(data_nli_unanswerable_wrong_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c4ace",
   "metadata": {},
   "source": [
    "# Assign the label: entailment & contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_right_train_df['label'] = 'entailment'\n",
    "data_nli_answerable_right_val_df['label'] = 'entailment'\n",
    "data_nli_answerable_right_test_df['label'] = 'entailment'\n",
    "\n",
    "data_nli_answerable_right_train_df = move_to_column_number(data_nli_answerable_right_train_df, \"label\", 4)\n",
    "data_nli_answerable_right_val_df = move_to_column_number(data_nli_answerable_right_val_df, \"label\", 4)\n",
    "data_nli_answerable_right_test_df = move_to_column_number(data_nli_answerable_right_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02098578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_wrong_train_df['label'] = 'contradiction'\n",
    "data_nli_answerable_wrong_val_df['label'] = 'contradiction'\n",
    "data_nli_answerable_wrong_test_df['label'] = 'contradiction'\n",
    "\n",
    "data_nli_answerable_wrong_train_df = move_to_column_number(data_nli_answerable_wrong_train_df, \"label\", 4)\n",
    "data_nli_answerable_wrong_val_df = move_to_column_number(data_nli_answerable_wrong_val_df, \"label\", 4)\n",
    "data_nli_answerable_wrong_test_df = move_to_column_number(data_nli_answerable_wrong_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ebcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_right_train_df['label'] = 'entailment'\n",
    "data_nli_unanswerable_right_val_df['label'] = 'entailment'\n",
    "data_nli_unanswerable_right_test_df['label'] = 'entailment'\n",
    "\n",
    "data_nli_unanswerable_right_train_df = move_to_column_number(data_nli_unanswerable_right_train_df, \"label\", 4)\n",
    "data_nli_unanswerable_right_val_df = move_to_column_number(data_nli_unanswerable_right_val_df, \"label\", 4)\n",
    "data_nli_unanswerable_right_test_df = move_to_column_number(data_nli_unanswerable_right_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_wrong_train_df['label'] = 'contradiction'\n",
    "data_nli_unanswerable_wrong_val_df['label'] = 'contradiction'\n",
    "data_nli_unanswerable_wrong_test_df['label'] = 'contradiction'\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = move_to_column_number(data_nli_unanswerable_wrong_train_df, \"label\", 4)\n",
    "data_nli_unanswerable_wrong_val_df = move_to_column_number(data_nli_unanswerable_wrong_val_df, \"label\", 4)\n",
    "data_nli_unanswerable_wrong_test_df = move_to_column_number(data_nli_unanswerable_wrong_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f431144",
   "metadata": {},
   "source": [
    "# Concat the right and wrong NLI to one NLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final = pd.concat([data_nli_answerable_right_train_df, \n",
    "                                     data_nli_answerable_wrong_train_df,\n",
    "                                     data_nli_unanswerable_right_train_df,\n",
    "                                     data_nli_unanswerable_wrong_train_df], axis=0, ignore_index=True)\n",
    "\n",
    "data_nli_val_df_final = pd.concat([data_nli_answerable_right_val_df, \n",
    "                                   data_nli_answerable_wrong_val_df,\n",
    "                                   data_nli_unanswerable_right_val_df,\n",
    "                                   data_nli_unanswerable_wrong_val_df], axis=0, ignore_index=True)\n",
    "\n",
    "data_nli_test_df_final = pd.concat([data_nli_answerable_right_test_df, \n",
    "                                    data_nli_answerable_wrong_test_df,\n",
    "                                    data_nli_unanswerable_right_test_df,\n",
    "                                    data_nli_unanswerable_wrong_test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a980a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debug purpose,\n",
    "# you can modify it too\n",
    "\n",
    "def debug_data(data):\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        print(f\"Iteration: {i}\")\n",
    "        print(f\"Answer: {data['answer'][i]}\")\n",
    "        \n",
    "        print(\"NER\")\n",
    "        print(data['ner_tag_answer'][i])\n",
    "        print(data['ner_tag_premise'][i])\n",
    "        \n",
    "        print(\"Chunking\")\n",
    "        print(data['chunking_tag_answer'][i])\n",
    "        print(data['chunking_tag_premise'][i])\n",
    "        print()\n",
    "\n",
    "# debug_data(data_nli_train_df_final)\n",
    "# debug_data(data_nli_val_df_final)\n",
    "# debug_data(data_nli_test_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debug purpose\n",
    "\n",
    "print(\"TRAIN FINAL\")\n",
    "print(len(data_nli_train_df_final))\n",
    "print()\n",
    "\n",
    "print(\"VAL FINAL\")\n",
    "print(len(data_nli_val_df_final))\n",
    "print()\n",
    "\n",
    "print(\"TEST FINAL\")\n",
    "print(len(data_nli_test_df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea9097",
   "metadata": {},
   "source": [
    "# Convert to DataFrame format to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final.to_csv(f\"{NAME}_nli_train_df.csv\", index=False)\n",
    "data_nli_val_df_final.to_csv(f\"{NAME}_nli_val_df.csv\", index=False)\n",
    "data_nli_test_df_final.to_csv(f\"{NAME}_nli_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PROGRAM FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4a255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
