{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9171daa4",
   "metadata": {},
   "source": [
    "# Define tool and model of the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a063a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 25 15:14:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   245W / 300W |  32501MiB / 32510MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   50C    P0   125W / 300W |  26022MiB / 32510MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   48C    P0   117W / 300W |  24006MiB / 32510MiB |     92%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   43C    P0   116W / 300W |  25842MiB / 32510MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    60W / 300W |    730MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    44W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    40W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41849a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "NAME = \"idk-mrc\"\n",
    "NO_ANSWER_STATEMENT = \"Tidak ada jawaban\"\n",
    "\n",
    "TASK_NER_NAME = \"ner\"\n",
    "MODEL_NER_NAME = \"ageng-anugrah/indobert-large-p2-finetuned-ner\"\n",
    "\n",
    "TASK_CHUNKING_NAME = \"token-classification\"\n",
    "MODEL_CHUNKING_NAME = \"ageng-anugrah/indobert-large-p2-finetuned-chunking\"\n",
    "\n",
    "MODEL_SIMILARITY_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "URL_STOPWORD = \"https://raw.githubusercontent.com/6/stopwords-json/master/stopwords-all.json\"\n",
    "\n",
    "TASK_PARAPHRASER_NAME = \"text2text-generation\"\n",
    "MODEL_PARAPHRASER_NAME = \"\"\n",
    "\n",
    "# SAMPLE = sys.maxsize\n",
    "SAMPLE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9fdd4",
   "metadata": {},
   "source": [
    "# Import anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26d313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import string\n",
    "import contextlib\n",
    "import gc\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from evaluate import load\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "from datetime import datetime\n",
    "from huggingface_hub import notebook_login\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import HfApi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    Dataset,\n",
    "    DatasetDict\n",
    ")\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback, \n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cd27c",
   "metadata": {},
   "source": [
    "# Retrieve QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f426d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRAM STARTED\n"
     ]
    }
   ],
   "source": [
    "print(\"PROGRAM STARTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafbf0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset idk_mrc (/root/.cache/huggingface/datasets/idk_mrc/idk_mrc_source/1.0.0/cf468d86fa7341e69998db1449851672ebfb4fa46036929d66b9de15c421334f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46645dc3489f4566ad274606a4bd03e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3659/3659 [00:16<00:00, 225.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 358/358 [00:01<00:00, 281.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 378/378 [00:01<00:00, 269.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 9332\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 764\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "data_qas = conhelps.filtered(lambda x: 'idk_mrc' in x.dataset_name)[0].load_dataset()\n",
    "\n",
    "df_train = pd.DataFrame(data_qas['train'])\n",
    "df_validation = pd.DataFrame(data_qas['validation'])\n",
    "df_test = pd.DataFrame(data_qas['test'])\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_train['context']))):\n",
    "    for j in df_train[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                           \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                           \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                           ignore_index=True)\n",
    "        else:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": str(), \n",
    "                                                           \"answer_start\": 0, \n",
    "                                                           \"answer_end\": 0}}, \n",
    "                                                           ignore_index=True)\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_val = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_validation['context']))):\n",
    "    for j in df_validation[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)        \n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_test = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_test['context']))):\n",
    "    for j in df_test[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict(new_df_train)\n",
    "validation_dataset = Dataset.from_dict(new_df_val)\n",
    "test_dataset = Dataset.from_dict(new_df_test)\n",
    "\n",
    "data_qas = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset, \"test\": test_dataset})\n",
    "data_qas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae908a",
   "metadata": {},
   "source": [
    "# Convert to NLI, with hypothesis being just do concat question & answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c79ac",
   "metadata": {},
   "source": [
    "## Convert Dataset to DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b342b8ce-41f9-4714-84a5-1697cfee1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275dc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE == sys.maxsize:\n",
    "    data_qas_train_df = pd.DataFrame(data_qas[\"train\"][:SAMPLE])\n",
    "    data_qas_val_df = pd.DataFrame(data_qas[\"validation\"][:SAMPLE])\n",
    "    data_qas_test_df = pd.DataFrame(data_qas[\"test\"][:SAMPLE])\n",
    "\n",
    "else:\n",
    "    data_qas_train_df = (pd.DataFrame(data_qas[\"train\"])).sample(n=SAMPLE, random_state=42)\n",
    "    data_qas_val_df = (pd.DataFrame(data_qas[\"validation\"])).sample(n=SAMPLE, random_state=42)\n",
    "    data_qas_test_df = (pd.DataFrame(data_qas[\"test\"])).sample(n=SAMPLE, random_state=42)\n",
    "\n",
    "    data_qas_train_df = data_qas_train_df.reset_index(drop=True)\n",
    "    data_qas_val_df = data_qas_val_df.reset_index(drop=True)\n",
    "    data_qas_test_df = data_qas_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bbf0b",
   "metadata": {},
   "source": [
    "## Retrieve answer text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0424485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answer_text(data):\n",
    "    for i in range(len(data)):\n",
    "        data['answer'][i] = data['answer'][i]['text']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b1a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = retrieve_answer_text(data_qas_train_df)\n",
    "data_qas_val_df = retrieve_answer_text(data_qas_val_df)\n",
    "data_qas_test_df = retrieve_answer_text(data_qas_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881d292",
   "metadata": {},
   "source": [
    "## Create NLI dataset from copy of QA dataset above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8808af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_qas_train_df.copy()\n",
    "data_nli_val_df = data_qas_val_df.copy()\n",
    "data_nli_test_df = data_qas_test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83072dc4",
   "metadata": {},
   "source": [
    "## Convert context pair to premise (only renaming column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1562622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_nli_train_df.rename(columns={\"context\": \"premise\"})\n",
    "data_nli_val_df = data_nli_val_df.rename(columns={\"context\": \"premise\"})\n",
    "data_nli_test_df = data_nli_test_df.rename(columns={\"context\": \"premise\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33986ce",
   "metadata": {},
   "source": [
    "# Add contradiction label cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095664cc",
   "metadata": {},
   "source": [
    "## Import pipeline to create contradiction cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8850d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_ner = pipeline(task = TASK_NER_NAME, \n",
    "                     model = MODEL_NER_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_NER_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84dda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_chunking = pipeline(task = TASK_CHUNKING_NAME, \n",
    "                     model = MODEL_CHUNKING_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_CHUNKING_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae4a76",
   "metadata": {},
   "source": [
    "## Add NER and chunking tag column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68f3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space_after_number_and_punctuation(text):\n",
    "    pattern = r'(\\d+)\\s*([.,])\\s*(?=\\S|$)'\n",
    "    cleaned_text = re.sub(pattern, r'\\1\\2', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee495118-61e1-4603-9194-690c0ae737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_premise_tag(data, tag, index, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "    \n",
    "    if len(tools(data['premise'][index])) == 0:\n",
    "        premise_array.append(\"NO TOKEN DETECTED\")\n",
    "    \n",
    "    else:\n",
    "        for j in tools(data['premise'][index]):\n",
    "            tag_premise = (j['entity_group'], remove_space_after_number_and_punctuation(j['word']))\n",
    "            premise_array.append(tag_premise)\n",
    "\n",
    "    return premise_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8de4a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c888804-88ec-4858-ba18-131545ee6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_tag(answer, tag, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "\n",
    "    tag_answer_list = []\n",
    "    \n",
    "    if tag == \"ner\":\n",
    "        if len(premise_array) != 0:\n",
    "            for i in premise_array:\n",
    "\n",
    "                label_from_premise_tag = i[0]\n",
    "                word_from_premise_tag = remove_space_after_number_and_punctuation(i[1])\n",
    "\n",
    "                splitted_word_from_premise_tag = set(remove_punctuation(text) for text in word_from_premise_tag.split())\n",
    "\n",
    "                # With assumption, that I do not divide label when\n",
    "                # there is more than one label in one word answer.\n",
    "                # Instead, I give a NULL.\n",
    "\n",
    "                if word_from_premise_tag.lower() == answer.lower():\n",
    "                    tag_answer = (label_from_premise_tag, word_from_premise_tag)\n",
    "                    break\n",
    "\n",
    "                # Or, I could do this: to reducing NULL label with char not really with string.\n",
    "                # But, the tradeoff is real-answer can be replace with word in premise_array\n",
    "                elif answer.lower() in word_from_premise_tag:\n",
    "                    tag_answer = (label_from_premise_tag, answer.lower())\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    tag_answer = (\"NULL\", answer)\n",
    "            tag_answer_list.append(tag_answer)\n",
    "\n",
    "        else:\n",
    "            tag_answer = (\"NULL\", answer)\n",
    "            tag_answer_list.append(tag_answer)\n",
    "    \n",
    "    elif tag == \"chunking\":\n",
    "        retrieved_from_tools = tools(answer)\n",
    "\n",
    "        if len(retrieved_from_tools) != 0:\n",
    "            for i in retrieved_from_tools:\n",
    "                tag_answer = (i['entity_group'], i['word'])\n",
    "                tag_answer_list.append(tag_answer)\n",
    "        else:\n",
    "            tag_answer = (\"NULL\", answer)\n",
    "            tag_answer_list.append(tag_answer)\n",
    "            \n",
    "        #sequence = [value[0] for value in tag_answer_list]\n",
    "        #tag_answer_list.append(sequence)\n",
    "        \n",
    "    return tag_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d682a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_order(list1, list2):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    matching_values = []\n",
    "\n",
    "    while i < len(list1) and j < len(list2):\n",
    "        if list1[i][0] == list2[j][0]:\n",
    "            matching_values.append(list2[j][1])\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    if j == len(list2):\n",
    "        return \" \".join(matching_values)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d9cdd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PLACE', 'ho chi minh')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_premise = [('PLACE', 'kota ho chi minh'), ('PLACE', 'vietnam'), ('PLACE', 'thanh pho ho chi minh'), ('PLACE', 'vietnam'), ('PLACE', 'sungai mekong'), ('PLACE', 'prey nok'), ('PLACE', 'kamboja'), ('PLACE', 'vietnam'), ('PLACE', 'saigon'), ('PLACE', 'vietnam'), ('PLACE', 'koloni perancis cochinchina'), ('PLACE', 'vietnam selatan'), ('PLACE', 'saigon'), ('PLACE', 'provinsi gia'), ('PLACE', 'kota ho chi minh'), ('PLACE', 'saigon'), ('PLACE', 'sungai saigon'), ('PLACE', 'china selatan')]\n",
    "\n",
    "x = add_row_tag(\"Ho Chi Minh\", \"ner\", arr_premise)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c084ae7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NP', 'ruang'),\n",
       " ('PP', 'dalam'),\n",
       " ('NP', 'sel'),\n",
       " ('SBAR', 'yang'),\n",
       " ('VP', 'berisi'),\n",
       " ('NP', 'cairan ( cell sap'),\n",
       " ('PP', 'dalam'),\n",
       " ('NP', 'bahasa inggris )'),\n",
       " ('SBAR', 'yang'),\n",
       " ('VP', 'berupa'),\n",
       " ('NP', 'rongga'),\n",
       " ('SBAR', 'yang'),\n",
       " ('VP', 'diselaputi'),\n",
       " ('NP', 'membran')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_row_tag(\n",
    "    answer=\"ruang dalam sel yang berisi cairan (cell sap dalam bahasa Inggris) yang berupa rongga yang diselaputi membran\", \n",
    "    tag=\"chunking\", \n",
    "    premise_array=[('NP', 'vakuola'), ('VP', 'merupakan'), ('NP', 'ruang'), ('PP', 'dalam'), ('NP', 'sel'), ('SBAR', 'yang'), ('VP', 'berisi'), ('NP', 'cairan ( cell sap'), ('PP', 'dalam'), ('NP', 'bahasa inggris )'), ('SBAR', 'yang'), ('VP', 'berupa'), ('NP', 'rongga'), ('SBAR', 'yang'), ('VP', 'diselaputi'), ('NP', 'membran ( tonoplas )'), ('NP', 'cairan ini'), ('VP', 'adalah'), ('NP', 'air'), ('PP', 'di'), ('NP', 'dalamnya'), ('VP', 'terlarut'), ('NP', 'zat'), ('PP', 'seperti'), ('NP', 'enzim, lipid, alkaloid, garam mineral, asam, dan basa'), ('PP', 'selain'), ('NP', 'itu'), ('NP', 'vakuola'), ('ADVP', 'juga'), ('VP', 'berisi'), ('NP', 'asam organik, asam amino, glukosa, dan gas'), ('NP', 'vakuola'), ('VP', 'ditemukan'), ('PP', 'pada'), ('NP', 'semua sel tumbuhan'), ('ADVP', 'tidak'), ('VP', 'dijumpai'), ('PP', 'pada'), ('NP', 'sel hewan dan bakteri'), ('VP', ','), ('ADVP', 'kecuali'), ('PP', 'pada'), ('NP', 'hewan uniseluler tingkat rendah')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4967bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ner_and_chunking_all_tag(data):\n",
    "    \n",
    "    data['ner_tag_answer'] = \"\"\n",
    "    data['chunking_tag_answer'] = \"\"\n",
    "    \n",
    "    data['ner_tag_premise'] = \"\"\n",
    "    data['chunking_tag_premise'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "        \n",
    "        ner_premise_array = []\n",
    "        chunking_premise_array = []\n",
    "                                                \n",
    "        data['ner_tag_premise'][i] = add_premise_tag(data, \"ner\", i, ner_premise_array)\n",
    "        data['chunking_tag_premise'][i] = add_premise_tag(data, \"chunking\", i, chunking_premise_array)\n",
    "        \n",
    "        data['ner_tag_answer'][i] = add_row_tag(answer, \"ner\", data['ner_tag_premise'][i])\n",
    "        data['chunking_tag_answer'][i] = add_row_tag(answer, \"chunking\", data['chunking_tag_premise'][i])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cad8f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▍                                                        | 31/100 [01:51<04:08,  3.60s/it]"
     ]
    }
   ],
   "source": [
    "data_nli_train_df = add_ner_and_chunking_all_tag(data_nli_train_df)\n",
    "data_nli_val_df = add_ner_and_chunking_all_tag(data_nli_val_df)\n",
    "data_nli_test_df = add_ner_and_chunking_all_tag(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49a3e4",
   "metadata": {},
   "source": [
    "# Create wrong answer for answerable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b5991",
   "metadata": {},
   "source": [
    "This is the flow to create wrong answer:\n",
    "\n",
    "1. Check the NER and POS/Chunking labels of the right_answer and context/premise.\n",
    "\n",
    "2. Search and group NER and POS/Chunking labels that match the right_answer throughout the context/premise.\n",
    "\n",
    "3. Perform NER classification. There will be two branches here, namely:\n",
    "\n",
    "   3a. If the NER of the right_answer can be detected, then calculate the distance using semantic similarity or word vectors between the right_answer and various possible wrong_answers with the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "   \n",
    "   3b. If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "   \n",
    "4. Perform POS/Chunking classification. Continuation from point 3b. There will be two more branches:\n",
    "\n",
    "   4a. If the POS/Chunking of the right_answer can be detected, then calculate the distance using semantic similarity or word vectors between the right_answer and various possible wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "   \n",
    "   4b. If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise does not contain any of NER of right_answer, then the final wrong_answer will be chosen based on a random word (random_word) from the context/premise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d00a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_similarity = SentenceTransformer(MODEL_SIMILARITY_NAME)\n",
    "\n",
    "def return_similarity_sorted_array(right_answer, sentence_array, model=model_similarity):\n",
    "    \n",
    "    right_answer = right_answer.lower()\n",
    "    \n",
    "    embedding_right_answer = model.encode([right_answer], convert_to_tensor=True, device=device)\n",
    "    embedding_sentence_array = model.encode(sentence_array, convert_to_tensor=True, device=device)\n",
    "    \n",
    "    cosine_scores = util.pytorch_cos_sim(embedding_right_answer, embedding_sentence_array)\n",
    "    \n",
    "    sorted_indices = cosine_scores.argsort(descending=True)[0]\n",
    "    sorted_array = [sentence_array[i] for i in sorted_indices]\n",
    "    \n",
    "    return sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_values_with_hash(arr):\n",
    "    return [item for item in arr if \"#\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(URL_STOPWORD)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    stopword_data = response.json()\n",
    "else:\n",
    "    print(\"Failed to download JSON.\")\n",
    "\n",
    "stopword_data = set([item for sublist in list(stopword_data.values()) for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_word(text, stopword_data=stopword_data):\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    filtered_words = [word for word in words if word not in stopword_data and word not in string.punctuation]\n",
    "    random_word = random.choice(filtered_words)\n",
    "    return random_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0afd1-e751-4cb8-ae22-1b7bb10a5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_same_tag(tag_answers, tag_premises, same_tag_array, tag):\n",
    "    \n",
    "    if tag == \"ner\":\n",
    "        for tag_premise in tag_premises:\n",
    "\n",
    "            label_tag_premise = tag_premise[0]\n",
    "            word_premise = tag_premise[1]\n",
    "\n",
    "            for tag_answer in tag_answers:\n",
    "\n",
    "                label_tag_answer = tag_answer[0]\n",
    "\n",
    "                if label_tag_answer == label_tag_premise:\n",
    "                    same_tag_array.append(word_premise)\n",
    "    \n",
    "    elif tag == \"chunking\":\n",
    "        matching_words = find_order(tag_premises, tag_answers)\n",
    "        if matching_words != None:\n",
    "            same_tag_array.append(matching_words)\n",
    "        else:\n",
    "            grouping_same_tag(tag_answers, tag_premises, same_tag_array, \"ner\")\n",
    "\n",
    "    return remove_values_with_hash(same_tag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_only_punctuation(text):\n",
    "    return all(char in string.punctuation for char in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_plausible_answer(answer, plausible_answer_array):\n",
    "    \n",
    "    answer = answer.lower()\n",
    "    \n",
    "    plausible_answer_array = [item.lower().strip() for item in plausible_answer_array]\n",
    "    plausible_answer_array = [string for string in plausible_answer_array if not contains_only_punctuation(string)]\n",
    "    plausible_answer_array = [remove_punctuation(text) for text in plausible_answer_array]\n",
    "    \n",
    "    final_plausible_answer_array = []\n",
    "    answer_words = set(remove_punctuation(text) for text in answer.split())\n",
    "    \n",
    "    for plausible_answer in plausible_answer_array:\n",
    "        plausible_answer_words = set(plausible_answer.split())\n",
    "        if not plausible_answer_words.intersection(answer_words):\n",
    "            final_plausible_answer_array.append(plausible_answer)\n",
    "    \n",
    "    return final_plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb26145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(input_str):\n",
    "    pattern = r'^-?\\d+(\\.\\d+)?$'\n",
    "    return re.match(pattern, input_str) is not None\n",
    "\n",
    "def is_date(input_str):\n",
    "    pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "    return re.match(pattern, input_str) is not None\n",
    "\n",
    "def is_time(input_str):\n",
    "    pattern = r'^\\d{2}:\\d{2}:\\d{2}$'\n",
    "    return re.match(pattern, input_str) is not None\n",
    "\n",
    "def check_regex(right_answer, plausible_answer_array):\n",
    "    \n",
    "    if is_number(right_answer):\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if is_number(item)]\n",
    "    \n",
    "    elif is_date(right_answer):\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if is_date(item)]\n",
    "    \n",
    "    elif is_time(right_answer):\n",
    "        plausible_answer_array = [item for item in plausible_answer_array if is_time(item)]\n",
    "    \n",
    "    return plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369eced-0cee-4d0d-a436-89a97d2af242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_similarity(data, right_answer, index, tag, plausible_answer_array, premise):\n",
    "\n",
    "    if tag == \"ner\": slice='same_ner_tag_answer'\n",
    "    elif tag == \"chunking\": slice='same_chunking_tag_answer'\n",
    "    else: slice=None\n",
    "\n",
    "    # Find all the sorted (by similarity) plausible wrong answer, \n",
    "    # and remove hask & punctuation only answer\n",
    "    if slice != None:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, data[slice][index])\n",
    "    else:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, plausible_answer_array)\n",
    "    \n",
    "    plausible_answer_array = remove_values_with_hash(wrong_answer_array)\n",
    "    plausible_answer_array = filtering_plausible_answer(right_answer, plausible_answer_array)\n",
    "    plausible_answer_array = check_regex(right_answer, plausible_answer_array)\n",
    "    \n",
    "    try:\n",
    "        # Only return the most similar to right_answer\n",
    "        wrong_answer = plausible_answer_array[0].strip()\n",
    "        \n",
    "        if tag == \"ner\": \n",
    "            properties = \"IDENTICAL NER labels were found, and the highest similarity score same NER array was selected\"\n",
    "        elif tag == \"chunking\":\n",
    "            properties = \"IDENTICAL Chunking labels were found, and the highest similarity score from same Chunking array was selected\"\n",
    "        else:\n",
    "            properties = \"NO CHUNKING labels were found, and the highest similarity score from plausible answer was selected\"\n",
    "    except:\n",
    "        wrong_answer = select_random_word(premise)\n",
    "        \n",
    "        if tag == \"ner\": \n",
    "            properties = \"Detected (NER) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "        elif tag == \"chunking\":\n",
    "            properties = \"Detected (Chunking) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "        else:\n",
    "            properties = \"Detected (Random) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "    \n",
    "    assert isinstance(wrong_answer, str)\n",
    "    assert isinstance(plausible_answer_array, list)\n",
    "    \n",
    "    return wrong_answer, plausible_answer_array, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97759144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong_answer(data, NO_ANSWER_STATEMENT=NO_ANSWER_STATEMENT):\n",
    "    \n",
    "    data['same_ner_tag_answer'] = \"\"\n",
    "    data['same_chunking_tag_answer'] = \"\"\n",
    "    data['wrong_answer'] = \"\"\n",
    "    data['no_answer'] = \"\"\n",
    "    data['plausible_answer_based_on_method'] = \"\"\n",
    "    data['properties'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        right_answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "\n",
    "        same_ner_tag_answer_array = []\n",
    "        same_chunking_tag_answer_array = []\n",
    "\n",
    "        ner_tag_answer = data['ner_tag_answer'][i]\n",
    "        ner_tag_premise = data['ner_tag_premise'][i]\n",
    "\n",
    "        chunking_tag_answer = data['chunking_tag_answer'][i]\n",
    "        chunking_tag_premise = data['chunking_tag_premise'][i]\n",
    "        \n",
    "        if right_answer == \"\":\n",
    "            data['properties'][i] = \"Unanswerable question\"\n",
    "            data['wrong_answer'][i] = \"NULL\"\n",
    "            data['no_answer'][i] = \"NULL\"\n",
    "            data['plausible_answer_based_on_method'][i] = \"Unanswerable question\"\n",
    "            continue\n",
    "            \n",
    "        # Grouped with the same NER & Chunking group, between answer and word of premise\n",
    "        data['same_ner_tag_answer'][i] = grouping_same_tag(ner_tag_answer,\n",
    "                                                           ner_tag_premise,\n",
    "                                                           same_ner_tag_answer_array, \"ner\")\n",
    "        \n",
    "        data['same_chunking_tag_answer'][i] = grouping_same_tag(chunking_tag_answer, \n",
    "                                                                chunking_tag_premise, \n",
    "                                                                same_chunking_tag_answer_array, \"chunking\")\n",
    "        \n",
    "        # Start to create wrong answer\n",
    "        plausible_answer_array = []\n",
    "\n",
    "        # Perform NER classification\n",
    "        # If the NER of the right_answer can be detected, then calculate the distance using semantic \n",
    "        # similarity or word vectors between the right_answer and various possible wrong_answers with \n",
    "        # the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "        if data['same_ner_tag_answer'][i] != []:\n",
    "            wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                      i, \"ner\", plausible_answer_array, premise)\n",
    "            \n",
    "        # If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain \n",
    "        # any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "        # Perform POS/Chunking classification\n",
    "        else:\n",
    "            # If the POS/Chunking of the right_answer can be detected, then calculate the distance \n",
    "            # using semantic similarity or word vectors between the right_answer and various possible \n",
    "            # wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the \n",
    "            # final wrong_answer.\n",
    "            if data['same_chunking_tag_answer'][i] != []:\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"chunking\", plausible_answer_array, premise)\n",
    "            \n",
    "            # If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise \n",
    "            # does not contain any of NER of right_answer, then the final wrong_answer will be chosen \n",
    "            # based on a random word (random_word) from the context/premise.\n",
    "            else:\n",
    "                for chunking_tag in chunking_tag_premise:\n",
    "                    plausible_answer_array.append(chunking_tag[1])\n",
    "\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"none\", plausible_answer_array, premise)\n",
    "        data['properties'][i] = properties\n",
    "        data['wrong_answer'][i] = wrong_answer\n",
    "        data['no_answer'][i] = NO_ANSWER_STATEMENT\n",
    "        data['plausible_answer_based_on_method'][i] = plausible_answer_array\n",
    "            \n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = create_wrong_answer(data_nli_train_df)\n",
    "data_nli_val_df = create_wrong_answer(data_nli_val_df)\n",
    "data_nli_test_df = create_wrong_answer(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe61c82",
   "metadata": {},
   "source": [
    "# Split to two dataset: right dataset & wrong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_column_number(data, column_name=\"hypothesis\", column_num=3):\n",
    "\n",
    "    cols = list(data.columns)\n",
    "    cols.remove(column_name)\n",
    "    cols.insert(column_num, column_name)\n",
    "\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56880d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['wrong_answer', 'no_answer']\n",
    "\n",
    "data_nli_answerable_right_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_right_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_right_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_answerable_right_train_df = data_nli_answerable_right_train_df[data_nli_answerable_right_train_df['answer'] != '']\n",
    "data_nli_answerable_right_val_df = data_nli_answerable_right_val_df[data_nli_answerable_right_val_df['answer'] != '']\n",
    "data_nli_answerable_right_test_df = data_nli_answerable_right_test_df[data_nli_answerable_right_test_df['answer'] != '']\n",
    "\n",
    "data_nli_answerable_right_train_df = data_nli_answerable_right_train_df.reset_index(drop=True)\n",
    "data_nli_answerable_right_val_df = data_nli_answerable_right_val_df.reset_index(drop=True)\n",
    "data_nli_answerable_right_test_df = data_nli_answerable_right_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['answer', 'no_answer']\n",
    "\n",
    "data_nli_answerable_wrong_train_df = data_nli_train_df[data_nli_train_df['answer'] != '']\n",
    "data_nli_answerable_wrong_val_df = data_nli_val_df[data_nli_val_df['answer'] != '']\n",
    "data_nli_answerable_wrong_test_df = data_nli_test_df[data_nli_test_df['answer'] != '']\n",
    "\n",
    "data_nli_answerable_wrong_train_df = data_nli_answerable_wrong_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_wrong_val_df = data_nli_answerable_wrong_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_answerable_wrong_test_df = data_nli_answerable_wrong_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_answerable_wrong_train_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_answerable_wrong_val_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_answerable_wrong_test_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "\n",
    "data_nli_answerable_wrong_train_df = data_nli_answerable_wrong_train_df.reset_index(drop=True)\n",
    "data_nli_answerable_wrong_val_df = data_nli_answerable_wrong_val_df.reset_index(drop=True)\n",
    "data_nli_answerable_wrong_test_df = data_nli_answerable_wrong_test_df.reset_index(drop=True)\n",
    "\n",
    "data_nli_answerable_wrong_train_df = move_to_column_number(data_nli_answerable_wrong_train_df, \"answer\", 2)\n",
    "data_nli_answerable_wrong_val_df = move_to_column_number(data_nli_answerable_wrong_val_df, \"answer\", 2)\n",
    "data_nli_answerable_wrong_test_df = move_to_column_number(data_nli_answerable_wrong_test_df, \"answer\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['wrong_answer', 'no_answer']\n",
    "\n",
    "data_nli_unanswerable_right_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_right_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_right_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_unanswerable_right_train_df = data_nli_unanswerable_right_train_df[data_nli_unanswerable_right_train_df['answer'] == '']\n",
    "data_nli_unanswerable_right_val_df = data_nli_unanswerable_right_val_df[data_nli_unanswerable_right_val_df['answer'] == '']\n",
    "data_nli_unanswerable_right_test_df = data_nli_unanswerable_right_test_df[data_nli_unanswerable_right_test_df['answer'] == '']\n",
    "\n",
    "data_nli_unanswerable_right_train_df = data_nli_unanswerable_right_train_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_right_val_df = data_nli_unanswerable_right_val_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_right_test_df = data_nli_unanswerable_right_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5df327",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['answer', 'wrong_answer']\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_train_df[data_nli_train_df['answer'] != '']\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_val_df[data_nli_val_df['answer'] != '']\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_test_df[data_nli_test_df['answer'] != '']\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_unanswerable_wrong_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_unanswerable_wrong_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_unanswerable_wrong_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df.rename(columns={'no_answer': 'answer'}, inplace=True)\n",
    "data_nli_unanswerable_wrong_val_df.rename(columns={'no_answer': 'answer'}, inplace=True)\n",
    "data_nli_unanswerable_wrong_test_df.rename(columns={'no_answer': 'answer'}, inplace=True)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_unanswerable_wrong_train_df.sample(len(data_nli_unanswerable_right_train_df), replace=True)\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_unanswerable_wrong_val_df.sample(len(data_nli_unanswerable_right_val_df), replace=True)\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_unanswerable_wrong_test_df.sample(len(data_nli_unanswerable_right_test_df), replace=True)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = data_nli_unanswerable_wrong_train_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_wrong_val_df = data_nli_unanswerable_wrong_val_df.reset_index(drop=True)\n",
    "data_nli_unanswerable_wrong_test_df = data_nli_unanswerable_wrong_test_df.reset_index(drop=True)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = move_to_column_number(data_nli_unanswerable_wrong_train_df, \"answer\", 2)\n",
    "data_nli_unanswerable_wrong_val_df = move_to_column_number(data_nli_unanswerable_wrong_val_df, \"answer\", 2)\n",
    "data_nli_unanswerable_wrong_test_df = move_to_column_number(data_nli_unanswerable_wrong_test_df, \"answer\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ENTAILMENT ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_answerable_right_train_df))\n",
    "print(\"VAL:\", len(data_nli_answerable_right_val_df))\n",
    "print(\"TEST:\", len(data_nli_answerable_right_test_df))\n",
    "print()\n",
    "\n",
    "print(\"CONTRADICTION ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_answerable_wrong_train_df))\n",
    "print(\"VAL:\", len(data_nli_answerable_wrong_val_df))\n",
    "print(\"TEST:\", len(data_nli_answerable_wrong_test_df))\n",
    "print()\n",
    "\n",
    "print(\"ENTAILMENT UN-ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_unanswerable_right_train_df))\n",
    "print(\"VAL:\", len(data_nli_unanswerable_right_val_df))\n",
    "print(\"TEST:\", len(data_nli_unanswerable_right_test_df))\n",
    "print()\n",
    "\n",
    "print(\"CONTRADICTION UN-ANSWERABLE\")\n",
    "print(\"TRAIN:\", len(data_nli_unanswerable_wrong_train_df))\n",
    "print(\"VAL:\", len(data_nli_unanswerable_wrong_val_df))\n",
    "print(\"TEST:\", len(data_nli_unanswerable_wrong_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6f08",
   "metadata": {},
   "source": [
    "# Convert question-answer pair to hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp_tools_paraphraser = pipeline(task = TASK_PARAPHRASER_NAME, \n",
    "#                     model = MODEL_PARAPHRASER_NAME, \n",
    "#                     tokenizer = AutoTokenizer.from_pretrained(MODEL_PARAPHRASER_NAME, \n",
    "#                                                               model_max_length=512, \n",
    "#                                                               truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_question_and_answer_to_hypothesis(data, NO_ANSWER_STATEMENT=NO_ANSWER_STATEMENT):\n",
    "    \n",
    "    data['hypothesis'] = \"\"\n",
    "    hypothesis_array = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if data['answer'][i] != \"\" and type(data['answer'][i]) == str:\n",
    "            hypothesis_array.append(data['question'][i] + ' ' + data['answer'][i])\n",
    "        else:\n",
    "            hypothesis_array.append(data['question'][i] + ' ' + NO_ANSWER_STATEMENT)\n",
    "        \n",
    "        # Use this to decline no-answer-warning properties\n",
    "        #hypothesis_array.append(data['question'][i] + ' ' + data['answer'][i])\n",
    "        \n",
    "        # Use this to use paraphraser\n",
    "        #hypothesis_array.append(str(nlp_tools_paraphraser(data['question'][i] + ' ' + data['answer'][i])[0]['generated_text']))\n",
    "    \n",
    "    data['hypothesis'] = hypothesis_array\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf340e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_right_train_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_right_train_df)\n",
    "data_nli_answerable_right_val_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_right_val_df)\n",
    "data_nli_answerable_right_test_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_right_test_df)\n",
    "\n",
    "data_nli_answerable_right_train_df = move_to_column_number(data_nli_answerable_right_train_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_right_val_df = move_to_column_number(data_nli_answerable_right_val_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_right_test_df = move_to_column_number(data_nli_answerable_right_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20241aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_wrong_train_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_wrong_train_df)\n",
    "data_nli_answerable_wrong_val_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_wrong_val_df)\n",
    "data_nli_answerable_wrong_test_df = convert_question_and_answer_to_hypothesis(data_nli_answerable_wrong_test_df)\n",
    "\n",
    "data_nli_answerable_wrong_train_df = move_to_column_number(data_nli_answerable_wrong_train_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_wrong_val_df = move_to_column_number(data_nli_answerable_wrong_val_df, \"hypothesis\", 3)\n",
    "data_nli_answerable_wrong_test_df = move_to_column_number(data_nli_answerable_wrong_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_right_train_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_right_train_df)\n",
    "data_nli_unanswerable_right_val_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_right_val_df)\n",
    "data_nli_unanswerable_right_test_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_right_test_df)\n",
    "\n",
    "data_nli_unanswerable_right_train_df = move_to_column_number(data_nli_unanswerable_right_train_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_right_val_df = move_to_column_number(data_nli_unanswerable_right_val_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_right_test_df = move_to_column_number(data_nli_unanswerable_right_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d28ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_wrong_train_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_wrong_train_df)\n",
    "data_nli_unanswerable_wrong_val_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_wrong_val_df)\n",
    "data_nli_unanswerable_wrong_test_df = convert_question_and_answer_to_hypothesis(data_nli_unanswerable_wrong_test_df)\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = move_to_column_number(data_nli_unanswerable_wrong_train_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_wrong_val_df = move_to_column_number(data_nli_unanswerable_wrong_val_df, \"hypothesis\", 3)\n",
    "data_nli_unanswerable_wrong_test_df = move_to_column_number(data_nli_unanswerable_wrong_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c4ace",
   "metadata": {},
   "source": [
    "# Add label: entailment & contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_right_train_df['label'] = 'entailment'\n",
    "data_nli_answerable_right_val_df['label'] = 'entailment'\n",
    "data_nli_answerable_right_test_df['label'] = 'entailment'\n",
    "\n",
    "data_nli_answerable_right_train_df = move_to_column_number(data_nli_answerable_right_train_df, \"label\", 4)\n",
    "data_nli_answerable_right_val_df = move_to_column_number(data_nli_answerable_right_val_df, \"label\", 4)\n",
    "data_nli_answerable_right_test_df = move_to_column_number(data_nli_answerable_right_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02098578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_wrong_train_df['label'] = 'contradiction'\n",
    "data_nli_answerable_wrong_val_df['label'] = 'contradiction'\n",
    "data_nli_answerable_wrong_test_df['label'] = 'contradiction'\n",
    "\n",
    "data_nli_answerable_wrong_train_df = move_to_column_number(data_nli_answerable_wrong_train_df, \"label\", 4)\n",
    "data_nli_answerable_wrong_val_df = move_to_column_number(data_nli_answerable_wrong_val_df, \"label\", 4)\n",
    "data_nli_answerable_wrong_test_df = move_to_column_number(data_nli_answerable_wrong_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ebcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_right_train_df['label'] = 'entailment'\n",
    "data_nli_unanswerable_right_val_df['label'] = 'entailment'\n",
    "data_nli_unanswerable_right_test_df['label'] = 'entailment'\n",
    "\n",
    "data_nli_unanswerable_right_train_df = move_to_column_number(data_nli_unanswerable_right_train_df, \"label\", 4)\n",
    "data_nli_unanswerable_right_val_df = move_to_column_number(data_nli_unanswerable_right_val_df, \"label\", 4)\n",
    "data_nli_unanswerable_right_test_df = move_to_column_number(data_nli_unanswerable_right_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_unanswerable_wrong_train_df['label'] = 'contradiction'\n",
    "data_nli_unanswerable_wrong_val_df['label'] = 'contradiction'\n",
    "data_nli_unanswerable_wrong_test_df['label'] = 'contradiction'\n",
    "\n",
    "data_nli_unanswerable_wrong_train_df = move_to_column_number(data_nli_unanswerable_wrong_train_df, \"label\", 4)\n",
    "data_nli_unanswerable_wrong_val_df = move_to_column_number(data_nli_unanswerable_wrong_val_df, \"label\", 4)\n",
    "data_nli_unanswerable_wrong_test_df = move_to_column_number(data_nli_unanswerable_wrong_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f431144",
   "metadata": {},
   "source": [
    "# Concat the right and wrong NLI to one NLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final = pd.concat([data_nli_answerable_right_train_df, \n",
    "                                     data_nli_answerable_wrong_train_df,\n",
    "                                     data_nli_unanswerable_right_train_df,\n",
    "                                     data_nli_unanswerable_wrong_train_df], axis=0, ignore_index=True)\n",
    "\n",
    "data_nli_val_df_final = pd.concat([data_nli_answerable_right_val_df, \n",
    "                                   data_nli_answerable_wrong_val_df,\n",
    "                                   data_nli_unanswerable_right_val_df,\n",
    "                                   data_nli_unanswerable_wrong_val_df], axis=0, ignore_index=True)\n",
    "\n",
    "data_nli_test_df_final = pd.concat([data_nli_answerable_right_test_df, \n",
    "                                    data_nli_answerable_wrong_test_df,\n",
    "                                    data_nli_unanswerable_right_test_df,\n",
    "                                    data_nli_unanswerable_wrong_test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_answerable_wrong_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a980a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(data_nli_answerable_right_test_df)):\n",
    "    print(f\"Iterasi: {i}\")\n",
    "    print(f\"answer: {data_nli_answerable_right_test_df['answer'][i]}\")\n",
    "    print(\"NER\")\n",
    "    print(data_nli_answerable_right_test_df['ner_tag_answer'][i])\n",
    "    print(data_nli_answerable_right_test_df['ner_tag_premise'][i])\n",
    "    print(\"Chunking\")\n",
    "    print(data_nli_answerable_right_test_df['chunking_tag_answer'][i])\n",
    "    print(data_nli_answerable_right_test_df['chunking_tag_premise'][i])\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAIN FINAL\")\n",
    "print(len(data_nli_train_df_final))\n",
    "print()\n",
    "\n",
    "print(\"VAL FINAL\")\n",
    "print(len(data_nli_val_df_final))\n",
    "print()\n",
    "\n",
    "print(\"TEST FINAL\")\n",
    "print(len(data_nli_test_df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea9097",
   "metadata": {},
   "source": [
    "# Convert to DataFrame format to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final.to_csv(f\"{NAME}_nli_train_df.csv\", index=False)\n",
    "data_nli_val_df_final.to_csv(f\"{NAME}_nli_val_df.csv\", index=False)\n",
    "data_nli_test_df_final.to_csv(f\"{NAME}_nli_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PROGRAM FINISHED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
