{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9171daa4",
   "metadata": {},
   "source": [
    "# Define tool and model of the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a063a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 13 09:42:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    43W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    42W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    60W / 300W |  17290MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    60W / 300W |    730MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    44W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    74W / 300W |  17242MiB / 32510MiB |     14%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    41W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41849a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "TASK_NER_NAME = \"ner\"\n",
    "MODEL_NER_NAME = \"ageng-anugrah/indobert-large-p2-finetuned-ner\"\n",
    "\n",
    "TASK_CHUNKING_NAME = \"token-classification\"\n",
    "MODEL_CHUNKING_NAME = \"ageng-anugrah/indobert-large-p2-finetuned-chunking\"\n",
    "\n",
    "MODEL_SIMILARITY_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "URL_STOPWORD = \"https://raw.githubusercontent.com/6/stopwords-json/master/stopwords-all.json\"\n",
    "\n",
    "TASK_PARAPHRASER_NAME = \"text2text-generation\"\n",
    "MODEL_PARAPHRASER_NAME = \"\"\n",
    "\n",
    "# SAMPLE = sys.maxsize\n",
    "SAMPLE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9fdd4",
   "metadata": {},
   "source": [
    "# Import anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26d313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import string\n",
    "import contextlib\n",
    "import gc\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from evaluate import load\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "from datetime import datetime\n",
    "from huggingface_hub import notebook_login\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import HfApi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    Dataset,\n",
    "    DatasetDict\n",
    ")\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback, \n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cd27c",
   "metadata": {},
   "source": [
    "# Retrieve QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f426d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRAM STARTED\n"
     ]
    }
   ],
   "source": [
    "print(\"PROGRAM STARTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafbf0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset idk_mrc (/root/.cache/huggingface/datasets/idk_mrc/idk_mrc_source/1.0.0/cf468d86fa7341e69998db1449851672ebfb4fa46036929d66b9de15c421334f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c030683da79482abda1de06a4182ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3659/3659 [01:46<00:00, 34.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 358/358 [00:08<00:00, 42.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 378/378 [00:08<00:00, 43.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 9332\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 764\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "data_qas = conhelps.filtered(lambda x: 'idk_mrc' in x.dataset_name)[0].load_dataset()\n",
    "\n",
    "df_train = pd.DataFrame(data_qas['train'])\n",
    "df_validation = pd.DataFrame(data_qas['validation'])\n",
    "df_test = pd.DataFrame(data_qas['test'])\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_train['context']))):\n",
    "    for j in df_train[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                           \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                           \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                           ignore_index=True)\n",
    "        else:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": str(), \n",
    "                                                           \"answer_start\": 0, \n",
    "                                                           \"answer_end\": 0}}, \n",
    "                                                           ignore_index=True)\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_val = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_validation['context']))):\n",
    "    for j in df_validation[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)        \n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_test = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_test['context']))):\n",
    "    for j in df_test[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict(new_df_train)\n",
    "validation_dataset = Dataset.from_dict(new_df_val)\n",
    "test_dataset = Dataset.from_dict(new_df_test)\n",
    "\n",
    "data_qas = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset, \"test\": test_dataset})\n",
    "data_qas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae908a",
   "metadata": {},
   "source": [
    "# Convert to NLI, with hypothesis being just do concat question & answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c79ac",
   "metadata": {},
   "source": [
    "## Convert Dataset to DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b342b8ce-41f9-4714-84a5-1697cfee1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275dc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE == sys.maxsize:\n",
    "    data_qas_train_df = pd.DataFrame(data_qas[\"train\"][:SAMPLE])\n",
    "    data_qas_val_df = pd.DataFrame(data_qas[\"validation\"][:SAMPLE])\n",
    "    data_qas_test_df = pd.DataFrame(data_qas[\"test\"][:SAMPLE])\n",
    "\n",
    "else:\n",
    "    data_qas_train_df = (pd.DataFrame(data_qas[\"train\"])).sample(n=SAMPLE, random_state=42)\n",
    "    data_qas_val_df = (pd.DataFrame(data_qas[\"validation\"])).sample(n=SAMPLE, random_state=42)\n",
    "    data_qas_test_df = (pd.DataFrame(data_qas[\"test\"])).sample(n=SAMPLE, random_state=42)\n",
    "\n",
    "    data_qas_train_df = data_qas_train_df.reset_index(drop=True)\n",
    "    data_qas_val_df = data_qas_val_df.reset_index(drop=True)\n",
    "    data_qas_test_df = data_qas_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bbf0b",
   "metadata": {},
   "source": [
    "## Retrieve answer text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0424485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answer_text(data):\n",
    "    for i in range(len(data)):\n",
    "        data['answer'][i] = data['answer'][i]['text']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b1a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = retrieve_answer_text(data_qas_train_df)\n",
    "data_qas_val_df = retrieve_answer_text(data_qas_val_df)\n",
    "data_qas_test_df = retrieve_answer_text(data_qas_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b1295",
   "metadata": {},
   "source": [
    "## Delete all unanswerable row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decb0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = data_qas_train_df[data_qas_train_df['answer'] != '']\n",
    "data_qas_val_df = data_qas_val_df[data_qas_val_df['answer'] != '']\n",
    "data_qas_test_df = data_qas_test_df[data_qas_test_df['answer'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3c125",
   "metadata": {},
   "source": [
    "### Reset index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2631db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = data_qas_train_df.reset_index(drop=True)\n",
    "data_qas_val_df = data_qas_val_df.reset_index(drop=True)\n",
    "data_qas_test_df = data_qas_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18588cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "50\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(data_qas_train_df))\n",
    "print(len(data_qas_val_df))\n",
    "print(len(data_qas_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881d292",
   "metadata": {},
   "source": [
    "## Create NLI dataset from copy of QA dataset above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8808af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_qas_train_df.copy()\n",
    "data_nli_val_df = data_qas_val_df.copy()\n",
    "data_nli_test_df = data_qas_test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83072dc4",
   "metadata": {},
   "source": [
    "## Convert context pair to premise (only renaming column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1562622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_nli_train_df.rename(columns={\"context\": \"premise\"})\n",
    "data_nli_val_df = data_nli_val_df.rename(columns={\"context\": \"premise\"})\n",
    "data_nli_test_df = data_nli_test_df.rename(columns={\"context\": \"premise\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33986ce",
   "metadata": {},
   "source": [
    "# Add contradiction label cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095664cc",
   "metadata": {},
   "source": [
    "## Import pipeline to create contradiction cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8850d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_ner = pipeline(task = TASK_NER_NAME, \n",
    "                     model = MODEL_NER_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_NER_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84dda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_chunking = pipeline(task = TASK_CHUNKING_NAME, \n",
    "                     model = MODEL_CHUNKING_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_CHUNKING_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae4a76",
   "metadata": {},
   "source": [
    "## Add NER and chunking tag column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a68f3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space_after_number_and_punctuation(text):\n",
    "    pattern = r'(\\d+)\\s*([.,])\\s*(?=\\S|$)'\n",
    "    cleaned_text = re.sub(pattern, r'\\1\\2', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee495118-61e1-4603-9194-690c0ae737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_premise_tag(data, tag, index, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "    \n",
    "    if len(tools(data['premise'][index])) == 0:\n",
    "        premise_array.append(\"NO TOKEN DETECTED\")\n",
    "    \n",
    "    else:\n",
    "        for j in tools(data['premise'][index]):\n",
    "            tag_premise = (j['entity_group'], remove_space_after_number_and_punctuation(j['word']))\n",
    "            premise_array.append(tag_premise)\n",
    "\n",
    "    return premise_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fede45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c888804-88ec-4858-ba18-131545ee6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_tag(answer, tag, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "\n",
    "    tag_answer_list = []\n",
    "    \n",
    "    if len(premise_array) != 0:\n",
    "        for i in premise_array:\n",
    "            \n",
    "            label_from_premise_tag = i[0]\n",
    "            word_from_premise_tag = remove_space_after_number_and_punctuation(i[1])\n",
    "            \n",
    "            splitted_word_from_premise_tag = set(remove_punctuation(text) for text in word_from_premise_tag.split())\n",
    "            \n",
    "            # With assumption, that I do not divide label when\n",
    "            # there is more than one label in one word answer.\n",
    "            # Instead, I give a NULL.\n",
    "            \n",
    "            if word_from_premise_tag.lower() == answer.lower():\n",
    "                tag_answer = (label_from_premise_tag, word_from_premise_tag)\n",
    "                break\n",
    "            \n",
    "            # Or, I could do this: to reducing NULL label with char not really with string.\n",
    "            # But, the tradeoff is real-answer can be replace with word in premise_array\n",
    "            #elif answer.lower() in word_from_premise_tag:\n",
    "            #    tag_answer = (label_from_premise_tag, answer.lower())\n",
    "            #    break\n",
    "            \n",
    "            else:\n",
    "                tag_answer = (\"NULL\", answer)\n",
    "        tag_answer_list.append(tag_answer)\n",
    "\n",
    "    else:\n",
    "        tag_answer = (\"NULL\", answer)\n",
    "        tag_answer_list.append(tag_answer)\n",
    "        \n",
    "    return tag_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "732cf931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PLACE', 'ho chi minh')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_premise = [('PLACE', 'kota ho chi minh'), ('PLACE', 'vietnam'), ('PLACE', 'thanh pho ho chi minh'), ('PLACE', 'vietnam'), ('PLACE', 'sungai mekong'), ('PLACE', 'prey nok'), ('PLACE', 'kamboja'), ('PLACE', 'vietnam'), ('PLACE', 'saigon'), ('PLACE', 'vietnam'), ('PLACE', 'koloni perancis cochinchina'), ('PLACE', 'vietnam selatan'), ('PLACE', 'saigon'), ('PLACE', 'provinsi gia'), ('PLACE', 'kota ho chi minh'), ('PLACE', 'saigon'), ('PLACE', 'sungai saigon'), ('PLACE', 'china selatan')]\n",
    "\n",
    "x = add_row_tag(\"Ho Chi Minh\", \"ner\", arr_premise)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4967bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ner_and_chunking_all_tag(data):\n",
    "    \n",
    "    data['ner_tag_answer'] = \"\"\n",
    "    data['chunking_tag_answer'] = \"\"\n",
    "    \n",
    "    data['ner_tag_premise'] = \"\"\n",
    "    data['chunking_tag_premise'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "        \n",
    "        ner_premise_array = []\n",
    "        chunking_premise_array = []\n",
    "                                                \n",
    "        data['ner_tag_premise'][i] = add_premise_tag(data, \"ner\", i, ner_premise_array)\n",
    "        data['chunking_tag_premise'][i] = add_premise_tag(data, \"chunking\", i, chunking_premise_array)\n",
    "        \n",
    "        data['ner_tag_answer'][i] = add_row_tag(answer, \"ner\", data['ner_tag_premise'][i])\n",
    "        data['chunking_tag_answer'][i] = add_row_tag(answer, \"chunking\", data['chunking_tag_premise'][i])\n",
    "        \n",
    "        print(\"answer:\", answer)\n",
    "        print(\"ner_tag_premise:\", data['ner_tag_premise'][i])\n",
    "        print(\"ner_tag_answer:\", data['ner_tag_answer'][i])\n",
    "        print()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25cad8f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                  | 1/53 [00:05<04:45,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: hitam di atas, merah di tengah, dan kuning (\"emas\") di bawah\n",
      "ner_tag_premise: [('PLACE', 'jerman'), ('PLACE', 'jerman barat'), ('PLACE', 'jerman')]\n",
      "ner_tag_answer: [('NULL', 'hitam di atas, merah di tengah, dan kuning (\"emas\") di bawah')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                                | 2/53 [00:17<08:10,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Paus\n",
      "ner_tag_premise: [('PERSON', 'paus'), ('PLACE', 'dutch'), ('PLACE', 'latin'), ('PLACE', 'roma'), ('PLACE', 'roma'), ('PERSON', 'santo petrus'), ('PERSON', 'yesus'), ('PERSON', 'paus fransiskus'), ('PERSON', 'paus benediktus xvi')]\n",
      "ner_tag_answer: [('PERSON', 'paus')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                               | 3/53 [00:26<07:39,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1 Januari 2002\n",
      "ner_tag_premise: [('PLACE', 'uni'), ('ORGANISATION', 'eropa')]\n",
      "ner_tag_answer: [('NULL', '1 Januari 2002')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▎                                                                             | 4/53 [00:39<08:32, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 36.000 km2\n",
      "ner_tag_premise: [('PLACE', 'kabupaten kaimana'), ('PLACE', 'provinsi papua barat'), ('PLACE', 'indonesia'), ('PLACE', 'kabupaten kaimana'), ('PLACE', 'kabupaten sarmi'), ('PLACE', 'kabupaten keerom'), ('PLACE', 'kabupaten sorong selatan'), ('PLACE', 'kabupaten radja ampat'), ('PLACE', 'kabupaten pegunungan bintang'), ('PLACE', 'kabupaten yahukimo'), ('PLACE', 'kabupaten tolikara'), ('PLACE', 'kabupaten waropen'), ('PLACE', 'kabupaten kaimana'), ('PLACE', 'kabupaten boven digoel'), ('PLACE', 'kabupaten mappi'), ('PLACE', 'kabupaten asmat'), ('PLACE', 'kabupaten teluk bintuni'), ('PLACE', 'kabupaten wondama'), ('PLACE', 'papua'), ('PLACE', 'distrik kaimana'), ('PLACE', 'kabupaten kaimana')]\n",
      "ner_tag_answer: [('NULL', '36.000 km2')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                            | 5/53 [00:48<08:00, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Wielkopolska\n",
      "ner_tag_premise: [('PERSON', 'plwacz'), ('PLACE', 'pl'), ('PERSON', '##wa'), ('PLACE', 'kalisz'), ('PLACE', 'poznan'), ('PLACE', 'uj'), ('PLACE', 'Nakło'), ('PLACE', 'wielkopolsk'), ('PLACE', 'sungai warta')]\n",
      "ner_tag_answer: [('NULL', 'Wielkopolska')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▌                                                                          | 6/53 [00:59<08:17, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: melakukan operasi aritmetika dan logika terhadap data yang diambil dari memori atau dari informasi yang dimasukkan melalui beberapa perangkat keras, seperti papan tombol, pemindai, tuas kontrol, maupun tetikus\n",
      "ner_tag_premise: ['NO TOKEN DETECTED']\n",
      "ner_tag_answer: [('NULL', 'melakukan operasi aritmetika dan logika terhadap data yang diambil dari memori atau dari informasi yang dimasukkan melalui beberapa perangkat keras, seperti papan tombol, pemindai, tuas kontrol, maupun tetikus')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████                                                                         | 7/53 [01:09<07:50, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 28\n",
      "ner_tag_premise: [('ORGANISATION', 'uni eropa'), ('ORGANISATION', 'ue'), ('PLACE', 'eropa'), ('ORGANISATION', 'uni eropa'), ('ORGANISATION', 'ma'), ('PLACE', '##astrich'), ('ORGANISATION', 'ue')]\n",
      "ner_tag_answer: [('NULL', '28')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▋                                                                       | 8/53 [01:21<08:02, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 358,55km²\n",
      "ner_tag_premise: [('PLACE', 'kota palembang'), ('PLACE', 'provinsi sumatera selatan'), ('PLACE', 'palembang'), ('PLACE', 'sumatera'), ('PLACE', 'medan'), ('PLACE', 'kota palembang'), ('PLACE', 'jakabaring'), ('PLACE', 'tanjung api - api'), ('PLACE', 'kota palembang')]\n",
      "ner_tag_answer: [('NULL', '358,55km²')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▎                                                                     | 9/53 [01:31<07:46, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 9.000.000km2\n",
      "ner_tag_premise: [('PLACE', 'sahara'), ('PLACE', 'afrika'), ('PLACE', 'samudra atlantik'), ('PLACE', 'laut merah'), ('PLACE', 'laut tengah'), ('PLACE', 'sahel'), ('PLACE', 'mauritania'), ('PLACE', 'mesir'), ('PLACE', 'afrika'), ('PLACE', 'afrika utara'), ('PLACE', 'afrika')]\n",
      "ner_tag_answer: [('NULL', '9.000.000km2')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▋                                                                   | 10/53 [01:37<06:38,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Armonk, New York, Amerika Serikat\n",
      "ner_tag_premise: [('ORGANISATION', 'international business machines corporation'), ('ORGANISATION', 'ibm'), ('ORGANISATION', 'nyse'), ('PLACE', 'amerika serikat'), ('ORGANISATION', 'ibm'), ('PLACE', 'armonk'), ('PLACE', 'new york'), ('PLACE', 'amerika serikat')]\n",
      "ner_tag_answer: [('NULL', 'Armonk, New York, Amerika Serikat')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████▏                                                                 | 11/53 [01:44<05:53,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Pontianak\n",
      "ner_tag_premise: [('PLACE', 'belanda'), ('PLACE', 'gouvernement borneo'), ('PLACE', 'banjarmasin'), ('PLACE', 'residentie westerafdeeling van borneo'), ('PLACE', 'pontianak')]\n",
      "ner_tag_answer: [('PLACE', 'pontianak')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▊                                                                | 12/53 [01:58<06:51, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Ho Chi Minh\n",
      "ner_tag_premise: [('PLACE', 'kota ho chi minh'), ('PLACE', 'vietnam'), ('PLACE', 'thanh pho ho chi minh'), ('PLACE', 'vietnam'), ('PLACE', 'sungai mekong'), ('PLACE', 'prey nok'), ('PLACE', 'kamboja'), ('PLACE', 'vietnam'), ('PLACE', 'saigon'), ('PLACE', 'vietnam'), ('PLACE', 'koloni perancis cochinchina'), ('PLACE', 'vietnam selatan'), ('PLACE', 'saigon'), ('PLACE', 'provinsi gia'), ('PLACE', 'kota ho chi minh'), ('PLACE', 'saigon'), ('PLACE', 'sungai saigon'), ('PLACE', 'china selatan')]\n",
      "ner_tag_answer: [('NULL', 'Ho Chi Minh')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▎                                                              | 13/53 [02:15<08:10, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: stimulus yang tidak atau belum menghasilkan sebuah respon tertentu\n",
      "ner_tag_premise: [('PERSON', 'pavlov'), ('PERSON', 'pavlov'), ('PERSON', 'pavlov')]\n",
      "ner_tag_answer: [('NULL', 'stimulus yang tidak atau belum menghasilkan sebuah respon tertentu')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▉                                                             | 14/53 [02:18<06:10,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1920an\n",
      "ner_tag_premise: [('PLACE', 'indonesia'), ('PLACE', 'indonesia'), ('PLACE', 'belanda')]\n",
      "ner_tag_answer: [('NULL', '1920an')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▍                                                           | 15/53 [02:35<07:29, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Nate dengan mentor dan figur ayah, Victor \"Sully\" Sullivan\n",
      "ner_tag_premise: [('PERSON', 'nate'), ('PERSON', 'victor \" sully \" sullivan'), ('PLACE', 'arab'), ('PLACE', 'rub'), ('PLACE', 'al khali desert'), ('PLACE', '##s'), ('PERSON', 'elena fisher'), ('PERSON', 'chloe frazer'), ('PERSON', 'charlie cutter'), ('PERSON', 'salim'), ('PERSON', 'nate'), ('PERSON', 'katherine marlowe'), ('PERSON', 'talbot'), ('PERSON', 'ramses')]\n",
      "ner_tag_answer: [('NULL', 'Nate dengan mentor dan figur ayah, Victor \"Sully\" Sullivan')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████                                                          | 16/53 [02:46<07:03, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: diperuntukkan bagi wanita\n",
      "ner_tag_premise: [('PLACE', 'yunani'), ('PLACE', 'yunani'), ('PLACE', 'india')]\n",
      "ner_tag_answer: [('NULL', 'diperuntukkan bagi wanita')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▌                                                        | 17/53 [02:49<05:23,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: substansi organik yang dibutuhkan organisme untuk fungsi normal dari sistem tubuh, pertumbuhan, pemeliharaan kesehatan\n",
      "ner_tag_premise: ['NO TOKEN DETECTED']\n",
      "ner_tag_answer: [('NULL', 'substansi organik yang dibutuhkan organisme untuk fungsi normal dari sistem tubuh, pertumbuhan, pemeliharaan kesehatan')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▏                                                      | 18/53 [02:56<04:50,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1.812,8km2\n",
      "ner_tag_premise: [('PLACE', 'kabupaten lamongan'), ('PLACE', 'kabupaten lamongan'), ('PLACE', 'provinsi jawa timur'), ('PLACE', 'kabupaten lamongan')]\n",
      "ner_tag_answer: [('NULL', '1.812,8km2')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▊                                                     | 19/53 [03:05<04:52,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 21 Maret 1685\n",
      "ner_tag_premise: [('PERSON', 'johann sebastian bach'), ('PLACE', 'kota eisenach'), ('PLACE', 'jerman'), ('PERSON', 'johann ambrosius bach'), ('PERSON', 'johann sebastian'), ('PERSON', 'bach'), ('PLACE', 'ohrdruf'), ('PERSON', 'johann christoph bach'), ('PLACE', 'ohrdruf'), ('PERSON', 'bach'), ('PLACE', 'lyceum'), ('PERSON', 'bach'), ('PERSON', 'bach'), ('PERSON', 'bach')]\n",
      "ner_tag_answer: [('NULL', '21 Maret 1685')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▎                                                   | 20/53 [03:15<04:57,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1 Juli 1971\n",
      "ner_tag_premise: [('PERSON', 'nicolaas jouwe'), ('ORGANISATION', 'opm'), ('PERSON', 'seth jafeth roemkorem'), ('PERSON', 'jacob hendrik prai'), ('PLACE', 'papua'), ('PERSON', 'roemkorem'), ('PERSON', 'prai'), ('PLACE', 'papua barat')]\n",
      "ner_tag_answer: [('NULL', '1 Juli 1971')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▉                                                  | 21/53 [03:26<05:09,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: California, Amerika Serikat\n",
      "ner_tag_premise: [('PLACE', 'amerika'), ('PLACE', 'california'), ('PLACE', 'amerika serikat')]\n",
      "ner_tag_answer: [('NULL', 'California, Amerika Serikat')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▍                                                | 22/53 [03:39<05:24, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 4 Februari 1937\n",
      "ner_tag_premise: [('ORGANISATION', 'walt disney'), ('ORGANISATION', 'rko radio pictures'), ('PLACE', 'bioskop'), ('PLACE', 'carthay circle'), ('PLACE', 'amerika serikat'), ('ORGANISATION', '##s grimm'), ('PERSON', 'snow white'), ('PLACE', 'amerika serikat'), ('ORGANISATION', 'walt disney'), ('ORGANISATION', 'disney'), ('ORGANISATION', 'walt disney')]\n",
      "ner_tag_answer: [('NULL', '4 Februari 1937')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████                                               | 23/53 [03:48<05:07, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Karl Marx\n",
      "ner_tag_premise: [('PERSON', 'karl marx'), ('PERSON', 'marx'), ('PERSON', 'marx'), ('PERSON', 'friedrich engels')]\n",
      "ner_tag_answer: [('PERSON', 'karl marx')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▌                                             | 24/53 [03:57<04:42,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Kastilia\n",
      "ner_tag_premise: [('PLACE', 'republik dominika'), ('PLACE', 'karibia'), ('PLACE', 'eropa'), ('PLACE', 'afrika'), ('PLACE', 'kastilia'), ('PLACE', 'spanyol'), ('PLACE', 'inggris'), ('PLACE', 'perancis'), ('PLACE', 'jerman'), ('PLACE', 'haiti'), ('PLACE', 'italia'), ('PLACE', 'eropa'), ('PLACE', 'afrika'), ('PLACE', 'taino')]\n",
      "ner_tag_answer: [('PLACE', 'kastilia')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████████▏                                           | 25/53 [04:00<03:36,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Pangeran Samudra\n",
      "ner_tag_premise: [('PERSON', 'pangeran samudra'), ('PLACE', 'kerajaan banjar'), ('PERSON', 'sultan suriansyah'), ('PERSON', 'khat'), ('PERSON', '##ib dayan')]\n",
      "ner_tag_answer: [('PERSON', 'pangeran samudra')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████████▋                                          | 26/53 [04:15<04:25,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 78,772km\n",
      "ner_tag_premise: [('PLACE', 'skotlandia'), ('PLACE', 'pulau britania raya'), ('PLACE', 'benua eropa'), ('PLACE', 'skotlandia'), ('PLACE', 'jawa'), ('PLACE', 'inggris'), ('PLACE', 'skotlandia'), ('PLACE', 'basin sungai tweed'), ('PLACE', 'solway firth'), ('PLACE', 'skotlandia'), ('PLACE', 'atlantik'), ('PLACE', 'laut utara'), ('PLACE', 'pulau irlandia'), ('PLACE', 'kintyre'), ('PLACE', 'norwegia'), ('PLACE', 'kepulauan faroe')]\n",
      "ner_tag_answer: [('NULL', '78,772km')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████████▎                                        | 27/53 [04:25<04:18,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1838\n",
      "ner_tag_premise: [('PLACE', 'pulau pitcairn'), ('PLACE', 'inggris'), ('PLACE', 'pulau pitcairn'), ('PLACE', 'inggris'), ('PLACE', 'inggris'), ('PLACE', 'pulau norfolk'), ('PLACE', 'pulau pitcairn'), ('PLACE', 'pulau norfolk'), ('PLACE', 'morayshire'), ('PLACE', 'pulau norfork'), ('PLACE', 'pitcairn'), ('PLACE', 'norfolk'), ('PLACE', 'pulau pitcairn')]\n",
      "ner_tag_answer: [('NULL', '1838')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████▊                                       | 28/53 [04:37<04:25, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1939\n",
      "ner_tag_premise: [('PERSON', 'albert einstein'), ('PLACE', 'as'), ('PERSON', 'franklin d. roosevelt'), ('PLACE', 'as'), ('PLACE', 'manhattan'), ('PLACE', 'jerman'), ('PLACE', 'jerman'), ('PLACE', 'jepang')]\n",
      "ner_tag_answer: [('NULL', '1939')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▍                                     | 29/53 [04:43<03:40,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1951\n",
      "ner_tag_premise: [('PERSON', 'david mcclure brinkley'), ('ORGANISATION', 'nbc'), ('ORGANISATION', 'abc'), ('PLACE', 'amerika serikat'), ('PLACE', 'north carolina')]\n",
      "ner_tag_answer: [('NULL', '1951')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████▉                                    | 30/53 [04:53<03:36,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: keinginan mereka untuk tidak terlibat dalam konfrontasi ideologi Barat-Timur\n",
      "ner_tag_premise: [('PLACE', 'asia'), ('PLACE', 'afrika'), ('PLACE', 'bandung'), ('PLACE', 'indonesia'), ('PERSON', 'josip broz tito'), ('PLACE', 'yugoslavia'), ('PERSON', 'soekarno'), ('PLACE', 'indonesia'), ('PERSON', 'gamal abdul nasser'), ('PLACE', 'mesir'), ('PERSON', 'pandit jawaharlal nehru'), ('PLACE', 'india'), ('PERSON', 'kwame nkrumah'), ('PLACE', 'ghana')]\n",
      "ner_tag_answer: [('NULL', 'keinginan mereka untuk tidak terlibat dalam konfrontasi ideologi Barat-Timur')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████████▌                                  | 31/53 [04:57<02:53,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1679\n",
      "ner_tag_premise: [('PLACE', 'kesultanan kanoman'), ('PLACE', 'kesultanan kasepuhan'), ('PERSON', 'sultan anom i pangeran muhammad badrudin kartawijaya')]\n",
      "ner_tag_answer: [('NULL', '1679')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████                                 | 32/53 [05:10<03:17,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 25 April 1833\n",
      "ner_tag_premise: [('PERSON', 'marko miljanov popovic'), ('PLACE', 'brda'), ('PLACE', 'montenegro'), ('PERSON', 'danilo i'), ('PLACE', 'montenegro'), ('PLACE', 'kuci'), ('PLACE', 'utsman'), ('PLACE', 'montenegro'), ('PERSON', 'miljanov'), ('PERSON', 'nikola i'), ('PLACE', 'montenegro'), ('PERSON', 'olgivanna lloyd wright'), ('PERSON', 'frank lloyd wright'), ('PLACE', 'amerika serikat')]\n",
      "ner_tag_answer: [('NULL', '25 April 1833')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████▋                               | 33/53 [05:15<02:41,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: kumpulan benda langit yang terdiri atas sebuah bintang yang disebut Matahari dan semua objek yang terikat oleh gaya gravitasinya\n",
      "ner_tag_premise: ['NO TOKEN DETECTED']\n",
      "ner_tag_answer: [('NULL', 'kumpulan benda langit yang terdiri atas sebuah bintang yang disebut Matahari dan semua objek yang terikat oleh gaya gravitasinya')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████████▏                             | 34/53 [05:21<02:21,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1930\n",
      "ner_tag_premise: [('ORGANISATION', 'majalah'), ('ORGANISATION', 'panji pustaka jakarta'), ('ORGANISATION', 'sinar deli medan'), ('PERSON', 'h. moh. said'), ('ORGANISATION', 'harian waspada'), ('PERSON', 'h. moh. said')]\n",
      "ner_tag_answer: [('NULL', '1930')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████▊                            | 35/53 [05:35<02:50,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: B&W Seaplane\n",
      "ner_tag_premise: [('PERSON', 'william boeing'), ('PERSON', 'george conrad westervelt'), ('PLACE', 'as'), ('ORGANISATION', 'boeing'), ('PERSON', 'westervelt'), ('PERSON', 'curtiss'), ('ORGANISATION', 'boeing'), ('PERSON', 'glenn martin'), ('PERSON', 'glenn martin'), ('PERSON', 'martin'), ('ORGANISATION', 'boeing'), ('ORGANISATION', 'boeing'), ('PERSON', 'cdr. g. c. westervelt'), ('ORGANISATION', 'boeing'), ('PLACE', 'seattle lake union'), ('ORGANISATION', 'boeing')]\n",
      "ner_tag_answer: [('NULL', 'B&W Seaplane')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████▍                          | 36/53 [05:40<02:18,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 2004-2007\n",
      "ner_tag_premise: [('PERSON', 'christoph blocher'), ('PLACE', 'schaffhausen'), ('PLACE', 'swiss'), ('PLACE', 'swiss'), ('ORGANISATION', 'dewan federal swiss'), ('ORGANISATION', 'partai rakyat swiss'), ('ORGANISATION', 'ems'), ('ORGANISATION', 'chemie')]\n",
      "ner_tag_answer: [('NULL', '2004-2007')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▉                         | 37/53 [05:48<02:07,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Masohi\n",
      "ner_tag_premise: [('PLACE', 'kabupaten maluku tengah'), ('PLACE', 'maluku'), ('PLACE', 'indonesia'), ('PLACE', 'masohi'), ('PLACE', 'pulau seram'), ('PLACE', 'kecamatan amahai'), ('PLACE', 'tehoru'), ('PLACE', 'kota masohi'), ('PLACE', 'pulau ambon'), ('PLACE', 'kecamatan leihitu'), ('PLACE', 'salahutu')]\n",
      "ner_tag_answer: [('PLACE', 'masohi')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████▌                       | 38/53 [05:57<02:05,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: pita frekuensi radio tertinggi\n",
      "ner_tag_premise: [('PLACE', 'english'), ('ORGANISATION', 'eh'), ('ORGANISATION', 'eh')]\n",
      "ner_tag_answer: [('NULL', 'pita frekuensi radio tertinggi')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████                      | 39/53 [06:10<02:15,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Triticum spp\n",
      "ner_tag_premise: [('PLACE', 'nepal'), ('ORGANISATION', 'triticum')]\n",
      "ner_tag_answer: [('NULL', 'Triticum spp')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▋                    | 40/53 [06:21<02:10, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1809\n",
      "ner_tag_premise: [('PERSON', 'samuel thomas von sommering'), ('PERSON', 'baron schilling'), ('PERSON', 'carl friedrich gauss'), ('PERSON', 'wilhelm weber'), ('PLACE', 'gottingen'), ('PERSON', 'william fothergill cooke'), ('ORGANISATION', 'great western railway'), ('PLACE', 'inggris'), ('PLACE', 'inggris'), ('PLACE', 'stasiun'), ('PLACE', 'paddington'), ('PLACE', 'west drayton')]\n",
      "ner_tag_answer: [('NULL', '1809')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████▏                  | 41/53 [06:25<01:40,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: mempersiapkan anggotanya dalam berbagai bidang pelayanan (pendidikan, sosial, politik, kemasyarakatan, dll) di Indonesia\n",
      "ner_tag_premise: [('ORGANISATION', 'gerakan angkatan muda kristen indonesia'), ('ORGANISATION', 'gamki'), ('PLACE', 'indonesia')]\n",
      "ner_tag_answer: [('NULL', 'mempersiapkan anggotanya dalam berbagai bidang pelayanan (pendidikan, sosial, politik, kemasyarakatan, dll) di Indonesia')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████████▊                 | 42/53 [06:34<01:31,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Gudeg\n",
      "ner_tag_premise: [('PLACE', 'jawa'), ('PLACE', 'yogyakarta'), ('PLACE', 'jawa tengah')]\n",
      "ner_tag_answer: [('NULL', 'Gudeg')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████▎               | 43/53 [06:39<01:15,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 14\n",
      "ner_tag_premise: [('ORGANISATION', 'ui')]\n",
      "ner_tag_answer: [('NULL', '14')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████▉              | 44/53 [06:49<01:12,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 24\n",
      "ner_tag_premise: [('ORGANISATION', 'tv tokyo jepang'), ('ORGANISATION', 'akb48'), ('ORGANISATION', 'ske48'), ('ORGANISATION', 'sdn48')]\n",
      "ner_tag_answer: [('NULL', '24')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████▍            | 45/53 [06:54<00:58,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Peso\n",
      "ner_tag_premise: [('ORGANISATION', 'mx'), ('PLACE', 'meksiko')]\n",
      "ner_tag_answer: [('NULL', 'Peso')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████████████████           | 46/53 [07:05<00:59,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Hindia Timur\n",
      "ner_tag_premise: [('PLACE', 'asia'), ('PLACE', 'asia'), ('PLACE', 'asia'), ('PLACE', 'hindia timur'), ('PLACE', 'sumatra'), ('PLACE', '##dang')]\n",
      "ner_tag_answer: [('PLACE', 'hindia timur')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████▌         | 47/53 [07:10<00:44,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: pemain sepak bola berkewarganegaraan Inggris\n",
      "ner_tag_premise: [('PERSON', 'jordan spence'), ('PLACE', 'inggris'), ('ORGANISATION', 'milton keynes dons')]\n",
      "ner_tag_answer: [('NULL', 'pemain sepak bola berkewarganegaraan Inggris')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████████████████▏       | 48/53 [07:21<00:41,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1293\n",
      "ner_tag_premise: [('PLACE', 'kerajaan majapahit'), ('PLACE', 'javanes'), ('PLACE', 'nagari kara'), ('PLACE', 'wilwati'), ('PLACE', 'jawa timur'), ('PLACE', 'indonesia'), ('PLACE', 'nusantara'), ('PERSON', 'hayam wuruk')]\n",
      "ner_tag_answer: [('NULL', '1293')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████████▋      | 49/53 [07:29<00:33,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Agra, India\n",
      "ner_tag_premise: [('PLACE', 'taj mahal'), ('PLACE', 'urdu'), ('PLACE', 'agra'), ('PLACE', 'india'), ('PLACE', 'mughal'), ('PERSON', 'shah jahan'), ('PERSON', 'jahangir'), ('PLACE', 'persia'), ('PERSON', 'arjumand banu begum'), ('PLACE', 'mumtaz - ul -'), ('PLACE', 'mumtaz mahal'), ('PLACE', 'taj mahal'), ('PLACE', 'mughal')]\n",
      "ner_tag_answer: [('NULL', 'Agra, India')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████▎    | 50/53 [07:34<00:21,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: suatu istilah yang mulai digunakan pada tahun 1920-an untuk mengistilahkan jenis media yang secara khusus didesain untuk mencapai masyarakat yang sangat luas\n",
      "ner_tag_premise: ['NO TOKEN DETECTED']\n",
      "ner_tag_answer: [('NULL', 'suatu istilah yang mulai digunakan pada tahun 1920-an untuk mengistilahkan jenis media yang secara khusus didesain untuk mencapai masyarakat yang sangat luas')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████████████▊   | 51/53 [07:42<00:14,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 03 April 1973\n",
      "ner_tag_premise: [('PERSON', 'martin cooper'), ('ORGANISATION', 'motorola'), ('ORGANISATION', 'motorola'), ('PERSON', 'cooper'), ('PERSON', 'cooper')]\n",
      "ner_tag_answer: [('NULL', '03 April 1973')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████████████▊   | 51/53 [08:03<00:18,  9.47s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_nli_train_df \u001b[38;5;241m=\u001b[39m \u001b[43madd_ner_and_chunking_all_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_nli_train_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data_nli_val_df \u001b[38;5;241m=\u001b[39m add_ner_and_chunking_all_tag(data_nli_val_df)\n\u001b[1;32m      3\u001b[0m data_nli_test_df \u001b[38;5;241m=\u001b[39m add_ner_and_chunking_all_tag(data_nli_test_df)\n",
      "Cell \u001b[0;32mIn[35], line 18\u001b[0m, in \u001b[0;36madd_ner_and_chunking_all_tag\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     15\u001b[0m chunking_premise_array \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tag_premise\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m=\u001b[39m add_premise_tag(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, ner_premise_array)\n\u001b[0;32m---> 18\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunking_tag_premise\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m=\u001b[39m \u001b[43madd_premise_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunking\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunking_premise_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tag_answer\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m=\u001b[39m add_row_tag(answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner_tag_premise\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m     21\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunking_tag_answer\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m=\u001b[39m add_row_tag(answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunking\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunking_tag_premise\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m, in \u001b[0;36madd_premise_tag\u001b[0;34m(data, tag, index, premise_array, ner, chunking)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools\u001b[38;5;241m=\u001b[39mner\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: tools\u001b[38;5;241m=\u001b[39mchunking\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpremise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m     premise_array\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO TOKEN DETECTED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/token_classification.py:216\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offset_mapping\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1084\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1077\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1078\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m     )\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1091\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1090\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1091\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:992\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m    991\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 992\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pipelines/token_classification.py:242\u001b[0m, in \u001b[0;36mTokenClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(model_inputs\u001b[38;5;241m.\u001b[39mdata)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: special_tokens_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m    250\u001b[0m }\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:1760\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1760\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1774\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:1019\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1012\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1013\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1014\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1018\u001b[0m )\n\u001b[0;32m-> 1019\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1032\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    602\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:549\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 549\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:449\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 449\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_nli_train_df = add_ner_and_chunking_all_tag(data_nli_train_df)\n",
    "data_nli_val_df = add_ner_and_chunking_all_tag(data_nli_val_df)\n",
    "data_nli_test_df = add_ner_and_chunking_all_tag(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49a3e4",
   "metadata": {},
   "source": [
    "# Create wrong answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b5991",
   "metadata": {},
   "source": [
    "This is the flow to create wrong answer:\n",
    "\n",
    "1. Check the NER and POS/Chunking labels of the right_answer and context/premise.\n",
    "\n",
    "2. Search and group NER and POS/Chunking labels that match the right_answer throughout the context/premise.\n",
    "\n",
    "3. Perform NER classification. There will be two branches here, namely:\n",
    "\n",
    "   3a. If the NER of the right_answer can be detected, then calculate the distance using semantic similarity or word vectors between the right_answer and various possible wrong_answers with the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "   \n",
    "   3b. If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "   \n",
    "4. Perform POS/Chunking classification. Continuation from point 3b. There will be two more branches:\n",
    "\n",
    "   4a. If the POS/Chunking of the right_answer can be detected, then calculate the distance using semantic similarity or word vectors between the right_answer and various possible wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "   \n",
    "   4b. If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise does not contain any of NER of right_answer, then the final wrong_answer will be chosen based on a random word (random_word) from the context/premise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d00a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_similarity = SentenceTransformer(MODEL_SIMILARITY_NAME)\n",
    "\n",
    "def return_similarity_sorted_array(right_answer, sentence_array, model=model_similarity):\n",
    "    \n",
    "    right_answer = right_answer.lower()\n",
    "    \n",
    "    embedding_right_answer = model.encode([right_answer], convert_to_tensor=True, device=device)\n",
    "    embedding_sentence_array = model.encode(sentence_array, convert_to_tensor=True, device=device)\n",
    "    \n",
    "    cosine_scores = util.pytorch_cos_sim(embedding_right_answer, embedding_sentence_array)\n",
    "    \n",
    "    sorted_indices = cosine_scores.argsort(descending=True)[0]\n",
    "    sorted_array = [sentence_array[i] for i in sorted_indices]\n",
    "    \n",
    "    return sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_values_with_hash(arr):\n",
    "    return [item for item in arr if \"#\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(URL_STOPWORD)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    stopword_data = response.json()\n",
    "else:\n",
    "    print(\"Failed to download JSON.\")\n",
    "\n",
    "stopword_data = set([item for sublist in list(stopword_data.values()) for item in sublist])\n",
    "stopword_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_word(text, stopword_data=stopword_data):\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    filtered_words = [word for word in words if word not in stopword_data and word not in string.punctuation]\n",
    "    random_word = random.choice(filtered_words)\n",
    "    return random_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0afd1-e751-4cb8-ae22-1b7bb10a5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_same_tag(tag_answers, tag_premises, same_tag_array):\n",
    "\n",
    "    for tag_premise in tag_premises:\n",
    "\n",
    "        label_tag_premise = tag_premise[0]\n",
    "        word_premise = tag_premise[1]\n",
    "\n",
    "        for tag_answer in tag_answers:\n",
    "            \n",
    "            label_tag_answer = tag_answer[0]\n",
    "            \n",
    "            if label_tag_answer == label_tag_premise:\n",
    "                same_tag_array.append(word_premise)\n",
    "\n",
    "    return remove_values_with_hash(same_tag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_only_punctuation(text):\n",
    "    return all(char in string.punctuation for char in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_plausible_answer(answer, plausible_answer_array):\n",
    "    \n",
    "    answer = answer.lower()\n",
    "    \n",
    "    plausible_answer_array = [item.lower().strip() for item in plausible_answer_array]\n",
    "    plausible_answer_array = [string for string in plausible_answer_array if not contains_only_punctuation(string)]\n",
    "    plausible_answer_array = [remove_punctuation(text) for text in plausible_answer_array]\n",
    "    \n",
    "    final_plausible_answer_array = []\n",
    "    answer_words = set(remove_punctuation(text) for text in answer.split())\n",
    "    \n",
    "    for plausible_answer in plausible_answer_array:\n",
    "        plausible_answer_words = set(plausible_answer.split())\n",
    "        if not plausible_answer_words.intersection(answer_words):\n",
    "            final_plausible_answer_array.append(plausible_answer)\n",
    "    \n",
    "    return final_plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369eced-0cee-4d0d-a436-89a97d2af242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_similarity(data, right_answer, index, tag, plausible_answer_array, premise):\n",
    "\n",
    "    if tag == \"ner\": slice='same_ner_tag_answer'\n",
    "    elif tag == \"chunking\": slice='same_chunking_tag_answer'\n",
    "    else: slice=None\n",
    "\n",
    "    # Find all the sorted (by similarity) plausible wrong answer, \n",
    "    # and remove hask & punctuation only answer\n",
    "    if slice != None:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, data[slice][index])\n",
    "    else:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, plausible_answer_array)\n",
    "    \n",
    "    plausible_answer_array = remove_values_with_hash(wrong_answer_array)\n",
    "    plausible_answer_array = filtering_plausible_answer(right_answer, plausible_answer_array)\n",
    "    \n",
    "    try:\n",
    "        # Only return the most similar to right_answer\n",
    "        wrong_answer = plausible_answer_array[0].strip()\n",
    "        \n",
    "        if tag == \"ner\": \n",
    "            properties = \"IDENTICAL NER labels were found, and the highest similarity score same NER array was selected\"\n",
    "        elif tag == \"chunking\":\n",
    "            properties = \"IDENTICAL Chunking labels were found, and the highest similarity score from same Chunking array was selected\"\n",
    "        else:\n",
    "            properties = \"NO CHUNKING labels were found, and the highest similarity score from plausible answer was selected\"\n",
    "    except:\n",
    "        wrong_answer = select_random_word(premise)\n",
    "        \n",
    "        if tag == \"ner\": \n",
    "            properties = \"Detected (NER) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "        elif tag == \"chunking\":\n",
    "            properties = \"Detected (Chunking) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "        else:\n",
    "            properties = \"Detected (Random) wrong answer that is the SAME as the right answer, search random word from premise\"\n",
    "    \n",
    "    assert isinstance(wrong_answer, str)\n",
    "    assert isinstance(plausible_answer_array, list)\n",
    "    \n",
    "    return wrong_answer, plausible_answer_array, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97759144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong_answer(data):\n",
    "    \n",
    "    data['same_ner_tag_answer'] = \"\"\n",
    "    data['same_chunking_tag_answer'] = \"\"\n",
    "    data['wrong_answer'] = \"\"\n",
    "    data['plausible_answer_based_on_method'] = \"\"\n",
    "    data['properties'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        right_answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "\n",
    "        same_ner_tag_answer_array = []\n",
    "        same_chunking_tag_answer_array = []\n",
    "\n",
    "        ner_tag_answer = data['ner_tag_answer'][i]\n",
    "        ner_tag_premise = data['ner_tag_premise'][i]\n",
    "\n",
    "        chunking_tag_answer = data['chunking_tag_answer'][i]\n",
    "        chunking_tag_premise = data['chunking_tag_premise'][i]\n",
    "        \n",
    "        # Grouped with the same NER & Chunking group, between answer and word of premise\n",
    "        data['same_ner_tag_answer'][i] = grouping_same_tag(ner_tag_answer,\n",
    "                                                           ner_tag_premise,\n",
    "                                                           same_ner_tag_answer_array)\n",
    "        \n",
    "        data['same_chunking_tag_answer'][i] = grouping_same_tag(chunking_tag_answer, \n",
    "                                                                chunking_tag_premise, \n",
    "                                                                same_chunking_tag_answer_array)\n",
    "        \n",
    "        # Start to create wrong answer\n",
    "        plausible_answer_array = []\n",
    "\n",
    "        # Perform NER classification\n",
    "        # If the NER of the right_answer can be detected, then calculate the distance using semantic \n",
    "        # similarity or word vectors between the right_answer and various possible wrong_answers with \n",
    "        # the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "        if data['same_ner_tag_answer'][i] != []:\n",
    "            wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                      i, \"ner\", plausible_answer_array, premise)\n",
    "            \n",
    "        # If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain \n",
    "        # any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "        # Perform POS/Chunking classification\n",
    "        else:\n",
    "            # If the POS/Chunking of the right_answer can be detected, then calculate the distance \n",
    "            # using semantic similarity or word vectors between the right_answer and various possible \n",
    "            # wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the \n",
    "            # final wrong_answer.\n",
    "            if data['same_chunking_tag_answer'][i] != []:\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"chunking\", plausible_answer_array, premise)\n",
    "            \n",
    "            # If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise \n",
    "            # does not contain any of NER of right_answer, then the final wrong_answer will be chosen \n",
    "            # based on a random word (random_word) from the context/premise.\n",
    "            else:\n",
    "                for chunking_tag in chunking_tag_premise:\n",
    "                    plausible_answer_array.append(chunking_tag[1])\n",
    "\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"none\", plausible_answer_array, premise)\n",
    "        data['properties'][i] = properties\n",
    "        data['wrong_answer'][i] = wrong_answer\n",
    "        data['plausible_answer_based_on_method'][i] = plausible_answer_array\n",
    "            \n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3230a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong_answer_with_removing_invalid_data(data):\n",
    "    \n",
    "    data['same_ner_tag_answer'] = \"\"\n",
    "    data['same_chunking_tag_answer'] = \"\"\n",
    "    data['wrong_answer'] = \"\"\n",
    "    data['plausible_answer_based_on_method'] = \"\"\n",
    "    data['properties'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        right_answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "\n",
    "        same_ner_tag_answer_array = []\n",
    "        same_chunking_tag_answer_array = []\n",
    "\n",
    "        ner_tag_answer = data['ner_tag_answer'][i]\n",
    "        ner_tag_premise = data['ner_tag_premise'][i]\n",
    "\n",
    "        chunking_tag_answer = data['chunking_tag_answer'][i]\n",
    "        chunking_tag_premise = data['chunking_tag_premise'][i]\n",
    "        \n",
    "        # Grouped with the same NER & Chunking group, between answer and word of premise\n",
    "        data['same_ner_tag_answer'][i] = grouping_same_tag(ner_tag_answer,\n",
    "                                                           ner_tag_premise,\n",
    "                                                           same_ner_tag_answer_array)\n",
    "        \n",
    "        data['same_chunking_tag_answer'][i] = grouping_same_tag(chunking_tag_answer, \n",
    "                                                                chunking_tag_premise, \n",
    "                                                                same_chunking_tag_answer_array)\n",
    "        \n",
    "        # Start to create wrong answer\n",
    "        plausible_answer_array = []\n",
    "        \n",
    "        # Golden rules: If same_NER isn't there, just drop it. If NER is NULL, check chunking\n",
    "        \n",
    "        if ner_tag_answer[0][0] == \"NULL\":\n",
    "            if data['same_chunking_tag_answer'][i] != []:\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"chunking\", plausible_answer_array, premise)\n",
    "            else:\n",
    "                for chunking_tag in chunking_tag_premise:\n",
    "                    plausible_answer_array.append(chunking_tag[1])\n",
    "\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"none\", plausible_answer_array, premise)\n",
    "            data['properties'][i] = properties\n",
    "            data['wrong_answer'][i] = wrong_answer\n",
    "            data['plausible_answer_based_on_method'][i] = plausible_answer_array\n",
    "            continue\n",
    "\n",
    "        # Perform NER classification\n",
    "        # If the NER of the right_answer can be detected, then calculate the distance using semantic \n",
    "        # similarity or word vectors between the right_answer and various possible wrong_answers with \n",
    "        # the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "        if data['same_ner_tag_answer'][i] != [] and ner_tag_answer[0][0] != \"NULL\":\n",
    "            wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                      i, \"ner\", plausible_answer_array, premise)\n",
    "            \n",
    "        # If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain \n",
    "        # any of NER of right_answer, then drop that particular row data.\n",
    "        else:\n",
    "            data.drop(i, inplace=True)\n",
    "            data.reset_index(drop=True)\n",
    "            \n",
    "        data['properties'][i] = properties\n",
    "        data['wrong_answer'][i] = wrong_answer\n",
    "        data['plausible_answer_based_on_method'][i] = plausible_answer_array\n",
    "            \n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = create_wrong_answer(data_nli_train_df)\n",
    "data_nli_val_df = create_wrong_answer(data_nli_val_df)\n",
    "data_nli_test_df = create_wrong_answer(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_nli_train_df)):\n",
    "    print(\"Iterasi:\", i)\n",
    "    #print(\"Premise:\", data_nli_train_df['premise'][i])\n",
    "    print(\"Right answer:\", data_nli_train_df['answer'][i])\n",
    "    print(\"Wrong answer:\", data_nli_train_df['wrong_answer'][i])\n",
    "    #print(\"Same NER tag answer:\", data_nli_train_df['same_ner_tag_answer'][i])\n",
    "    #print(\"Same Chunking tag answer:\", data_nli_train_df['same_chunking_tag_answer'][i])\n",
    "    #print(\"Chunking tag premise\", data_nli_train_df['chunking_tag_premise'][i])\n",
    "    #print(\"Plausible answer:\", data_nli_train_df['plausible_answer_based_on_method'][i])\n",
    "    #print(\"Properties:\", data_nli_train_df['properties'][i])\n",
    "    #print(\"Overlap:\", check_string_overlap(data_nli_train_df['answer'][i].lower(), data_nli_train_df['wrong_answer'][i].lower()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_nli_train_df))\n",
    "print(len(data_nli_val_df))\n",
    "print(len(data_nli_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27634d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_create_wrong_answer(data):\n",
    "    assert all(data['properties'] != '')\n",
    "    assert all(data['wrong_answer'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_create_wrong_answer(data_nli_train_df)\n",
    "test_create_wrong_answer(data_nli_val_df)\n",
    "test_create_wrong_answer(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe61c82",
   "metadata": {},
   "source": [
    "# Split to two dataset: right dataset & wrong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_column_number(data, column_name=\"hypothesis\", column_num=3):\n",
    "\n",
    "    cols = list(data.columns)\n",
    "    cols.remove(column_name)\n",
    "    cols.insert(column_num, column_name)\n",
    "\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56880d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['wrong_answer']\n",
    "\n",
    "data_nli_right_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_right_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_right_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['answer']\n",
    "\n",
    "data_nli_wrong_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_wrong_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_wrong_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_wrong_train_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_wrong_val_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_wrong_test_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "\n",
    "data_nli_wrong_train_df = move_to_column_number(data_nli_wrong_train_df, \"answer\", 2)\n",
    "data_nli_wrong_val_df = move_to_column_number(data_nli_wrong_val_df, \"answer\", 2)\n",
    "data_nli_wrong_test_df = move_to_column_number(data_nli_wrong_test_df, \"answer\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6f08",
   "metadata": {},
   "source": [
    "# Convert question-answer pair to hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_paraphraser = pipeline(task = TASK_PARAPHRASER_NAME, \n",
    "                     model = MODEL_PARAPHRASER_NAME, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_PARAPHRASER_NAME, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_question_and_answer_to_hypothesis(data):\n",
    "    for i in range(len(data)):\n",
    "        #data['hypothesis'] = data['question'] + ' ' + data['answer']\n",
    "        data['hypothesis'] = str(nlp_tools_paraphraser(data['question'] + ' ' + data['answer'])[0]['generated_text'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf340e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_right_train_df = convert_question_and_answer_to_hypothesis(data_nli_right_train_df)\n",
    "data_nli_right_val_df = convert_question_and_answer_to_hypothesis(data_nli_right_val_df)\n",
    "data_nli_right_test_df = convert_question_and_answer_to_hypothesis(data_nli_right_test_df)\n",
    "\n",
    "data_nli_right_train_df = move_to_column_number(data_nli_right_train_df, \"hypothesis\", 3)\n",
    "data_nli_right_val_df = move_to_column_number(data_nli_right_val_df, \"hypothesis\", 3)\n",
    "data_nli_right_test_df = move_to_column_number(data_nli_right_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20241aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_wrong_train_df = convert_question_and_answer_to_hypothesis(data_nli_wrong_train_df)\n",
    "data_nli_wrong_val_df = convert_question_and_answer_to_hypothesis(data_nli_wrong_val_df)\n",
    "data_nli_wrong_test_df = convert_question_and_answer_to_hypothesis(data_nli_wrong_test_df)\n",
    "\n",
    "data_nli_wrong_train_df = move_to_column_number(data_nli_wrong_train_df, \"hypothesis\", 3)\n",
    "data_nli_wrong_val_df = move_to_column_number(data_nli_wrong_val_df, \"hypothesis\", 3)\n",
    "data_nli_wrong_test_df = move_to_column_number(data_nli_wrong_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c4ace",
   "metadata": {},
   "source": [
    "# Add label: entailment & contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_right_train_df['label'] = 'entailment'\n",
    "data_nli_right_val_df['label'] = 'entailment'\n",
    "data_nli_right_test_df['label'] = 'entailment'\n",
    "\n",
    "data_nli_right_train_df = move_to_column_number(data_nli_right_train_df, \"label\", 4)\n",
    "data_nli_right_val_df = move_to_column_number(data_nli_right_val_df, \"label\", 4)\n",
    "data_nli_right_test_df = move_to_column_number(data_nli_right_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02098578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_wrong_train_df['label'] = 'contradiction'\n",
    "data_nli_wrong_val_df['label'] = 'contradiction'\n",
    "data_nli_wrong_test_df['label'] = 'contradiction'\n",
    "\n",
    "data_nli_wrong_train_df = move_to_column_number(data_nli_wrong_train_df, \"label\", 4)\n",
    "data_nli_wrong_val_df = move_to_column_number(data_nli_wrong_val_df, \"label\", 4)\n",
    "data_nli_wrong_test_df = move_to_column_number(data_nli_wrong_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f431144",
   "metadata": {},
   "source": [
    "# Concat the right and wrong NLI to one NLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final = pd.concat([data_nli_right_train_df, data_nli_wrong_train_df], axis=0, ignore_index=True)\n",
    "data_nli_val_df_final = pd.concat([data_nli_right_val_df, data_nli_wrong_val_df], axis=0, ignore_index=True)\n",
    "data_nli_test_df_final = pd.concat([data_nli_right_test_df, data_nli_wrong_test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea9097",
   "metadata": {},
   "source": [
    "# Convert to DataFrame format to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ae44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final.to_csv(\"data_nli_train_df_paraphrase.csv\", index=False)\n",
    "data_nli_val_df_final.to_csv(\"data_nli_val_df_paraphrase.csv\", index=False)\n",
    "data_nli_test_df_final.to_csv(\"data_nli_test_df_paraphrase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28862303-7b4c-4279-91b3-b5efcdf00e75",
   "metadata": {},
   "source": [
    "# Push to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d50f6c-1e40-4087-9f6c-f5bc5aaaa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HUB_TOKEN = \"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\"\n",
    "USER = \"muhammadravi251001\"\n",
    "REPO = \"idk-mrc-nli\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"data_nli_train_df.csv\",\n",
    "    path_in_repo=\"data_nli_train_df.csv\",\n",
    "    repo_id=f\"{USER}/{REPO}\",\n",
    "    token=HUB_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"data_nli_val_df.csv\",\n",
    "    path_in_repo=\"data_nli_val_df.csv\",\n",
    "    repo_id=f\"{USER}/{REPO}\",\n",
    "    token=HUB_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"data_nli_test_df.csv\",\n",
    "    path_in_repo=\"data_nli_test_df.csv\",\n",
    "    repo_id=f\"{USER}/{REPO}\",\n",
    "    token=HUB_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PROGRAM FINISHED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
