{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9171daa4",
   "metadata": {},
   "source": [
    "# Define tool and model of the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41849a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "TOOLS_NAME_NER = \"ner\"\n",
    "MODEL_TOOLS_NAME_NER = \"ageng-anugrah/indobert-large-p2-finetuned-ner\"\n",
    "\n",
    "TOOLS_NAME_POS = \"token-classification\"\n",
    "MODEL_TOOLS_NAME_POS = \"ageng-anugrah/indobert-large-p2-finetuned-chunking\"\n",
    "\n",
    "MODEL_SIMILARITY_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "\n",
    "# SAMPLE = sys.maxsize\n",
    "SAMPLE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9fdd4",
   "metadata": {},
   "source": [
    "# Import anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26d313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import string\n",
    "import contextlib\n",
    "import gc\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from evaluate import load\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "from datetime import datetime\n",
    "from huggingface_hub import notebook_login\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import HfApi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    Dataset,\n",
    "    DatasetDict\n",
    ")\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback, \n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cd27c",
   "metadata": {},
   "source": [
    "# Retrieve QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafbf0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset idk_mrc (/root/.cache/huggingface/datasets/idk_mrc/idk_mrc_source/1.0.0/cf468d86fa7341e69998db1449851672ebfb4fa46036929d66b9de15c421334f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4463af6e94c43d18f9b9ae5667276ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3659/3659 [00:16<00:00, 215.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 358/358 [00:01<00:00, 268.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 378/378 [00:01<00:00, 273.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 9332\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 764\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "data_qas = conhelps.filtered(lambda x: 'idk_mrc' in x.dataset_name)[0].load_dataset()\n",
    "\n",
    "df_train = pd.DataFrame(data_qas['train'])\n",
    "df_validation = pd.DataFrame(data_qas['validation'])\n",
    "df_test = pd.DataFrame(data_qas['test'])\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_train['context']))):\n",
    "    for j in df_train[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                           \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                           \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                           ignore_index=True)\n",
    "        else:\n",
    "            new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                                'question': j['question'], \n",
    "                                                'answer': {\"text\": str(), \n",
    "                                                           \"answer_start\": 0, \n",
    "                                                           \"answer_end\": 0}}, \n",
    "                                                           ignore_index=True)\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_val = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_validation['context']))):\n",
    "    for j in df_validation[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)        \n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_test = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_test['context']))):\n",
    "    for j in df_test[\"qas\"][i]:\n",
    "        if len(j['answers']) != 0:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": j['answers'][0]['text'], \n",
    "                                                       \"answer_start\": j['answers'][0]['answer_start'], \n",
    "                                                       \"answer_end\": j['answers'][0]['answer_start'] + len(j['answers'][0]['text'])}}, \n",
    "                                                       ignore_index=True)\n",
    "        else:\n",
    "            new_df_test = new_df_test.append({'context': df_test[\"context\"][i], \n",
    "                                            'question': j['question'], \n",
    "                                            'answer': {\"text\": str(), \n",
    "                                                       \"answer_start\": 0, \n",
    "                                                       \"answer_end\": 0}}, \n",
    "                                                       ignore_index=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict(new_df_train)\n",
    "validation_dataset = Dataset.from_dict(new_df_val)\n",
    "test_dataset = Dataset.from_dict(new_df_test)\n",
    "\n",
    "data_qas = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset, \"test\": test_dataset})\n",
    "data_qas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae908a",
   "metadata": {},
   "source": [
    "# Convert to NLI, with hypothesis being just do concat question & answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c79ac",
   "metadata": {},
   "source": [
    "## Convert Dataset to DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b342b8ce-41f9-4714-84a5-1697cfee1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275dc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE == sys.maxsize:\n",
    "    data_qas_train_df = pd.DataFrame(data_qas[\"train\"][:SAMPLE])\n",
    "    data_qas_val_df = pd.DataFrame(data_qas[\"validation\"][:SAMPLE])\n",
    "    data_qas_test_df = pd.DataFrame(data_qas[\"test\"][:SAMPLE])\n",
    "\n",
    "else:\n",
    "    data_qas_train_df = (pd.DataFrame(data_qas[\"train\"])).sample(n=SAMPLE, random_state=42)\n",
    "    data_qas_val_df = (pd.DataFrame(data_qas[\"validation\"])).sample(n=SAMPLE, random_state=42)\n",
    "    data_qas_test_df = (pd.DataFrame(data_qas[\"test\"])).sample(n=SAMPLE, random_state=42)\n",
    "\n",
    "    data_qas_train_df = data_qas_train_df.reset_index(drop=True)\n",
    "    data_qas_val_df = data_qas_val_df.reset_index(drop=True)\n",
    "    data_qas_test_df = data_qas_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bbf0b",
   "metadata": {},
   "source": [
    "## Retrieve answer text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0424485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answer_text(data):\n",
    "    for i in range(len(data)):\n",
    "        data['answer'][i] = data['answer'][i]['text']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b1a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = retrieve_answer_text(data_qas_train_df)\n",
    "data_qas_val_df = retrieve_answer_text(data_qas_val_df)\n",
    "data_qas_test_df = retrieve_answer_text(data_qas_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84be34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_qas_train_df[data_qas_train_df['answer'] == '']\n",
    "y = data_qas_val_df[data_qas_val_df['answer'] == '']\n",
    "z = data_qas_test_df[data_qas_test_df['answer'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc421743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returning_answer_form_and_answer_that_suitable(data):\n",
    "    \n",
    "    for i in range(len(data['question'])):\n",
    "        \n",
    "        question = data['question'][i]\n",
    "\n",
    "        if \"apa\" in question.split():\n",
    "            answer_form = \"sentence\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        elif \"siapa\" in question.split():\n",
    "            answer_form = \"word\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        elif \"kapan\" in question.split():\n",
    "            answer_form = \"word\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        elif \"dimana\" in question.split():\n",
    "            answer_form = \"word\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        elif \"mengapa\" in question.split():\n",
    "            answer_form = \"sentence\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        elif \"bagaimana\" in question.split():\n",
    "            answer_form = \"sentence\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        elif \"berapa\" in question.split():\n",
    "            answer_form = \"word\"\n",
    "            answer_ner = \"\"\n",
    "        \n",
    "        else:\n",
    "            answer_form = \"word\"\n",
    "            answer_ner = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b1295",
   "metadata": {},
   "source": [
    "## Delete all unanswerable row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decb0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = data_qas_train_df[data_qas_train_df['answer'] != '']\n",
    "data_qas_val_df = data_qas_val_df[data_qas_val_df['answer'] != '']\n",
    "data_qas_test_df = data_qas_test_df[data_qas_test_df['answer'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3c125",
   "metadata": {},
   "source": [
    "### Reset index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2631db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qas_train_df = data_qas_train_df.reset_index(drop=True)\n",
    "data_qas_val_df = data_qas_val_df.reset_index(drop=True)\n",
    "data_qas_test_df = data_qas_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881d292",
   "metadata": {},
   "source": [
    "## Create NLI dataset from copy of QA dataset above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80799917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = [\n",
    "#    {\n",
    "#     \"Ir. Basuki Tjahaja Purnama, M.M. (EYD: Basuki Cahaya Purnama, nama Tionghoa: Zhōng Wànxué / 鍾萬學,[2] ), atau paling dikenal dengan panggilan Hakka Ahok (阿學), adalah Gubernur DKI Jakarta yang menjabat sejak 19 November 2014 hingga 9 Mei 2017.\", \n",
    "#     \"Siapakah Gubernur DKI Jakarta yang menjabat sejak tahun 2014?\", \n",
    "#     \"Basuki Tjahaja Purnama\"\n",
    "#    }\n",
    "#]\n",
    "\n",
    "#x = pd.DataFrame(x, columns=[\"answer\", \"question\", \"context\"])\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8808af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_qas_train_df.copy()\n",
    "data_nli_val_df = data_qas_val_df.copy()\n",
    "data_nli_test_df = data_qas_test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83072dc4",
   "metadata": {},
   "source": [
    "## Convert context pair to premise (only renaming column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1562622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df = data_nli_train_df.rename(columns={\"context\": \"premise\"})\n",
    "data_nli_val_df = data_nli_val_df.rename(columns={\"context\": \"premise\"})\n",
    "data_nli_test_df = data_nli_test_df.rename(columns={\"context\": \"premise\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33986ce",
   "metadata": {},
   "source": [
    "# Add contradiction label cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095664cc",
   "metadata": {},
   "source": [
    "## Import pipeline to create contradiction cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8850d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_ner = pipeline(task = TOOLS_NAME_NER, \n",
    "                     model = MODEL_TOOLS_NAME_NER, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_TOOLS_NAME_NER, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84dda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tools_chunking = pipeline(task = TOOLS_NAME_POS, \n",
    "                     model = MODEL_TOOLS_NAME_POS, \n",
    "                     tokenizer = AutoTokenizer.from_pretrained(MODEL_TOOLS_NAME_POS, \n",
    "                                                               model_max_length=512, \n",
    "                                                               truncation=True),\n",
    "                     aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae4a76",
   "metadata": {},
   "source": [
    "## Add NER and chunking tag column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c888804-88ec-4858-ba18-131545ee6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_tag(answer, tag, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "\n",
    "    retrieved_from_tools = tools(answer)\n",
    "    tag_answer_list = []\n",
    "    \n",
    "    if len(retrieved_from_tools) != 0:\n",
    "        for i in retrieved_from_tools:\n",
    "            tag_answer = (i['entity_group'], i['word'])\n",
    "            tag_answer_list.append(tag_answer)\n",
    "    else:\n",
    "        tag_answer = (\"NULL\", answer)\n",
    "        tag_answer_list.append(tag_answer)\n",
    "        \n",
    "    return tag_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee495118-61e1-4603-9194-690c0ae737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_premise_tag(data, tag, index, premise_array, ner=nlp_tools_ner, chunking=nlp_tools_chunking):\n",
    "\n",
    "    if tag == \"ner\": tools=ner\n",
    "    else: tools=chunking\n",
    "    \n",
    "    if len(tools(data['premise'][index])) == 0:\n",
    "        premise_array.append(\"NO TOKEN DETECTED\")\n",
    "    \n",
    "    else:\n",
    "        for j in tools(data['premise'][index]):\n",
    "            tag_premise = (j['entity_group'], j['word'])\n",
    "            premise_array.append(tag_premise)\n",
    "\n",
    "    return premise_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4967bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ner_and_chunking_all_tag(data):\n",
    "    \n",
    "    data['ner_tag_answer'] = \"\"\n",
    "    data['chunking_tag_answer'] = \"\"\n",
    "    \n",
    "    data['ner_tag_premise'] = \"\"\n",
    "    data['chunking_tag_premise'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "        \n",
    "        ner_premise_array = []\n",
    "        chunking_premise_array = []\n",
    "            \n",
    "        data['ner_tag_answer'][i] = add_row_tag(answer, \"ner\")\n",
    "        data['chunking_tag_answer'][i] = add_row_tag(answer, \"chunking\")\n",
    "                                                \n",
    "        data['ner_tag_premise'][i] = add_premise_tag(data, \"ner\", i, ner_premise_array)\n",
    "        data['chunking_tag_premise'][i] = add_premise_tag(data, \"chunking\", i, chunking_premise_array)  \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25cad8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [02:05<00:00,  4.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [02:01<00:00,  4.35s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 21/21 [01:25<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "data_nli_train_df = add_ner_and_chunking_all_tag(data_nli_train_df)\n",
    "data_nli_val_df = add_ner_and_chunking_all_tag(data_nli_val_df)\n",
    "data_nli_test_df = add_ner_and_chunking_all_tag(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49a3e4",
   "metadata": {},
   "source": [
    "# Create wrong answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b5991",
   "metadata": {},
   "source": [
    "This is the flow to create wrong answer:\n",
    "\n",
    "1. Check the NER and POS/Chunking labels of the right_answer and context/premise.\n",
    "\n",
    "2. Search and group NER and POS/Chunking labels that match the right_answer throughout the context/premise.\n",
    "\n",
    "3. Perform NER classification. There will be two branches here, namely:\n",
    "\n",
    "   3a. If the NER of the right_answer can be detected, then calculate the distance using semantic similarity or word vectors between the right_answer and various possible wrong_answers with the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "   \n",
    "   3b. If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "   \n",
    "4. Perform POS/Chunking classification. Continuation from point 3b. There will be two more branches:\n",
    "\n",
    "   4a. If the POS/Chunking of the right_answer can be detected, then calculate the distance using semantic similarity or word vectors between the right_answer and various possible wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "   \n",
    "   4b. If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise does not contain any of NER of right_answer, then the final wrong_answer will be chosen based on a random word (random_word) from the context/premise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0d00a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-multilingual-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "model_similarity = SentenceTransformer(MODEL_SIMILARITY_NAME)\n",
    "\n",
    "def return_similarity_sorted_array(right_answer, sentence_array, model=model_similarity):\n",
    "    \n",
    "    embedding_right_answer = model.encode([right_answer], convert_to_tensor=True)\n",
    "    embedding_sentence_array = model.encode(sentence_array, convert_to_tensor=True)\n",
    "    \n",
    "    cosine_scores = util.pytorch_cos_sim(embedding_right_answer, embedding_sentence_array)\n",
    "    \n",
    "    sorted_indices = cosine_scores.argsort(descending=True)[0]\n",
    "    sorted_array = [sentence_array[i] for i in sorted_indices]\n",
    "    \n",
    "    return sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_values_with_hash(arr):\n",
    "    return [item for item in arr if \"#\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c043ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_word(text):\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    random_word = random.choice(words)\n",
    "    return random_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d0afd1-e751-4cb8-ae22-1b7bb10a5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_same_tag(tag_answers, tag_premise, same_tag_array):\n",
    "    \n",
    "    for tag in tag_premise:\n",
    "\n",
    "        # Check is it in tuple?\n",
    "        if isinstance(tag, tuple):\n",
    "            tag_word = tag[0]\n",
    "        else:\n",
    "            tag_word = None\n",
    "\n",
    "        for tag_answer in tag_answers:\n",
    "            if tag_answer == tag_word:\n",
    "                same_tag_array.append(tag[1])\n",
    "\n",
    "    return remove_values_with_hash(same_tag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5369eced-0cee-4d0d-a436-89a97d2af242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_similarity(data, right_answer, index, tag, plausible_answer_array):\n",
    "\n",
    "    if tag == \"ner\": slice='same_ner_tag_answer'\n",
    "    elif tag == \"chunking\": slice='same_chunking_tag_answer'\n",
    "    else: slice=None\n",
    "        \n",
    "    plausible_answer_array = [item for item in plausible_answer_array \\\n",
    "                              if item not in [right_answer.lower()]]\n",
    "\n",
    "    # Find all the sorted (by similarity) plausible wrong answer, \n",
    "    # and remove hask & punctuation only answer\n",
    "    if slice != None:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, data[slice][index])\n",
    "    else:\n",
    "        wrong_answer_array = return_similarity_sorted_array(right_answer, plausible_answer_array)\n",
    "    \n",
    "    plausible_answer_array = remove_values_with_hash(wrong_answer_array)\n",
    "    plausible_answer_array = [string for string in plausible_answer_array \\\n",
    "                                      if not contains_only_punctuation(string)]\n",
    "\n",
    "    # Only return the most similar to right_answer\n",
    "    wrong_answer = plausible_answer_array[0]\n",
    "    \n",
    "    assert isinstance(wrong_answer, str)\n",
    "    assert isinstance(plausible_answer_array, list)\n",
    "    \n",
    "    if tag == \"ner\": \n",
    "        properties = \"\"\"IDENTICAL NER labels were found, and the highest similarity \\\n",
    "                                    score same NER array was selected\"\"\"\n",
    "    elif tag == \"chunking\":\n",
    "        properties = \"\"\"IDENTICAL Chunking labels were found, and the highest similarity \\\n",
    "                                        score from same Chunking array was selected\"\"\"\n",
    "    else:\n",
    "        properties = \"\"\"NO CHUNKING labels were found, and the highest similarity score \\\n",
    "                                        from plausible answer was selected\"\"\"\n",
    "    \n",
    "    return wrong_answer, plausible_answer_array, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e980a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_substring_span(long_string, substring):\n",
    "    long_string = long_string.lower()\n",
    "    substring = substring.lower()\n",
    "    \n",
    "    start_index = long_string.find(substring)\n",
    "    \n",
    "    if start_index != -1:\n",
    "        end_index = start_index + len(substring) - 1\n",
    "        return start_index, end_index\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a6eef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_span_overlap(span1, span2):\n",
    "    if span1 == None or span2 == None: return True # Exit plan\n",
    "    else: return span1[0] <= span2[1] and span2[0] <= span1[1]\n",
    "\n",
    "def check_string_overlap(str1, str2):\n",
    "    assert isinstance(str1, str)\n",
    "    assert isinstance(str1, str)\n",
    "    \n",
    "    return (str1[-1] >= str2[0]) \\\n",
    "            or (str1 in str2) \\\n",
    "            or (str2 in str1)\n",
    "\n",
    "def contains_only_punctuation(text):\n",
    "    return all(char in string.punctuation for char in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c89fc59b-cb40-4dc3-a324-e850b1324a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_same_answer(right_answer, \n",
    "                        wrong_answer, \n",
    "                        premise, \n",
    "                        plausible_answer_array):\n",
    "    \n",
    "    # Removing right answer & wrong answer in this particular time\n",
    "    plausible_answer_array = [item for item in plausible_answer_array \\\n",
    "                              if item not in [right_answer.lower(), wrong_answer.lower()]]\n",
    "\n",
    "    if len(plausible_answer_array) <= 1:\n",
    "        wrong_answer = select_random_word(premise)\n",
    "        properties = \"\"\"Detected span that is the SAME as the right answer, \\\n",
    "                                search random word from premise\"\"\"\n",
    "\n",
    "    else:\n",
    "        wrong_answer = plausible_answer_array[0] # Take the highest value in the sorted array\n",
    "        properties = \"\"\"Detected span that is the SAME as the right answer, \\\n",
    "                                search the highest value in the sorted array\"\"\"\n",
    "\n",
    "    return wrong_answer, properties, plausible_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95e7087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_multiple_label(data, index, tag):\n",
    "    \n",
    "    if tag == \"ner\": slice='ner_tag_answer'\n",
    "    elif tag == \"chunking\": slice='chunking_tag_answer'\n",
    "    else: pass\n",
    "        \n",
    "    if len(data[slice][index]) > 1: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a4e20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_answer_match_to_multiple_label(data, \n",
    "                                          index, \n",
    "                                          tag,\n",
    "                                          wrong_answer, \n",
    "                                          plausible_answer_array):\n",
    "    \n",
    "    if tag == \"none\":\n",
    "        for answer in plausible_answer_array:\n",
    "            if len(answer.split()) == len(wrong_answer.split()):\n",
    "                wrong_answer = answer\n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if is_multiple_label(data, index, tag):\n",
    "            # Check if wrong_answer a form of sentence?\n",
    "            # If not, look for a wrong_answer in the form of a sentence\n",
    "            if len(wrong_answer.split()) == 1:\n",
    "                for answer in plausible_answer_array:\n",
    "                    if len(answer.split()) > 1:\n",
    "                        wrong_answer = answer\n",
    "                        break\n",
    "\n",
    "        else:\n",
    "            # Check if wrong_answer a form of word?\n",
    "            # If not, look for a wrong_answer in the form of a word\n",
    "            if len(wrong_answer.split()) > 1:\n",
    "                for answer in plausible_answer_array:\n",
    "                    if len(answer.split()) == 1:\n",
    "                        wrong_answer = answer\n",
    "                        break\n",
    "                        \n",
    "    # We can try this out, actually.\n",
    "    # With this code, we only have just check the length of each answer. \n",
    "    # We don't need is_multiple_label function check.\n",
    "    #if len(right_answer) != len(wrong_answer):\n",
    "    #    for answer in plausible_answer_array:\n",
    "    #        if len(answer) == len(right_answer):\n",
    "    #            wrong_answer = answer\n",
    "    #            break\n",
    "                    \n",
    "    if tag == \"ner\": \n",
    "        properties = \"\"\"IDENTICAL NER labels were found, however, \\\n",
    "                        the final wrong_answer is sought \\\n",
    "                        which is a form of a sentence\"\"\"\n",
    "    \n",
    "    elif tag == \"chunking\":\n",
    "        properties = \"\"\"IDENTICAL Chunking labels were found, however, \\\n",
    "                        the final wrong_answer is sought \\\n",
    "                        which is a form of a word\"\"\"\n",
    "    \n",
    "    elif tag == \"none\":\n",
    "        properties = \"\"\"NO CHUNKING labels were found, however, \\\n",
    "                        the final wrong_answer is sought \\\n",
    "                        which is a same form (word or sentence)\"\"\"\n",
    "                    \n",
    "    return wrong_answer, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97759144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong_answer(data):\n",
    "    \n",
    "    data['same_ner_tag_answer'] = \"\"\n",
    "    data['same_chunking_tag_answer'] = \"\"\n",
    "    data['wrong_answer'] = \"\"\n",
    "    data['plausible_answer_based_on_method'] = \"\"\n",
    "    data['properties'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        right_answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "\n",
    "        same_ner_tag_answer_array = []\n",
    "        same_chunking_tag_answer_array = []\n",
    "\n",
    "        ner_tag_answer = data['ner_tag_answer'][i][0]\n",
    "        ner_tag_premise = data['ner_tag_premise'][i]\n",
    "        \n",
    "        #print(ner_tag_answer)\n",
    "\n",
    "        chunking_tag_answer = data['chunking_tag_answer'][i][0]\n",
    "        chunking_tag_premise = data['chunking_tag_premise'][i]\n",
    "        \n",
    "        # Grouped with the same NER & Chunking group, between answer and word of premise\n",
    "        data['same_ner_tag_answer'][i] = grouping_same_tag(ner_tag_answer,\n",
    "                                                           ner_tag_premise,\n",
    "                                                           same_ner_tag_answer_array)\n",
    "        \n",
    "        data['same_chunking_tag_answer'][i] = grouping_same_tag(chunking_tag_answer, \n",
    "                                                                chunking_tag_premise, \n",
    "                                                                same_chunking_tag_answer_array)\n",
    "               \n",
    "        # Start to create wrong answer\n",
    "        plausible_answer_array = []\n",
    "\n",
    "        # Perform NER classification\n",
    "        # If the NER of the right_answer can be detected, then calculate the distance using semantic \n",
    "        # similarity or word vectors between the right_answer and various possible wrong_answers with \n",
    "        # the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "        if data['same_ner_tag_answer'][i] != []:\n",
    "            wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                      i, \"ner\", plausible_answer_array)\n",
    "            #wrong_answer, properties = create_answer_match_to_multiple_label(data, i, \"ner\", wrong_answer,\n",
    "            #                                                                 plausible_answer_array)\n",
    "            \n",
    "        # If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain \n",
    "        # any of NER of right_answer, then the POS/Chunking of the right_answer will be identified.\n",
    "        # Perform POS/Chunking classification\n",
    "        else:\n",
    "            \n",
    "            # If the POS/Chunking of the right_answer can be detected, then calculate the distance \n",
    "            # using semantic similarity or word vectors between the right_answer and various possible \n",
    "            # wrong_answers with the same POS/Chunking as the right_answer. Once done, proceed to the \n",
    "            # final wrong_answer.\n",
    "            if data['same_chunking_tag_answer'][i] != []:\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"chunking\", plausible_answer_array)\n",
    "                #wrong_answer, properties = create_answer_match_to_multiple_label(data, i, \"chunking\", wrong_answer,\n",
    "                #                                                             plausible_answer_array)\n",
    "            \n",
    "            # If the POS/Chunking of the right_answer cannot be detected (NULL) or context/premise \n",
    "            # does not contain any of NER of right_answer, then the final wrong_answer will be chosen \n",
    "            # based on a random word (random_word) from the context/premise.\n",
    "            else:\n",
    "                for chunking_tag in chunking_tag_premise:\n",
    "                    plausible_answer_array.append(chunking_tag[1])\n",
    "\n",
    "                wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                          i, \"none\", plausible_answer_array)\n",
    "                #wrong_answer, properties = create_answer_match_to_multiple_label(data, i, \"none\", wrong_answer,\n",
    "                #                                                             plausible_answer_array)\n",
    "\n",
    "        # Check for preventing same answer for right_answer and wrong_answer  \n",
    "        right_answer_span = find_substring_span(premise, right_answer)\n",
    "        wrong_answer_span = find_substring_span(premise, wrong_answer)\n",
    "        \n",
    "        is_span_or_same_literal = check_span_overlap(right_answer_span, wrong_answer_span) \\\n",
    "                or check_string_overlap(right_answer.lower(), wrong_answer.lower())\n",
    "\n",
    "        if is_span_or_same_literal:\n",
    "\n",
    "            # Removing right answer & wrong answer in this particular time\n",
    "            wrong_answer, properties, plausible_answer_array = replace_same_answer(right_answer, \n",
    "                                                                                  wrong_answer, \n",
    "                                                                                  premise, \n",
    "                                                                                  plausible_answer_array)\n",
    "            data['properties'][i] = properties\n",
    "        \n",
    "        data['wrong_answer'][i] = wrong_answer\n",
    "        data['plausible_answer_based_on_method'][i] = plausible_answer_array\n",
    "            \n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea5d11b-872d-4620-98a9-74a37b5248f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong_answer_with_removing_invalid_data(data):\n",
    "    \n",
    "    data['same_ner_tag_answer'] = \"\"\n",
    "    data['same_chunking_tag_answer'] = \"\"\n",
    "    data['wrong_answer'] = \"\"\n",
    "    data['plausible_answer_based_on_method'] = \"\"\n",
    "    data['properties'] = \"\"\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        \n",
    "        right_answer = data['answer'][i]\n",
    "        premise = data['premise'][i]\n",
    "\n",
    "        same_ner_tag_answer_array = []\n",
    "        same_chunking_tag_answer_array = []\n",
    "\n",
    "        ner_tag_answer = data['ner_tag_answer'][i]\n",
    "        ner_tag_premise = data['ner_tag_premise'][i]\n",
    "\n",
    "        chunking_tag_answer = data['chunking_tag_answer'][i]\n",
    "        chunking_tag_premise = data['chunking_tag_premise'][i]\n",
    "        \n",
    "        # Grouped with the same NER & Chunking group, between answer and word of premise\n",
    "        data['same_ner_tag_answer'][i] = grouping_same_tag(ner_tag_answer,\n",
    "                                                           ner_tag_premise,\n",
    "                                                           same_ner_tag_answer_array)\n",
    "        \n",
    "        data['same_chunking_tag_answer'][i] = grouping_same_tag(chunking_tag_answer, \n",
    "                                                                chunking_tag_premise, \n",
    "                                                                same_chunking_tag_answer_array)\n",
    "               \n",
    "        # Start to create wrong answer\n",
    "        plausible_answer_array = []\n",
    "\n",
    "        # Perform NER classification\n",
    "        # If the NER of the right_answer can be detected, then calculate the distance using semantic \n",
    "        # similarity or word vectors between the right_answer and various possible wrong_answers with \n",
    "        # the same NER as the right_answer. Once done, proceed to the final wrong_answer.\n",
    "        if data['same_ner_tag_answer'][i] != []:\n",
    "            wrong_answer, plausible_answer_array, properties = sorting_similarity(data, right_answer, \\\n",
    "                                                                      i, \"ner\", plausible_answer_array)\n",
    "            #wrong_answer, properties = create_answer_match_to_multiple_label(data, i, \"ner\", wrong_answer,\n",
    "            #                                                                 plausible_answer_array)\n",
    "            \n",
    "        # Kalau NER engga ada, baru drop\n",
    "        # Kalau NER NULL, cek chunking\n",
    "            \n",
    "        # If the NER of the right_answer cannot be detected (NULL) or context/premise does not contain \n",
    "        # any of NER of right_answer, then drop that particular row data.\n",
    "        else:\n",
    "            data.drop(i, inplace=True)\n",
    "            data.reset_index(drop=True)\n",
    "            continue\n",
    "        \n",
    "        # Check for preventing same answer for right_answer and wrong_answer  \n",
    "        right_answer_span = find_substring_span(premise, right_answer)\n",
    "        wrong_answer_span = find_substring_span(premise, wrong_answer)\n",
    "        \n",
    "        is_span_or_same_literal = check_span_overlap(right_answer_span, wrong_answer_span) \\\n",
    "                or check_string_overlap(right_answer.lower(), wrong_answer.lower())\n",
    "\n",
    "        if is_span_or_same_literal:\n",
    "\n",
    "            # I'm still confused, whether the overlapping \n",
    "            # answers (either in span or its literal form) \n",
    "            # should also be dropped or not.\n",
    "            # If it's dropped, then, uncomment 3 lines of\n",
    "            # code below.\n",
    "            \n",
    "            data.drop(i, inplace=True)\n",
    "            data.reset_index(drop=True)\n",
    "            continue\n",
    "\n",
    "            # Removing right answer & wrong answer in this particular time\n",
    "            #wrong_answer, properties, plausible_answer_array = replace_same_answer(right_answer, \n",
    "            #                                                                      wrong_answer, \n",
    "            #                                                                      premise, \n",
    "            #                                                                      plausible_answer_array)\n",
    "            #data['properties'][i] = properties\n",
    "        \n",
    "        data['wrong_answer'][i] = wrong_answer\n",
    "        data['plausible_answer_based_on_method'][i] = plausible_answer_array\n",
    "            \n",
    "    return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16be56d2-8924-47aa-9009-b7378190e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = create_wrong_answer_with_removing_invalid_data(data_nli_train_df)\n",
    "#y = create_wrong_answer_with_removing_invalid_data(data_nli_val_df)\n",
    "#z = create_wrong_answer_with_removing_invalid_data(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efed3dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc027a43fc2a49b8980b601ae42f971f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b369ac80e5f41ca818a1967fec49994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                                 | 1/28 [00:01<00:52,  1.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0578a6ece9094f458bb7e3519829bf98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6431c42a496641738fde538f5c34cf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822ba2328ba641718b9806a070eebc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da77e876b21f402f806c2caea1e43400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dd879eecd147b8812afc9464b1be6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fde0c38da747719651872f341d8b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                        | 4/28 [00:02<00:09,  2.48it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1d458a3d7e4877855c5b1b136afd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e55e789a6e41c7864ceeaff9584ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a136a81167540a7a162865fba7ce108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146c8f703b8b46bf9e6bb359e1a448ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39d2543af534ee1bb5c221cc5f9913a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4c6cdd41d84a6c851d701af29b8a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 7/28 [00:02<00:04,  4.74it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b52ed27b0f4c4cb6502a96e35a90e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6e0fab372a422892315d15d6cf4b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252a76616717418697010592b8b2dbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bf0852b8834b2abbf9f3f6a0ae1dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abe727b52f84538a817de3b18063f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea7055fbb76457c8156028586140494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▋                                                     | 10/28 [00:02<00:02,  7.20it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c818536cfdee4ae6917cf6fa2bf2be2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7741e4d2fec4d4fbdec7a9a69d65123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68466322c58b4c3894b3160ae1753789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66892943d3e453cabc906b62f736e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b817e9530884229bbcd405116fbc605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0efc3f87be431eae715a13c0d68fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████▌                                            | 13/28 [00:02<00:01,  9.52it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4512639ec35b4b6c9da1887361a3c702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60d0aabdfe840459b1e20d72a948c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb3507aa6e9418baf343e24053bd529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007fa96f21c243cfa294e26136ce390c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45774efb4826493e9e3381fc298d36f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63d6603ed46494280c327817ccd407b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████▍                                   | 16/28 [00:02<00:01, 11.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e245193cffc142b58b9416add66f0618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb2fe5811844a0c97f536f04401a38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df297c9ff6f43cf962dbc7125cf2cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9366a8ff12b434aab978eb01a2640fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ef5c804dce4058bc933e74c36ee9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf2b54c8e6046c6a655c788e4758382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████▎                          | 19/28 [00:02<00:00, 13.90it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba91922f24b484c808f55f2d813afd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0e5bdfa0314683a58ea585de114d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5431079c9340c4a50dc0e2aa20543f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804a6aa8c3f4449ca4f63b5bd4605d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5df1b9080546c292f9565c0ce54c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f727fa086d34536803b827e562990ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████████▏                 | 22/28 [00:03<00:00, 11.28it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c892ce3e5dd48c0ba5a1891933c2715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b31c81931ec4d34ae7aac2adf8b4781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780d76a26ae54e8c89b86c81d6aabb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d49dfb396b4e8e848939bb6e695251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a666ad2cc949d09aacab152b945527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd10584038dd4c8db291c05302486890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████████         | 25/28 [00:03<00:00, 13.16it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44be470ee34c44e8838d95bbd9477e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24d5c1b81e64dffa6a0a82ec2801728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45dd30af2b84e5e81a12b08be259b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a5b3cff09a4982a160d03b4cc43dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████████   | 27/28 [00:03<00:00, 13.97it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd05aea64e684f6a806264cebe3a5e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1839dbb2ecb747c4b05e9d8b07dd1c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  8.11it/s]\n",
      "  0%|                                                                                            | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226e44c2b3754904b35c487cf34b2574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95256e354fc43e9877b438c891164af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589005fe479e4df7b8907bffcce6a106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba3de5714484d7e8b11cb9a530eeb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████                                                                              | 2/28 [00:00<00:01, 18.01it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b90698ee0944cfbda2525d3f4af3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9c460a350e4847b50607bafdcf8dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1805b5a171224e7b89aa9903004b9c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b244d1305b4b4f6d960695bec51ed46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d23b9a97b9430b82ff0a6afac0bf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fa5b3e88554b5ea25bbb8ef6840c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████                                                                     | 5/28 [00:00<00:01, 20.54it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed87695a2ed4faa94130184171ff51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23adc84cf98a4209a2a7c4f56e6f33cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59031b17ae0444ab96bfcff723cfec6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda2ea3dbea1458a8ac23b0c951ecc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99481e3f6f8a47c1816e0fa308b6c4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfd4dd9753a40de89e368aa62b6456b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████                                                            | 8/28 [00:00<00:00, 20.79it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef08cad45ee4b6a99ba3622db498128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ea317830cc4771ada684308a2e59d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb817ce24bf1463082e9e3f7dc5e5887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2924f432ee2b4a64936becddb564b66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c3562ea01b4d569303d4c7d7616bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba25837c52ed4dedabc5fddb63894ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████▌                                                  | 11/28 [00:00<00:00, 20.80it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f6cbbddddd4cd98d71dfb2b38d2bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14bbd2c370a4f61ba5f0ad624a09a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085acb6b46bd41e0b7a92be2c827f14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bf411e9c8e4b0f925c12b1c6f141ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f8b46ae0e841a498038431cd7e6240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898c6a8f3222475794f130c065cb08b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 14/28 [00:00<00:00, 20.76it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a0e64dae024c9a987b1d7d2d74b11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29557dcc2d04b808afd8ce82994c058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb37e843aea642199157d2ade6a608b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fd80c46fff45b285f644dc6bab7b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3611a569b20140988c05916086b50e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4336ed88694216932454409b9c4447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████████▍                                | 17/28 [00:00<00:00, 20.13it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e6344846fc491d9aff54757e32d159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc64972107c43b4b25509e95fece720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e3c529e1184b1f9dc4a030b75bdfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0acdf35e5e34d649a9e696ca2727087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95eb7a47a6464a8a86ae9d987804232a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349fc70c43d2430397a4ff8e377e9221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████▎                       | 20/28 [00:01<00:00, 18.51it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6ea464098944168383f2ffdf4f11c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc97d63522d4431bb79f6bb4f4c36dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c5ece354ec46c1819190512d10697f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5094f32f6e840e6997e05c449c9a6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61a697eeae245a49fd6ef2eba6e7f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489114dc573843c3bc4084d682aa3d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████▏              | 23/28 [00:01<00:00, 19.07it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db0253cfa204ce49ca9671e11238c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2c4831f9644f6887f9b04018671a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e41c48269d487bb7f0e5a671656401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251cd64e97ed426d92ce3c9b9c2ac482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb83edaa195543869e3bde9adf20ac07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b8778531d54a57bbe85ddfce096322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████████      | 26/28 [00:01<00:00, 19.52it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9cef5f62b64e5a9fc3a7873714d88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47554d472c3148fe84de0458491336d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ea642cff04026acf3016238e3432a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4229573b5340a5a00c5ff6daebd648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 19.76it/s]\n",
      "  0%|                                                                                            | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b03ad60ac4c4c93a5bba99a21d9177e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130ea11b9d1f4c4988550054d3cb431c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f17f4011554f83ae2e04efc279919f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e1f81f27f44a789355046210c8296e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                            | 2/21 [00:00<00:01, 18.27it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e37948b3ac4f6ba77d72be7c241d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ef9bc6be5b497fb030f7573a273651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecd854d8f834f03aceed1800f786ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d78fd7fa14d47f8b0d95e7cb60a8944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfd938f9f52402c868dbc71ded89285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e479e3a58644808b39cfc9c9cb3be5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████                                                                | 5/21 [00:00<00:00, 19.71it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187aff1cb94048f1924bcbc7bc7617f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfca5ad8f5f946779a1f5e32c65445f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c122f4a76b814679bb549f031ca38886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6f4bbb86d04491937047609b5e0097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 7/21 [00:00<00:00, 18.60it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9345b4de9544c6b157660efddf9547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eab005c2e574d9b830418feda102f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1576622a0341479d8c6a147874d03d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06429029a4354b9db317ecd43c7192a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████                                                | 9/21 [00:00<00:00, 18.38it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc68819c215e4d61bebf4c0714bbc95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114c312df30541f5ae68c5e36c9fe568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53403bc59c84fb5b9b28de5b63d1523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf64642b0bb48c5aa9751abb3111dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bb9ebc9cfd499c8099ee9804324eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4981624288214ed0ab10ea7b8fc2e723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████▍                                   | 12/21 [00:00<00:00, 19.23it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5802d52ae846474cb2144c386313b604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f13e8ea368a42b7ac4bc5f1d8380c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f47d76518b415f8f0d8012bfb306d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d90751ca0b14bf99280d89889ef1003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████▎                           | 14/21 [00:00<00:00, 19.39it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f090a5255b45ab917884b937453b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96120c87a08d4e278c954f047f3c9fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574b446bbc31454ab9af9f0f1ac4208d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28b6bc55b184dd1a2abd934ed40072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████▏                   | 16/21 [00:00<00:00, 19.13it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9ec6348e634da882d22cb4b8963f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264d3f9c918e4c418f02a009472fcb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c1d4333aa5439c9e571a9f75c5a100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ba514b46bb4f26b0097612b08b638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 18/21 [00:00<00:00, 18.45it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d466e9def904d7584000bc268cc107a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a3f5af84054d96bef540e6034ceae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b82a3b7169642be8cc948c516210940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615883bd5073490693a1de9b3de77299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████    | 20/21 [00:01<00:00, 18.82it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c508b9c2a5b4e559496e3d650ce37b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bdcf6a70d2463086a688c2e74f003a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 19.01it/s]\n"
     ]
    }
   ],
   "source": [
    "data_nli_train_df = create_wrong_answer(data_nli_train_df)\n",
    "data_nli_val_df = create_wrong_answer(data_nli_val_df)\n",
    "data_nli_test_df = create_wrong_answer(data_nli_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5766804d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ner_tag_answer</th>\n",
       "      <th>chunking_tag_answer</th>\n",
       "      <th>ner_tag_premise</th>\n",
       "      <th>chunking_tag_premise</th>\n",
       "      <th>same_ner_tag_answer</th>\n",
       "      <th>same_chunking_tag_answer</th>\n",
       "      <th>wrong_answer</th>\n",
       "      <th>plausible_answer_based_on_method</th>\n",
       "      <th>properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bendera Jerman pertama kali diperkenalkan pada...</td>\n",
       "      <td>Apa warna bendera Jerman ?</td>\n",
       "      <td>hitam di atas, merah di tengah, dan kuning (\"e...</td>\n",
       "      <td>[(NULL, hitam di atas, merah di tengah, dan ku...</td>\n",
       "      <td>[(NP, hitam), (PP, di), (NP, atas, merah), (PP...</td>\n",
       "      <td>[(PLACE, jerman), (PLACE, jerman barat), (PLAC...</td>\n",
       "      <td>[(NP, bendera jerman), (ADVP, pertama kali), (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bendera jerman, tahun 1919, tahun 1949 bender...</td>\n",
       "      <td>atas, merah</td>\n",
       "      <td>[atas, merah, tiga warna, hitam, bendera ini, ...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paus (dari Dutch: paus; Latin: papa dari Greek...</td>\n",
       "      <td>Siapakah nama pemimpin dalam gereja ?</td>\n",
       "      <td>Paus</td>\n",
       "      <td>[(NULL, Paus)]</td>\n",
       "      <td>[(NP, paus)]</td>\n",
       "      <td>[(PERSON, paus), (PLACE, dutch), (PLACE, latin...</td>\n",
       "      <td>[(NP, paus (), (PP, dari), (NP, dutch : paus ;...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[paus (, dutch : paus ; latin : papa, greek : ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 4, 1, peranannya, 2 ], besar, siapa, yesus...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Euro (€) adalah mata uang yang dipakai di 19 n...</td>\n",
       "      <td>Kapan mata uang Euro secara fisik baru dipakai?</td>\n",
       "      <td>1 Januari 2002</td>\n",
       "      <td>[(NULL, 1 Januari 2002)]</td>\n",
       "      <td>[(NP, 1 januari 2002)]</td>\n",
       "      <td>[(PLACE, uni), (ORGANISATION, eropa)]</td>\n",
       "      <td>[(NP, euro ( € )), (VP, adalah), (NP, mata uan...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[euro ( € ), mata uang, 19 negara anggota uni ...</td>\n",
       "      <td>tanggal 1 januari 1999</td>\n",
       "      <td>[tanggal 1 januari 1999, mana - mana, belakang...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kabupaten Kaimana adalah salah satu kabupaten ...</td>\n",
       "      <td>Berapa luas Kabupaten Kaimana?</td>\n",
       "      <td>36.000 km2</td>\n",
       "      <td>[(NULL, 36.000 km2)]</td>\n",
       "      <td>[(NP, 36. 000 km2)]</td>\n",
       "      <td>[(PLACE, kabupaten kaimana), (PLACE, provinsi ...</td>\n",
       "      <td>[(NP, kabupaten kaimana), (VP, adalah), (NP, s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kabupaten kaimana, salah satu kabupaten, prov...</td>\n",
       "      <td>18. 500 km2 dan</td>\n",
       "      <td>[18. 500 km2 dan, luas lautan / perairan ± 17....</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Władysław (juga bernama Włodzisław) Odonic (di...</td>\n",
       "      <td>Dimana Władysław Odonic berasal?</td>\n",
       "      <td>Wielkopolska</td>\n",
       "      <td>[(PLACE, wielkop)]</td>\n",
       "      <td>[(NP, wielkopolska)]</td>\n",
       "      <td>[(PERSON, plwacz), (PLACE, pl), (PERSON, ##wa)...</td>\n",
       "      <td>[(NP, Władysław (), (ADVP, juga), (VP, bernama...</td>\n",
       "      <td>[pl, kalisz, poznan, uj, Nakło, wielkopolsk, s...</td>\n",
       "      <td>[Władysław (, Włodzisław ) odonic (, plwacz ),...</td>\n",
       "      <td>poznan</td>\n",
       "      <td>[poznan, kalisz, Nakło, pl, uj, sungai warta]</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CPU berfungsi seperti kalkulator, hanya saja C...</td>\n",
       "      <td>Apakah fungsi utama CPU ?</td>\n",
       "      <td>melakukan operasi aritmetika dan logika terhad...</td>\n",
       "      <td>[(NULL, melakukan operasi aritmetika dan logik...</td>\n",
       "      <td>[(VP, melakukan), (NP, operasi aritmetika dan ...</td>\n",
       "      <td>[NO TOKEN DETECTED]</td>\n",
       "      <td>[(NP, cpu), (VP, berfungsi), (PP, seperti), (N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[berfungsi, adalah melakukan, diambil, dimasuk...</td>\n",
       "      <td>dapat dijalankan</td>\n",
       "      <td>[dapat dijalankan, dikontrol, berfungsi, adala...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Uni Eropa (disingkat UE) adalah organisasi ant...</td>\n",
       "      <td>Ada berapa negara yang tergabung dalam Uni Eropa?</td>\n",
       "      <td>28</td>\n",
       "      <td>[(NULL, 28)]</td>\n",
       "      <td>[(NP, 28)]</td>\n",
       "      <td>[(ORGANISATION, uni eropa), (ORGANISATION, ue)...</td>\n",
       "      <td>[(NP, uni eropa), (VP, disingkat), (NP, ue )),...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[uni eropa, ue ), organisasi antarpemerintahan...</td>\n",
       "      <td>tanggal tersebut</td>\n",
       "      <td>[tanggal tersebut, 1 juli 2013, ue, persatuan ...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kota Palembang adalah ibu kota provinsi Sumate...</td>\n",
       "      <td>berapakah Luas kota Palembang?</td>\n",
       "      <td>358,55km²</td>\n",
       "      <td>[(NULL, 358,55km²)]</td>\n",
       "      <td>[(NP, 358), (NP, 55km²)]</td>\n",
       "      <td>[(PLACE, kota palembang), (PLACE, provinsi sum...</td>\n",
       "      <td>[(NP, kota palembang), (VP, adalah), (NP, ibu ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kota palembang, ibu kota provinsi sumatera se...</td>\n",
       "      <td>luas wilayah 358,</td>\n",
       "      <td>[luas wilayah 358,, km², 1. 573. 898 jiwa, 2, ...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sahara terletak di utara Afrika dan berusia 2,...</td>\n",
       "      <td>Berapakah Luas Gurun Sahara ?</td>\n",
       "      <td>9.000.000km2</td>\n",
       "      <td>[(NULL, 9.000.000km2)]</td>\n",
       "      <td>[(NP, 9. 000. 000km2)]</td>\n",
       "      <td>[(PLACE, sahara), (PLACE, afrika), (PLACE, sam...</td>\n",
       "      <td>[(NP, sahara), (VP, terletak), (PP, di), (NP, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sahara, utara afrika, 2,, 5 juta tahun, padan...</td>\n",
       "      <td>5 juta tahun</td>\n",
       "      <td>[5 juta tahun, luas padang pasir ini, kedua ba...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Business Machines Corporation (d...</td>\n",
       "      <td>Dimana kantor pusat perusahaan IBM?</td>\n",
       "      <td>Armonk, New York, Amerika Serikat</td>\n",
       "      <td>[(PLACE, armonk), (PLACE, new york), (PLACE, a...</td>\n",
       "      <td>[(NP, armonk,), (NP, new york, amerika serikat)]</td>\n",
       "      <td>[(ORGANISATION, international business machine...</td>\n",
       "      <td>[(NP, international business machines corporat...</td>\n",
       "      <td>[amerika serikat, armonk, new york, amerika se...</td>\n",
       "      <td>[international business machines corporation (...</td>\n",
       "      <td>armonk</td>\n",
       "      <td>[armonk, amerika serikat, amerika serikat]</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pada zaman pemerintahan Hindia Belanda berdasa...</td>\n",
       "      <td>apakah nama ibukota Kalimantan Barat?</td>\n",
       "      <td>Pontianak</td>\n",
       "      <td>[(PLACE, pontianak)]</td>\n",
       "      <td>[(NP, pontianak)]</td>\n",
       "      <td>[(PLACE, belanda), (PLACE, gouvernement borneo...</td>\n",
       "      <td>[(PP, pada), (NP, zaman pemerintahan hindia be...</td>\n",
       "      <td>[belanda, gouvernement borneo, banjarmasin, re...</td>\n",
       "      <td>[zaman pemerintahan hindia belanda, keputusan ...</td>\n",
       "      <td>banjarmasin</td>\n",
       "      <td>[banjarmasin, belanda, residentie westerafdeel...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kota Ho Chi Minh (bahasa Vietnam: Thành phố Hồ...</td>\n",
       "      <td>Apa nama kota terbesar di Vietnam?</td>\n",
       "      <td>Ho Chi Minh</td>\n",
       "      <td>[(PLACE, ho chi minh)]</td>\n",
       "      <td>[(NP, ho chi minh)]</td>\n",
       "      <td>[(PLACE, kota ho chi minh), (PLACE, vietnam), ...</td>\n",
       "      <td>[(NP, kota ho chi minh ( bahasa vietnam : than...</td>\n",
       "      <td>[kota ho chi minh, vietnam, thanh pho ho chi m...</td>\n",
       "      <td>[kota ho chi minh ( bahasa vietnam : thanh pho...</td>\n",
       "      <td>kota ho chi minh</td>\n",
       "      <td>[kota ho chi minh, kota ho chi minh, vietnam, ...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Menurut Pavlov, refleks mengeluarkan air liur ...</td>\n",
       "      <td>Apa itu stimulus netral?</td>\n",
       "      <td>stimulus yang tidak atau belum menghasilkan se...</td>\n",
       "      <td>[(NULL, stimulus yang tidak atau belum menghas...</td>\n",
       "      <td>[(NP, stimulus), (SBAR, yang), (ADVP, tidak), ...</td>\n",
       "      <td>[(PERSON, pavlov), (PERSON, pavlov), (PERSON, ...</td>\n",
       "      <td>[(PP, menurut), (NP, pavlov), (NP, refleks), (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pavlov, refleks, air liur, anjing tersebut, s...</td>\n",
       "      <td>conditioned stimulus )</td>\n",
       "      <td>[conditioned stimulus ), sebuah stimulus netra...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jika kita membuka-buka lembaran sejarah radio ...</td>\n",
       "      <td>Kapan radio pertama kali digunakan di Indonesia ?</td>\n",
       "      <td>1920an</td>\n",
       "      <td>[(NULL, 1920an)]</td>\n",
       "      <td>[(NP, 1920an)]</td>\n",
       "      <td>[(PLACE, indonesia), (PLACE, indonesia), (PLAC...</td>\n",
       "      <td>[(SBAR, jika), (NP, kita), (VP, membuka -), (V...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kita, lembaran sejarah radio indonesia, radio...</td>\n",
       "      <td>kepentingan penjajah belanda</td>\n",
       "      <td>[kepentingan penjajah belanda, pertama kalinya...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Uncharted 3: Drake's Deception dirilis pada No...</td>\n",
       "      <td>siapakah karakter utama dari game Uncharted 3:...</td>\n",
       "      <td>Nate dengan mentor dan figur ayah, Victor \"Sul...</td>\n",
       "      <td>[(PERSON, nat), (PERSON, victor \" sully \" sull...</td>\n",
       "      <td>[(NP, nate), (PP, dengan), (NP, mentor dan fig...</td>\n",
       "      <td>[(PERSON, nate), (PERSON, victor \" sully \" sul...</td>\n",
       "      <td>[(NP, uncharted 3 : drake ' s deception), (VP,...</td>\n",
       "      <td>[nate, victor \" sully \" sullivan, elena fisher...</td>\n",
       "      <td>[uncharted 3 : drake ' s deception, november 2...</td>\n",
       "      <td>victor \" sully \" sullivan</td>\n",
       "      <td>[victor \" sully \" sullivan, talbot, katherine ...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Di Yunani Kuno, gynaeceum (Greek: γυναικεῖον g...</td>\n",
       "      <td>Apa fungsi bangunan gynaeceum?</td>\n",
       "      <td>diperuntukkan bagi wanita</td>\n",
       "      <td>[(NULL, diperuntukkan bagi wanita)]</td>\n",
       "      <td>[(VP, diperuntukkan), (PP, bagi), (NP, wanita)]</td>\n",
       "      <td>[(PLACE, yunani), (PLACE, yunani), (PLACE, ind...</td>\n",
       "      <td>[(PP, di), (NP, yunani kuno), (NP, gynaeceum (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[diperuntukkan, berarti \", milik, merupakan, d...</td>\n",
       "      <td>milik</td>\n",
       "      <td>[milik, merupakan, adalah, berarti \"]</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nutrisi atau gizi adalah substansi organik yan...</td>\n",
       "      <td>Apa yang dimaksud dengan gizi ?</td>\n",
       "      <td>substansi organik yang dibutuhkan organisme un...</td>\n",
       "      <td>[(NULL, substansi organik yang dibutuhkan orga...</td>\n",
       "      <td>[(NP, substansi organik), (SBAR, yang), (VP, d...</td>\n",
       "      <td>[NO TOKEN DETECTED]</td>\n",
       "      <td>[(NP, nutrisi atau gizi), (VP, adalah), (NP, s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nutrisi atau gizi, substansi organik, organis...</td>\n",
       "      <td>substansi organik</td>\n",
       "      <td>[substansi organik, nutrisi atau gizi, organis...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Secara geografis Kabupaten Lamongan terletak p...</td>\n",
       "      <td>berapakah luas Lamongan?</td>\n",
       "      <td>1.812,8km2</td>\n",
       "      <td>[(NULL, 1.812,8km2)]</td>\n",
       "      <td>[(NP, 1. 812,), (NP, 8km2)]</td>\n",
       "      <td>[(PLACE, kabupaten lamongan), (PLACE, kabupate...</td>\n",
       "      <td>[(PP, secara), (ADVP, geografis), (NP, kabupat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kabupaten lamongan, 6o51 ', 7o23 ' lintang se...</td>\n",
       "      <td>seluas 902, 4km2</td>\n",
       "      <td>[seluas 902, 4km2, luas wilayah, panjang garis...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Johann Sebastian Bach lahir pada tanggal 21 Ma...</td>\n",
       "      <td>Kapan Johann Sebastian Bach lahir ?</td>\n",
       "      <td>21 Maret 1685</td>\n",
       "      <td>[(NULL, 21 Maret 1685)]</td>\n",
       "      <td>[(NP, 21 maret 1685)]</td>\n",
       "      <td>[(PERSON, johann sebastian bach), (PLACE, kota...</td>\n",
       "      <td>[(NP, johann sebastian bach), (VP, lahir), (PP...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[johann sebastian bach, tanggal 21 maret 1685,...</td>\n",
       "      <td>tahun 1695 dia</td>\n",
       "      <td>[tahun 1695 dia, saat, zaman itu, johann sebas...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Menanggapi hal tersebut, Nicolaas Jouwe dan du...</td>\n",
       "      <td>kapankah papua nugini melepaskan diri dari ind...</td>\n",
       "      <td>1 Juli 1971</td>\n",
       "      <td>[(NULL, 1 Juli 1971)]</td>\n",
       "      <td>[(NP, 1 juli 1971)]</td>\n",
       "      <td>[(PERSON, nicolaas jouwe), (ORGANISATION, opm)...</td>\n",
       "      <td>[(VP, menanggapi), (NP, hal tersebut), (NP, ni...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hal tersebut, nicolaas jouwe dan dua komandan...</td>\n",
       "      <td>tahun 1971</td>\n",
       "      <td>[tahun 1971, roemkorem dan prai, konstitusinya...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kucing bengal adalah keturunan ketiga dari has...</td>\n",
       "      <td>dari manakah kucing bengal berasal?</td>\n",
       "      <td>California, Amerika Serikat</td>\n",
       "      <td>[(PLACE, california), (PLACE, amerika serikat)]</td>\n",
       "      <td>[(NP, california, amerika serikat)]</td>\n",
       "      <td>[(PLACE, amerika), (PLACE, california), (PLACE...</td>\n",
       "      <td>[(NP, kucing bengal), (VP, adalah), (NP, ketur...</td>\n",
       "      <td>[amerika, california, amerika serikat]</td>\n",
       "      <td>[kucing bengal, keturunan ketiga, hasil persil...</td>\n",
       "      <td>amerika</td>\n",
       "      <td>[amerika, amerika serikat]</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Snow White and the Seven Dwarfs (\"Putri Salju ...</td>\n",
       "      <td>Kapan Snow White and the Seven Dwarfs dirilis?</td>\n",
       "      <td>4 Februari 1937</td>\n",
       "      <td>[(NULL, 4 Februari 1937)]</td>\n",
       "      <td>[(NP, 4 februari 1937)]</td>\n",
       "      <td>[(ORGANISATION, walt disney), (ORGANISATION, r...</td>\n",
       "      <td>[(NP, snow white and the seven dwarfs ( \" putr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[snow white and the seven dwarfs ( \" putri sal...</td>\n",
       "      <td>awal</td>\n",
       "      <td>[awal, film pertama, film pertama, film pertam...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Istilah kapitalisme, dalam arti modern, sering...</td>\n",
       "      <td>Siapa yang menciptakan teori kapitalis ?</td>\n",
       "      <td>Karl Marx</td>\n",
       "      <td>[(PERSON, karl marx)]</td>\n",
       "      <td>[(NP, karl marx)]</td>\n",
       "      <td>[(PERSON, karl marx), (PERSON, marx), (PERSON,...</td>\n",
       "      <td>[(NP, istilah kapitalisme), (PP, dalam), (NP, ...</td>\n",
       "      <td>[karl marx, marx, marx, friedrich engels]</td>\n",
       "      <td>[istilah kapitalisme, arti modern, karl marx, ...</td>\n",
       "      <td>marx</td>\n",
       "      <td>[marx, marx, friedrich engels]</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Budaya Republik Dominika, seperti negara Karib...</td>\n",
       "      <td>Apakah bahasa kebangsaan Republik Dominika?</td>\n",
       "      <td>Kastilia</td>\n",
       "      <td>[(NULL, Kastilia)]</td>\n",
       "      <td>[(NP, kastilia)]</td>\n",
       "      <td>[(PLACE, republik dominika), (PLACE, karibia),...</td>\n",
       "      <td>[(NP, budaya republik dominika), (PP, seperti)...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[budaya republik dominika, negara karibia seki...</td>\n",
       "      <td>bahasa spanyol,</td>\n",
       "      <td>[bahasa spanyol,, bahasa kastilia, budaya repu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pangeran Samudra menjadi raja pertama Kerajaan...</td>\n",
       "      <td>Siapa raja pertama kerajaan Banjar ?</td>\n",
       "      <td>Pangeran Samudra</td>\n",
       "      <td>[(PERSON, pangeran samudra)]</td>\n",
       "      <td>[(NP, pangeran samudra)]</td>\n",
       "      <td>[(PERSON, pangeran samudra), (PLACE, kerajaan ...</td>\n",
       "      <td>[(NP, pangeran samudra), (VP, menjadi), (NP, r...</td>\n",
       "      <td>[pangeran samudra, sultan suriansyah, khat]</td>\n",
       "      <td>[pangeran samudra, raja pertama kerajaan banja...</td>\n",
       "      <td>sultan suriansyah</td>\n",
       "      <td>[sultan suriansyah, khat]</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Daratan utama Skotlandia mencakup sepertiga da...</td>\n",
       "      <td>Berapa luas Skotlandia?</td>\n",
       "      <td>78,772km</td>\n",
       "      <td>[(NULL, 78,772km)]</td>\n",
       "      <td>[(NP, 78, 772km)]</td>\n",
       "      <td>[(PLACE, skotlandia), (PLACE, pulau britania r...</td>\n",
       "      <td>[(NP, daratan utama skotlandia), (VP, mencakup...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[daratan utama skotlandia, sepertiga daratan p...</td>\n",
       "      <td>305 kilometres ( 190mi</td>\n",
       "      <td>[305 kilometres ( 190mi, 30 kilometres ( 19mi,...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pulau Pitcairn menjadi koloni Inggris pada tah...</td>\n",
       "      <td>Kapan Pulau Pitcairn menjadi koloni Inggris?</td>\n",
       "      <td>1838</td>\n",
       "      <td>[(NULL, 1838)]</td>\n",
       "      <td>[(NP, 1838)]</td>\n",
       "      <td>[(PLACE, pulau pitcairn), (PLACE, inggris), (P...</td>\n",
       "      <td>[(NP, pulau pitcairn), (VP, menjadi), (NP, kol...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pulau pitcairn, koloni inggris, tahun 1838, s...</td>\n",
       "      <td>pertengahan tahun 1850an</td>\n",
       "      <td>[pertengahan tahun 1850an, tanggal 8 juni 1856...</td>\n",
       "      <td>Detected span that is the SAME as the right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rencana untuk membuat bom uranium oleh negara-...</td>\n",
       "      <td>Kapan senjata nuklir pertama diciptakan?</td>\n",
       "      <td>1939</td>\n",
       "      <td>[(NULL, 1939)]</td>\n",
       "      <td>[(VP, 1939)]</td>\n",
       "      <td>[(PERSON, albert einstein), (PLACE, as), (PERS...</td>\n",
       "      <td>[(NP, rencana), (SBAR, untuk), (VP, membuat), ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[membuat, dimulai, menulis, dan menyampaikan, ...</td>\n",
       "      <td>mencapai</td>\n",
       "      <td>[mencapai, membuat, dijadikan, disebut, adalah...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              premise  \\\n",
       "0   Bendera Jerman pertama kali diperkenalkan pada...   \n",
       "1   Paus (dari Dutch: paus; Latin: papa dari Greek...   \n",
       "2   Euro (€) adalah mata uang yang dipakai di 19 n...   \n",
       "3   Kabupaten Kaimana adalah salah satu kabupaten ...   \n",
       "4   Władysław (juga bernama Włodzisław) Odonic (di...   \n",
       "5   CPU berfungsi seperti kalkulator, hanya saja C...   \n",
       "6   Uni Eropa (disingkat UE) adalah organisasi ant...   \n",
       "7   Kota Palembang adalah ibu kota provinsi Sumate...   \n",
       "8   Sahara terletak di utara Afrika dan berusia 2,...   \n",
       "9   International Business Machines Corporation (d...   \n",
       "10  Pada zaman pemerintahan Hindia Belanda berdasa...   \n",
       "11  Kota Ho Chi Minh (bahasa Vietnam: Thành phố Hồ...   \n",
       "12  Menurut Pavlov, refleks mengeluarkan air liur ...   \n",
       "13  Jika kita membuka-buka lembaran sejarah radio ...   \n",
       "14  Uncharted 3: Drake's Deception dirilis pada No...   \n",
       "15  Di Yunani Kuno, gynaeceum (Greek: γυναικεῖον g...   \n",
       "16  Nutrisi atau gizi adalah substansi organik yan...   \n",
       "17  Secara geografis Kabupaten Lamongan terletak p...   \n",
       "18  Johann Sebastian Bach lahir pada tanggal 21 Ma...   \n",
       "19  Menanggapi hal tersebut, Nicolaas Jouwe dan du...   \n",
       "20  Kucing bengal adalah keturunan ketiga dari has...   \n",
       "21  Snow White and the Seven Dwarfs (\"Putri Salju ...   \n",
       "22  Istilah kapitalisme, dalam arti modern, sering...   \n",
       "23  Budaya Republik Dominika, seperti negara Karib...   \n",
       "24  Pangeran Samudra menjadi raja pertama Kerajaan...   \n",
       "25  Daratan utama Skotlandia mencakup sepertiga da...   \n",
       "26  Pulau Pitcairn menjadi koloni Inggris pada tah...   \n",
       "27  Rencana untuk membuat bom uranium oleh negara-...   \n",
       "\n",
       "                                             question  \\\n",
       "0                          Apa warna bendera Jerman ?   \n",
       "1               Siapakah nama pemimpin dalam gereja ?   \n",
       "2     Kapan mata uang Euro secara fisik baru dipakai?   \n",
       "3                      Berapa luas Kabupaten Kaimana?   \n",
       "4                    Dimana Władysław Odonic berasal?   \n",
       "5                           Apakah fungsi utama CPU ?   \n",
       "6   Ada berapa negara yang tergabung dalam Uni Eropa?   \n",
       "7                      berapakah Luas kota Palembang?   \n",
       "8                       Berapakah Luas Gurun Sahara ?   \n",
       "9                 Dimana kantor pusat perusahaan IBM?   \n",
       "10              apakah nama ibukota Kalimantan Barat?   \n",
       "11                 Apa nama kota terbesar di Vietnam?   \n",
       "12                           Apa itu stimulus netral?   \n",
       "13  Kapan radio pertama kali digunakan di Indonesia ?   \n",
       "14  siapakah karakter utama dari game Uncharted 3:...   \n",
       "15                     Apa fungsi bangunan gynaeceum?   \n",
       "16                    Apa yang dimaksud dengan gizi ?   \n",
       "17                           berapakah luas Lamongan?   \n",
       "18                Kapan Johann Sebastian Bach lahir ?   \n",
       "19  kapankah papua nugini melepaskan diri dari ind...   \n",
       "20                dari manakah kucing bengal berasal?   \n",
       "21     Kapan Snow White and the Seven Dwarfs dirilis?   \n",
       "22           Siapa yang menciptakan teori kapitalis ?   \n",
       "23        Apakah bahasa kebangsaan Republik Dominika?   \n",
       "24               Siapa raja pertama kerajaan Banjar ?   \n",
       "25                            Berapa luas Skotlandia?   \n",
       "26       Kapan Pulau Pitcairn menjadi koloni Inggris?   \n",
       "27           Kapan senjata nuklir pertama diciptakan?   \n",
       "\n",
       "                                               answer  \\\n",
       "0   hitam di atas, merah di tengah, dan kuning (\"e...   \n",
       "1                                                Paus   \n",
       "2                                      1 Januari 2002   \n",
       "3                                          36.000 km2   \n",
       "4                                        Wielkopolska   \n",
       "5   melakukan operasi aritmetika dan logika terhad...   \n",
       "6                                                  28   \n",
       "7                                           358,55km²   \n",
       "8                                        9.000.000km2   \n",
       "9                   Armonk, New York, Amerika Serikat   \n",
       "10                                          Pontianak   \n",
       "11                                        Ho Chi Minh   \n",
       "12  stimulus yang tidak atau belum menghasilkan se...   \n",
       "13                                             1920an   \n",
       "14  Nate dengan mentor dan figur ayah, Victor \"Sul...   \n",
       "15                          diperuntukkan bagi wanita   \n",
       "16  substansi organik yang dibutuhkan organisme un...   \n",
       "17                                         1.812,8km2   \n",
       "18                                      21 Maret 1685   \n",
       "19                                        1 Juli 1971   \n",
       "20                        California, Amerika Serikat   \n",
       "21                                    4 Februari 1937   \n",
       "22                                          Karl Marx   \n",
       "23                                           Kastilia   \n",
       "24                                   Pangeran Samudra   \n",
       "25                                           78,772km   \n",
       "26                                               1838   \n",
       "27                                               1939   \n",
       "\n",
       "                                       ner_tag_answer  \\\n",
       "0   [(NULL, hitam di atas, merah di tengah, dan ku...   \n",
       "1                                      [(NULL, Paus)]   \n",
       "2                            [(NULL, 1 Januari 2002)]   \n",
       "3                                [(NULL, 36.000 km2)]   \n",
       "4                                  [(PLACE, wielkop)]   \n",
       "5   [(NULL, melakukan operasi aritmetika dan logik...   \n",
       "6                                        [(NULL, 28)]   \n",
       "7                                 [(NULL, 358,55km²)]   \n",
       "8                              [(NULL, 9.000.000km2)]   \n",
       "9   [(PLACE, armonk), (PLACE, new york), (PLACE, a...   \n",
       "10                               [(PLACE, pontianak)]   \n",
       "11                             [(PLACE, ho chi minh)]   \n",
       "12  [(NULL, stimulus yang tidak atau belum menghas...   \n",
       "13                                   [(NULL, 1920an)]   \n",
       "14  [(PERSON, nat), (PERSON, victor \" sully \" sull...   \n",
       "15                [(NULL, diperuntukkan bagi wanita)]   \n",
       "16  [(NULL, substansi organik yang dibutuhkan orga...   \n",
       "17                               [(NULL, 1.812,8km2)]   \n",
       "18                            [(NULL, 21 Maret 1685)]   \n",
       "19                              [(NULL, 1 Juli 1971)]   \n",
       "20    [(PLACE, california), (PLACE, amerika serikat)]   \n",
       "21                          [(NULL, 4 Februari 1937)]   \n",
       "22                              [(PERSON, karl marx)]   \n",
       "23                                 [(NULL, Kastilia)]   \n",
       "24                       [(PERSON, pangeran samudra)]   \n",
       "25                                 [(NULL, 78,772km)]   \n",
       "26                                     [(NULL, 1838)]   \n",
       "27                                     [(NULL, 1939)]   \n",
       "\n",
       "                                  chunking_tag_answer  \\\n",
       "0   [(NP, hitam), (PP, di), (NP, atas, merah), (PP...   \n",
       "1                                        [(NP, paus)]   \n",
       "2                              [(NP, 1 januari 2002)]   \n",
       "3                                 [(NP, 36. 000 km2)]   \n",
       "4                                [(NP, wielkopolska)]   \n",
       "5   [(VP, melakukan), (NP, operasi aritmetika dan ...   \n",
       "6                                          [(NP, 28)]   \n",
       "7                            [(NP, 358), (NP, 55km²)]   \n",
       "8                              [(NP, 9. 000. 000km2)]   \n",
       "9    [(NP, armonk,), (NP, new york, amerika serikat)]   \n",
       "10                                  [(NP, pontianak)]   \n",
       "11                                [(NP, ho chi minh)]   \n",
       "12  [(NP, stimulus), (SBAR, yang), (ADVP, tidak), ...   \n",
       "13                                     [(NP, 1920an)]   \n",
       "14  [(NP, nate), (PP, dengan), (NP, mentor dan fig...   \n",
       "15    [(VP, diperuntukkan), (PP, bagi), (NP, wanita)]   \n",
       "16  [(NP, substansi organik), (SBAR, yang), (VP, d...   \n",
       "17                        [(NP, 1. 812,), (NP, 8km2)]   \n",
       "18                              [(NP, 21 maret 1685)]   \n",
       "19                                [(NP, 1 juli 1971)]   \n",
       "20                [(NP, california, amerika serikat)]   \n",
       "21                            [(NP, 4 februari 1937)]   \n",
       "22                                  [(NP, karl marx)]   \n",
       "23                                   [(NP, kastilia)]   \n",
       "24                           [(NP, pangeran samudra)]   \n",
       "25                                  [(NP, 78, 772km)]   \n",
       "26                                       [(NP, 1838)]   \n",
       "27                                       [(VP, 1939)]   \n",
       "\n",
       "                                      ner_tag_premise  \\\n",
       "0   [(PLACE, jerman), (PLACE, jerman barat), (PLAC...   \n",
       "1   [(PERSON, paus), (PLACE, dutch), (PLACE, latin...   \n",
       "2               [(PLACE, uni), (ORGANISATION, eropa)]   \n",
       "3   [(PLACE, kabupaten kaimana), (PLACE, provinsi ...   \n",
       "4   [(PERSON, plwacz), (PLACE, pl), (PERSON, ##wa)...   \n",
       "5                                 [NO TOKEN DETECTED]   \n",
       "6   [(ORGANISATION, uni eropa), (ORGANISATION, ue)...   \n",
       "7   [(PLACE, kota palembang), (PLACE, provinsi sum...   \n",
       "8   [(PLACE, sahara), (PLACE, afrika), (PLACE, sam...   \n",
       "9   [(ORGANISATION, international business machine...   \n",
       "10  [(PLACE, belanda), (PLACE, gouvernement borneo...   \n",
       "11  [(PLACE, kota ho chi minh), (PLACE, vietnam), ...   \n",
       "12  [(PERSON, pavlov), (PERSON, pavlov), (PERSON, ...   \n",
       "13  [(PLACE, indonesia), (PLACE, indonesia), (PLAC...   \n",
       "14  [(PERSON, nate), (PERSON, victor \" sully \" sul...   \n",
       "15  [(PLACE, yunani), (PLACE, yunani), (PLACE, ind...   \n",
       "16                                [NO TOKEN DETECTED]   \n",
       "17  [(PLACE, kabupaten lamongan), (PLACE, kabupate...   \n",
       "18  [(PERSON, johann sebastian bach), (PLACE, kota...   \n",
       "19  [(PERSON, nicolaas jouwe), (ORGANISATION, opm)...   \n",
       "20  [(PLACE, amerika), (PLACE, california), (PLACE...   \n",
       "21  [(ORGANISATION, walt disney), (ORGANISATION, r...   \n",
       "22  [(PERSON, karl marx), (PERSON, marx), (PERSON,...   \n",
       "23  [(PLACE, republik dominika), (PLACE, karibia),...   \n",
       "24  [(PERSON, pangeran samudra), (PLACE, kerajaan ...   \n",
       "25  [(PLACE, skotlandia), (PLACE, pulau britania r...   \n",
       "26  [(PLACE, pulau pitcairn), (PLACE, inggris), (P...   \n",
       "27  [(PERSON, albert einstein), (PLACE, as), (PERS...   \n",
       "\n",
       "                                 chunking_tag_premise  \\\n",
       "0   [(NP, bendera jerman), (ADVP, pertama kali), (...   \n",
       "1   [(NP, paus (), (PP, dari), (NP, dutch : paus ;...   \n",
       "2   [(NP, euro ( € )), (VP, adalah), (NP, mata uan...   \n",
       "3   [(NP, kabupaten kaimana), (VP, adalah), (NP, s...   \n",
       "4   [(NP, Władysław (), (ADVP, juga), (VP, bernama...   \n",
       "5   [(NP, cpu), (VP, berfungsi), (PP, seperti), (N...   \n",
       "6   [(NP, uni eropa), (VP, disingkat), (NP, ue )),...   \n",
       "7   [(NP, kota palembang), (VP, adalah), (NP, ibu ...   \n",
       "8   [(NP, sahara), (VP, terletak), (PP, di), (NP, ...   \n",
       "9   [(NP, international business machines corporat...   \n",
       "10  [(PP, pada), (NP, zaman pemerintahan hindia be...   \n",
       "11  [(NP, kota ho chi minh ( bahasa vietnam : than...   \n",
       "12  [(PP, menurut), (NP, pavlov), (NP, refleks), (...   \n",
       "13  [(SBAR, jika), (NP, kita), (VP, membuka -), (V...   \n",
       "14  [(NP, uncharted 3 : drake ' s deception), (VP,...   \n",
       "15  [(PP, di), (NP, yunani kuno), (NP, gynaeceum (...   \n",
       "16  [(NP, nutrisi atau gizi), (VP, adalah), (NP, s...   \n",
       "17  [(PP, secara), (ADVP, geografis), (NP, kabupat...   \n",
       "18  [(NP, johann sebastian bach), (VP, lahir), (PP...   \n",
       "19  [(VP, menanggapi), (NP, hal tersebut), (NP, ni...   \n",
       "20  [(NP, kucing bengal), (VP, adalah), (NP, ketur...   \n",
       "21  [(NP, snow white and the seven dwarfs ( \" putr...   \n",
       "22  [(NP, istilah kapitalisme), (PP, dalam), (NP, ...   \n",
       "23  [(NP, budaya republik dominika), (PP, seperti)...   \n",
       "24  [(NP, pangeran samudra), (VP, menjadi), (NP, r...   \n",
       "25  [(NP, daratan utama skotlandia), (VP, mencakup...   \n",
       "26  [(NP, pulau pitcairn), (VP, menjadi), (NP, kol...   \n",
       "27  [(NP, rencana), (SBAR, untuk), (VP, membuat), ...   \n",
       "\n",
       "                                  same_ner_tag_answer  \\\n",
       "0                                                  []   \n",
       "1                                                  []   \n",
       "2                                                  []   \n",
       "3                                                  []   \n",
       "4   [pl, kalisz, poznan, uj, Nakło, wielkopolsk, s...   \n",
       "5                                                  []   \n",
       "6                                                  []   \n",
       "7                                                  []   \n",
       "8                                                  []   \n",
       "9   [amerika serikat, armonk, new york, amerika se...   \n",
       "10  [belanda, gouvernement borneo, banjarmasin, re...   \n",
       "11  [kota ho chi minh, vietnam, thanh pho ho chi m...   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14  [nate, victor \" sully \" sullivan, elena fisher...   \n",
       "15                                                 []   \n",
       "16                                                 []   \n",
       "17                                                 []   \n",
       "18                                                 []   \n",
       "19                                                 []   \n",
       "20             [amerika, california, amerika serikat]   \n",
       "21                                                 []   \n",
       "22          [karl marx, marx, marx, friedrich engels]   \n",
       "23                                                 []   \n",
       "24        [pangeran samudra, sultan suriansyah, khat]   \n",
       "25                                                 []   \n",
       "26                                                 []   \n",
       "27                                                 []   \n",
       "\n",
       "                             same_chunking_tag_answer  \\\n",
       "0   [bendera jerman, tahun 1919, tahun 1949 bender...   \n",
       "1   [paus (, dutch : paus ; latin : papa, greek : ...   \n",
       "2   [euro ( € ), mata uang, 19 negara anggota uni ...   \n",
       "3   [kabupaten kaimana, salah satu kabupaten, prov...   \n",
       "4   [Władysław (, Włodzisław ) odonic (, plwacz ),...   \n",
       "5   [berfungsi, adalah melakukan, diambil, dimasuk...   \n",
       "6   [uni eropa, ue ), organisasi antarpemerintahan...   \n",
       "7   [kota palembang, ibu kota provinsi sumatera se...   \n",
       "8   [sahara, utara afrika, 2,, 5 juta tahun, padan...   \n",
       "9   [international business machines corporation (...   \n",
       "10  [zaman pemerintahan hindia belanda, keputusan ...   \n",
       "11  [kota ho chi minh ( bahasa vietnam : thanh pho...   \n",
       "12  [pavlov, refleks, air liur, anjing tersebut, s...   \n",
       "13  [kita, lembaran sejarah radio indonesia, radio...   \n",
       "14  [uncharted 3 : drake ' s deception, november 2...   \n",
       "15  [diperuntukkan, berarti \", milik, merupakan, d...   \n",
       "16  [nutrisi atau gizi, substansi organik, organis...   \n",
       "17  [kabupaten lamongan, 6o51 ', 7o23 ' lintang se...   \n",
       "18  [johann sebastian bach, tanggal 21 maret 1685,...   \n",
       "19  [hal tersebut, nicolaas jouwe dan dua komandan...   \n",
       "20  [kucing bengal, keturunan ketiga, hasil persil...   \n",
       "21  [snow white and the seven dwarfs ( \" putri sal...   \n",
       "22  [istilah kapitalisme, arti modern, karl marx, ...   \n",
       "23  [budaya republik dominika, negara karibia seki...   \n",
       "24  [pangeran samudra, raja pertama kerajaan banja...   \n",
       "25  [daratan utama skotlandia, sepertiga daratan p...   \n",
       "26  [pulau pitcairn, koloni inggris, tahun 1838, s...   \n",
       "27  [membuat, dimulai, menulis, dan menyampaikan, ...   \n",
       "\n",
       "                    wrong_answer  \\\n",
       "0                    atas, merah   \n",
       "1                              3   \n",
       "2         tanggal 1 januari 1999   \n",
       "3                18. 500 km2 dan   \n",
       "4                         poznan   \n",
       "5               dapat dijalankan   \n",
       "6               tanggal tersebut   \n",
       "7              luas wilayah 358,   \n",
       "8                   5 juta tahun   \n",
       "9                         armonk   \n",
       "10                   banjarmasin   \n",
       "11              kota ho chi minh   \n",
       "12        conditioned stimulus )   \n",
       "13  kepentingan penjajah belanda   \n",
       "14     victor \" sully \" sullivan   \n",
       "15                         milik   \n",
       "16             substansi organik   \n",
       "17              seluas 902, 4km2   \n",
       "18                tahun 1695 dia   \n",
       "19                    tahun 1971   \n",
       "20                       amerika   \n",
       "21                          awal   \n",
       "22                          marx   \n",
       "23               bahasa spanyol,   \n",
       "24             sultan suriansyah   \n",
       "25        305 kilometres ( 190mi   \n",
       "26      pertengahan tahun 1850an   \n",
       "27                      mencapai   \n",
       "\n",
       "                     plausible_answer_based_on_method  \\\n",
       "0   [atas, merah, tiga warna, hitam, bendera ini, ...   \n",
       "1   [3, 4, 1, peranannya, 2 ], besar, siapa, yesus...   \n",
       "2   [tanggal 1 januari 1999, mana - mana, belakang...   \n",
       "3   [18. 500 km2 dan, luas lautan / perairan ± 17....   \n",
       "4       [poznan, kalisz, Nakło, pl, uj, sungai warta]   \n",
       "5   [dapat dijalankan, dikontrol, berfungsi, adala...   \n",
       "6   [tanggal tersebut, 1 juli 2013, ue, persatuan ...   \n",
       "7   [luas wilayah 358,, km², 1. 573. 898 jiwa, 2, ...   \n",
       "8   [5 juta tahun, luas padang pasir ini, kedua ba...   \n",
       "9          [armonk, amerika serikat, amerika serikat]   \n",
       "10  [banjarmasin, belanda, residentie westerafdeel...   \n",
       "11  [kota ho chi minh, kota ho chi minh, vietnam, ...   \n",
       "12  [conditioned stimulus ), sebuah stimulus netra...   \n",
       "13  [kepentingan penjajah belanda, pertama kalinya...   \n",
       "14  [victor \" sully \" sullivan, talbot, katherine ...   \n",
       "15              [milik, merupakan, adalah, berarti \"]   \n",
       "16  [substansi organik, nutrisi atau gizi, organis...   \n",
       "17  [seluas 902, 4km2, luas wilayah, panjang garis...   \n",
       "18  [tahun 1695 dia, saat, zaman itu, johann sebas...   \n",
       "19  [tahun 1971, roemkorem dan prai, konstitusinya...   \n",
       "20                         [amerika, amerika serikat]   \n",
       "21  [awal, film pertama, film pertama, film pertam...   \n",
       "22                     [marx, marx, friedrich engels]   \n",
       "23  [bahasa spanyol,, bahasa kastilia, budaya repu...   \n",
       "24                          [sultan suriansyah, khat]   \n",
       "25  [305 kilometres ( 190mi, 30 kilometres ( 19mi,...   \n",
       "26  [pertengahan tahun 1850an, tanggal 8 juni 1856...   \n",
       "27  [mencapai, membuat, dijadikan, disebut, adalah...   \n",
       "\n",
       "                                           properties  \n",
       "0   Detected span that is the SAME as the right an...  \n",
       "1   Detected span that is the SAME as the right an...  \n",
       "2   Detected span that is the SAME as the right an...  \n",
       "3   Detected span that is the SAME as the right an...  \n",
       "4   Detected span that is the SAME as the right an...  \n",
       "5   Detected span that is the SAME as the right an...  \n",
       "6   Detected span that is the SAME as the right an...  \n",
       "7   Detected span that is the SAME as the right an...  \n",
       "8   Detected span that is the SAME as the right an...  \n",
       "9   Detected span that is the SAME as the right an...  \n",
       "10  Detected span that is the SAME as the right an...  \n",
       "11  Detected span that is the SAME as the right an...  \n",
       "12  Detected span that is the SAME as the right an...  \n",
       "13  Detected span that is the SAME as the right an...  \n",
       "14  Detected span that is the SAME as the right an...  \n",
       "15  Detected span that is the SAME as the right an...  \n",
       "16  Detected span that is the SAME as the right an...  \n",
       "17  Detected span that is the SAME as the right an...  \n",
       "18  Detected span that is the SAME as the right an...  \n",
       "19  Detected span that is the SAME as the right an...  \n",
       "20  Detected span that is the SAME as the right an...  \n",
       "21  Detected span that is the SAME as the right an...  \n",
       "22  Detected span that is the SAME as the right an...  \n",
       "23                                                     \n",
       "24  Detected span that is the SAME as the right an...  \n",
       "25  Detected span that is the SAME as the right an...  \n",
       "26  Detected span that is the SAME as the right an...  \n",
       "27                                                     "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nli_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe61c82",
   "metadata": {},
   "source": [
    "# Split to two dataset: right dataset & wrong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9d6c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_column_number(data, column_name=\"hypothesis\", column_num=3):\n",
    "\n",
    "    cols = list(data.columns)\n",
    "    cols.remove(column_name)\n",
    "    cols.insert(column_num, column_name)\n",
    "\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56880d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['wrong_answer']\n",
    "\n",
    "data_nli_right_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_right_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_right_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "232c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['answer']\n",
    "\n",
    "data_nli_wrong_train_df = data_nli_train_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_wrong_val_df = data_nli_val_df.drop(columns=columns_to_exclude).copy()\n",
    "data_nli_wrong_test_df = data_nli_test_df.drop(columns=columns_to_exclude).copy()\n",
    "\n",
    "data_nli_wrong_train_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_wrong_val_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "data_nli_wrong_test_df.rename(columns={'wrong_answer': 'answer'}, inplace=True)\n",
    "\n",
    "data_nli_wrong_train_df = move_to_column_number(data_nli_wrong_train_df, \"answer\", 2)\n",
    "data_nli_wrong_val_df = move_to_column_number(data_nli_wrong_val_df, \"answer\", 2)\n",
    "data_nli_wrong_test_df = move_to_column_number(data_nli_wrong_test_df, \"answer\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6f08",
   "metadata": {},
   "source": [
    "# Convert question-answer pair to hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01d0b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_question_and_answer_to_hypothesis(data):\n",
    "    for i in range(len(data)):\n",
    "        data['hypothesis'] = data['question'] + ' ' + data['answer']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acf340e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_right_train_df = convert_question_and_answer_to_hypothesis(data_nli_right_train_df)\n",
    "data_nli_right_val_df = convert_question_and_answer_to_hypothesis(data_nli_right_val_df)\n",
    "data_nli_right_test_df = convert_question_and_answer_to_hypothesis(data_nli_right_test_df)\n",
    "\n",
    "data_nli_right_train_df = move_to_column_number(data_nli_right_train_df, \"hypothesis\", 3)\n",
    "data_nli_right_val_df = move_to_column_number(data_nli_right_val_df, \"hypothesis\", 3)\n",
    "data_nli_right_test_df = move_to_column_number(data_nli_right_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20241aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_wrong_train_df = convert_question_and_answer_to_hypothesis(data_nli_wrong_train_df)\n",
    "data_nli_wrong_val_df = convert_question_and_answer_to_hypothesis(data_nli_wrong_val_df)\n",
    "data_nli_wrong_test_df = convert_question_and_answer_to_hypothesis(data_nli_wrong_test_df)\n",
    "\n",
    "data_nli_wrong_train_df = move_to_column_number(data_nli_wrong_train_df, \"hypothesis\", 3)\n",
    "data_nli_wrong_val_df = move_to_column_number(data_nli_wrong_val_df, \"hypothesis\", 3)\n",
    "data_nli_wrong_test_df = move_to_column_number(data_nli_wrong_test_df, \"hypothesis\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c4ace",
   "metadata": {},
   "source": [
    "# Add label: entailment & contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45df14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_right_train_df['label'] = 'entailment'\n",
    "data_nli_right_val_df['label'] = 'entailment'\n",
    "data_nli_right_test_df['label'] = 'entailment'\n",
    "\n",
    "data_nli_right_train_df = move_to_column_number(data_nli_right_train_df, \"label\", 4)\n",
    "data_nli_right_train_df = move_to_column_number(data_nli_right_val_df, \"label\", 4)\n",
    "data_nli_right_train_df = move_to_column_number(data_nli_right_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02098578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_wrong_train_df['label'] = 'contradiction'\n",
    "data_nli_wrong_val_df['label'] = 'contradiction'\n",
    "data_nli_wrong_test_df['label'] = 'contradiction'\n",
    "\n",
    "data_nli_wrong_train_df = move_to_column_number(data_nli_wrong_train_df, \"label\", 4)\n",
    "data_nli_wrong_val_df = move_to_column_number(data_nli_wrong_val_df, \"label\", 4)\n",
    "data_nli_wrong_test_df = move_to_column_number(data_nli_wrong_test_df, \"label\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f431144",
   "metadata": {},
   "source": [
    "# Concat the right and wrong NLI to one NLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "165d72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final = pd.concat([data_nli_right_train_df, data_nli_wrong_train_df], axis=0, ignore_index=True)\n",
    "data_nli_val_df_final = pd.concat([data_nli_right_val_df, data_nli_wrong_val_df], axis=0, ignore_index=True)\n",
    "data_nli_test_df_final = pd.concat([data_nli_right_test_df, data_nli_wrong_test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea9097",
   "metadata": {},
   "source": [
    "# Convert to DataFrame format to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nli_train_df_final.to_csv(\"data_nli_train_df.csv\", index=False)\n",
    "data_nli_val_df_final.to_csv(\"data_nli_val_df.csv\", index=False)\n",
    "data_nli_test_df_final.to_csv(\"data_nli_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28862303-7b4c-4279-91b3-b5efcdf00e75",
   "metadata": {},
   "source": [
    "# Push to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d50f6c-1e40-4087-9f6c-f5bc5aaaa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HUB_TOKEN = \"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\"\n",
    "USER = \"muhammadravi251001\"\n",
    "REPO = \"idk-mrc-nli\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"data_nli_train_df.csv\",\n",
    "    path_in_repo=\"data_nli_train_df.csv\",\n",
    "    repo_id=f\"{USER}/{REPO}\",\n",
    "    token=HUB_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"data_nli_val_df.csv\",\n",
    "    path_in_repo=\"data_nli_val_df.csv\",\n",
    "    repo_id=f\"{USER}/{REPO}\",\n",
    "    token=HUB_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"data_nli_test_df.csv\",\n",
    "    path_in_repo=\"data_nli_test_df.csv\",\n",
    "    repo_id=f\"{USER}/{REPO}\",\n",
    "    token=HUB_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
