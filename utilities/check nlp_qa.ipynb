{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa08b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    Dataset,\n",
    "    DatasetDict\n",
    ")\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoModelForQuestionAnswering, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForTokenClassification, \n",
    "    AutoModelForSequenceClassification, \n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aecfb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_QA_NAME = \"muhammadravi251001/fine-tuned-DatasetQAS-IDK-MRC-with-xlm-roberta-large-without-ITTL-without-freeze-LR-1e-05\"\n",
    "\n",
    "tokenizer_kwargs = {'truncation': True, 'max_length': 512}\n",
    "\n",
    "tokenizer_qa = AutoTokenizer.from_pretrained(MODEL_QA_NAME)\n",
    "model_qa = AutoModelForQuestionAnswering.from_pretrained(MODEL_QA_NAME)\n",
    "model_qa.config.top_k = 3\n",
    "#model_qa = model_qa.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_qa_original(question, context):\n",
    "        \n",
    "    inputs = tokenizer_qa(question, context, \n",
    "                          return_tensors=\"pt\",\n",
    "                          **tokenizer_kwargs)\n",
    "\n",
    "    #inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model_qa(**inputs)\n",
    "\n",
    "    sorted_start_logits = torch.argsort(outputs.start_logits)\n",
    "    sorted_end_logits = torch.argsort(outputs.end_logits)\n",
    "\n",
    "    answer_array = []\n",
    "    for i in range(1, (top_k + 1)):\n",
    "\n",
    "        start_index = sorted_start_logits[0, -i]\n",
    "        end_index = sorted_end_logits[0, -i]\n",
    "        \n",
    "        print(start_index)\n",
    "        print(end_index)\n",
    "        \n",
    "        answer_tokens = inputs[\"input_ids\"][0][start_index : end_index + 1]\n",
    "\n",
    "        answer = tokenizer_qa.decode(answer_tokens)\n",
    "        answer_array.append({'answer': answer})\n",
    "\n",
    "    return answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd0af9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_qa(question, context, top_k=5):\n",
    "        \n",
    "    inputs = tokenizer_qa(question, context, \n",
    "                          return_tensors=\"pt\",\n",
    "                          **tokenizer_kwargs)\n",
    "\n",
    "    #inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model_qa(**inputs)\n",
    "\n",
    "    sorted_start_logits = torch.argsort(outputs.start_logits)\n",
    "    sorted_end_logits = torch.argsort(outputs.end_logits)\n",
    "    \n",
    "    print(outputs.start_logits.shape)\n",
    "\n",
    "    answer_array = []\n",
    "    for i in range(1, (top_k + 1)):\n",
    "\n",
    "        start_index = sorted_start_logits[0, -i]\n",
    "        end_index = sorted_end_logits[0, -i]\n",
    "        \n",
    "        print(outputs.start_logits[0, start_index])\n",
    "        print(outputs.end_logits[0, end_index])\n",
    "        print()\n",
    "        \n",
    "        #print(start_index)\n",
    "        #print(end_index)\n",
    "        \n",
    "        answer_tokens = inputs[\"input_ids\"][0][start_index : end_index + 1]\n",
    "\n",
    "        answer = tokenizer_qa.decode(answer_tokens)\n",
    "        answer_array.append({'answer': answer})\n",
    "\n",
    "    return answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d515a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Protista adalah mikroorganisme eukariota yang bukan hewan, tumbuhan, atau fungus. Mereka pernah dikelompokkan ke dalam satu kerajaan bernama Protista, namun sekarang tidak dipertahankan lagi.[2] Penggunaannya masih digunakan untuk kepentingan kajian ekologi dan morfologi bagi semua organisme eukariotik bersel tunggal yang hidup secara mandiri atau, jika membentuk koloni, bersama-sama namun tidak menunjukkan diferensiasi menjadi jaringan yang berbeda-beda.[3]. Dari sudut pandang taksonomi, pengelompokan ini ditinggalkan karena bersifat parafiletik. Organisme dalam Protista tidak memiliki kesamaan, kecuali pengelompokan yang mudah[4]â€”baik yang bersel satu atau bersel banyak tanpa memiliki jaringan. Protista hidup di hampir semua lingkungan yang mengandung air. Banyak protista, seperti algae, adalah fotosintetik dan produsen primer vital dalam ekosistem, khususnya di laut sebagai bagian dari plankton. Protista lain, seperti Kinetoplastid dan Apicomplexa, adalah penyakit berbahaya bagi manusia, seperti malaria dan tripanosomiasis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e16782a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Mengapa protista tidak dikelompokkan ke dalam satu kerajaan taksonomi?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adda1b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 228])\n",
      "tensor(7.8845, grad_fn=<SelectBackward0>)\n",
      "tensor(8.2361, grad_fn=<SelectBackward0>)\n",
      "\n",
      "tensor(6.0922, grad_fn=<SelectBackward0>)\n",
      "tensor(7.1699, grad_fn=<SelectBackward0>)\n",
      "\n",
      "tensor(5.7972, grad_fn=<SelectBackward0>)\n",
      "tensor(5.7037, grad_fn=<SelectBackward0>)\n",
      "\n",
      "tensor(5.6187, grad_fn=<SelectBackward0>)\n",
      "tensor(5.1508, grad_fn=<SelectBackward0>)\n",
      "\n",
      "tensor(5.5576, grad_fn=<SelectBackward0>)\n",
      "tensor(5.0051, grad_fn=<SelectBackward0>)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'answer': ''},\n",
       " {'answer': 'karena bersifat parafiletik'},\n",
       " {'answer': ''},\n",
       " {'answer': ''},\n",
       " {'answer': ''}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa89a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
